{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch101Week#01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNE8q9Dpha+Uo8b2x1RaW8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahosnyyy/CIT690E-DL-Course/blob/master/PyTorch101Week_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding PyTorch with an example: a step-by-step tutorial\n",
        "\n",
        "## Introduction\n",
        "\n",
        "PyTorch is a machine learning framework produced by Facebook in October 2016. It is open source, and is based on the popular [Torch](http://torch.ch/) library. PyTorch is designed to provide good flexibility and high speeds for deep neural network implementation.\n",
        "\n",
        "PyTorch is different from other deep learning frameworks in that it uses dynamic computation graphs. While static computational graphs (like those used in TensorFlow) are defined prior to runtime, dynamic graphs are defined \"*on the fly*\" via the forward computation. In other words, the graph is rebuilt from scratch on every iteration (for more information, check out the Stanford [CS231n course](http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture06.pdf)).\n",
        "\n",
        "PyTorch is also very pythonic, meaning, it feels more natural to use it if you already are a Python developer.\n",
        "\n",
        "Besides, using PyTorch may even improve your health, according to [Andrej Karpathy](https://twitter.com/karpathy/status/868178954032513024) :-)\n",
        "\n",
        "\n",
        "## Motivation\n",
        "\n",
        "In this tutorial, We will go through the main reasons why PyTorch makes it much easier and more intuitive to build a Deep Learning model in Python — **autograd, dynamic computation graph, model classes** and more — and I will also show you how to avoid some common pitfalls and errors along the way."
      ],
      "metadata": {
        "id": "IseOR-umN7vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Simple Regression Problem\n",
        "\n",
        "Most tutorials start with some nice and pretty image classification problem to illustrate how to use PyTorch. It may seem cool, but I believe it distracts you from the **main goal: how PyTorch works?**\n",
        "\n",
        "For this reason, in this tutorial, I will stick with a simple and familiar problem: a **linear regression with a single feature x!** It doesn’t get much simpler than that…\n",
        "\n",
        "$$y=a + bx + c$$"
      ],
      "metadata": {
        "id": "hplOm9pQRmp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation\n",
        "\n",
        "Let’s start generating some synthetic data: we start with a vector of 100 points for our feature $x$ and create our labels using $a = 1, b = 2$ and some Gaussian noise.\n",
        "\n",
        "Next, let’s split our synthetic data into train and validation sets, shuffling the array of indices and using the first 80 shuffled points for training."
      ],
      "metadata": {
        "id": "Hrz3dzupSedw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uvGcszEbNvQ6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data Generation\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1)\n",
        "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
        "\n",
        "# Shuffles the indices\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:80]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[80:]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,7))\n",
        "ax1.scatter(x_train, y_train, color='blue')\n",
        "ax1.set_title('Generated Data - Train')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax2.scatter(x_val, y_val, color='red')\n",
        "ax2.set_title('Generated Data - Validation')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "5XPPFhQGW9aA",
        "outputId": "88036d59-a5b1-476d-85be-0369277fddd3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that $a = 1$ and $b = 2$, but now let’s see how close we can get to the true values by using **gradient descent** and the 80 points in the training set…"
      ],
      "metadata": {
        "id": "35JxvSiAZ5Co"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent\n",
        "\n",
        "It goes beyond the scope of this tutorial to fully explain how gradient descent works, but I’ll cover the four basic steps you’d need to go through to compute it.\n",
        "\n",
        "### Step 1: Compute the Loss\n",
        "For a regression problem, the loss is given by the **Mean Square Error (MSE)**, that is, the average of all squared differences between **labels (y)** and **predictions ($a + bx$)**.\n",
        "\n",
        "$$MSE=\\frac{1}{N}\\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$$"
      ],
      "metadata": {
        "id": "sGzSPFyianwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        "> *It is worth mentioning that, if we use **all points** in the training set (N) to compute the loss, we are performing a **batch** gradient descent. If we were to use a single point at each time, it would be a **stochastic** gradient descent. Anything else (n) in-between 1 and N characterizes a **mini-batch** gradient descent.*\n",
        ">"
      ],
      "metadata": {
        "id": "1qN6NHJavKZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Compute the Gradients\n",
        "A **gradient** is a **partial derivative** — why partial? Because one computes it with respect to (w.r.t.) a **single parameter**. We have two parameters, $a$ and $b$, so we must compute two partial derivatives.\n",
        "\n",
        "A **derivative** tells you how much **a given quantity changes** when you slightly vary some **other quantity**. In our case, how much does our **MSE loss** change when we vary **each one of our two parameters**?"
      ],
      "metadata": {
        "id": "Jka814yJvMK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Update the Parameters\n",
        "In the final step, we **use the gradients to update** the parameters. Since we are trying to **minimize** our **losses**, we **reverse the sign** of the gradient for the update.\n",
        "\n",
        "There is still another parameter to consider: the **learning rate**, denoted by the Greek letter **eta** (that looks like the letter $n$), which is the **multiplicative factor** that we need to apply to the gradient for the parameter update.\n",
        "\n",
        "<br />\n",
        "$$a=a- \\eta \\frac{\\partial MSE}{\\partial a}$$\n",
        "<br />\n",
        "$$b=b- \\eta \\frac{\\partial MSE}{\\partial b}$$\n",
        "<br />\n",
        "\n",
        "How to choose a learning rate? That is a topic on its own and beyond the scope of this post as well."
      ],
      "metadata": {
        "id": "ZJGd4voVwKvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Rinse and Repeat!\n",
        "Now we use the **updated parameters** to go back to Step 1 and restart the process."
      ],
      "metadata": {
        "id": "DhVdQEeCx6Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*An epoch is complete whenever every point has been already used for computing the loss. For batch gradient descent, this is trivial, as it uses all points for computing the loss — one epoch is the same as one update. For stochastic gradient descent, one epoch means N updates, while for mini-batch (of size n), one epoch has N/n updates.*\n",
        ">"
      ],
      "metadata": {
        "id": "brau656P9a2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating this process over and over, for many epochs, is, in a nutshell, training a model."
      ],
      "metadata": {
        "id": "74BnCfmp9i_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression in Numpy\n",
        "\n",
        "It’s time to implement our linear regression model using gradient descent using **Numpy only**.\n",
        "\n",
        "For training a model, there are **two initialization steps**:\n",
        "* Random initialization of parameters/weights (we have only two, $a$ and $b$)\n",
        "\n",
        "* Initialization of hyper-parameters (in our case, only learning rate and number of epochs)\n",
        "\n",
        "\n",
        "Make sure to always initialize your random seed to ensure reproducibility of your results. As usual, the random seed is 42, the least random of all random seeds one could possibly choose :-)\n",
        "\n",
        "\n",
        "For each epoch, there are **four training steps**:\n",
        "\n",
        "* Compute model’s predictions — this is the **forward pass**\n",
        "* Compute the loss, using predictions and and labels and the appropriate **loss function** for the task at hand\n",
        "* Compute the **gradients** for every parameter\n",
        "* **Update** the parameters\n",
        "\n",
        "Just keep in mind that, if you don’t use batch gradient descent (our example does),you’ll have to write an **inner loop** to perform the four training steps for either each individual point (stochastic) or n points (mini-batch). We’ll see a mini-batch example later down the line.\n",
        "\n"
      ],
      "metadata": {
        "id": "p3KGzZFi9nRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes parameters \"a\" and \"b\" randomly\n",
        "np.random.seed(42)\n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "\n",
        "print(\"# a and b after initialization: \", a, b)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 1e-1\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Computes our model's predicted output\n",
        "    yhat = a + b * x_train\n",
        "    \n",
        "    # How wrong is our model? That's the error! \n",
        "    error = (y_train - yhat)\n",
        "    # It is a regression, so it computes mean squared error (MSE)\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Computes gradients for both \"a\" and \"b\" parameters\n",
        "    a_grad = -2 * error.mean()\n",
        "    b_grad = -2 * (x_train * error).mean()\n",
        "    \n",
        "    # Updates parameters using gradients and the learning rate\n",
        "    a = a - lr * a_grad\n",
        "    b = b - lr * b_grad\n",
        "    \n",
        "print(\"# a and b after our gradient descent: \", a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH_HB_kfToJX",
        "outputId": "2faf6747-e8c3-4f8b-9953-0dd7fc02e260"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# a and b after initialization:  [0.49671415] [-0.1382643]\n",
            "# a and b after our gradient descent:  [1.02354094] [1.96896411]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity Check: do we get the same results as our gradient descent?\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linr = LinearRegression()\n",
        "linr.fit(x_train, y_train)\n",
        "print(\"# intercept and coef from Scikit-Learn: \", linr.intercept_, linr.coef_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqi5LINHBieR",
        "outputId": "985116c7-b33b-4bd0-fe29-07f2b07b66f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# intercept and coef from Scikit-Learn:  [1.02354075] [1.96896447]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "They match up to 6 decimal places — we have a fully working implementation of linear regression using Numpy.\n",
        "\n",
        "\n",
        "Time to **TORCH** it :-)\n"
      ],
      "metadata": {
        "id": "vc6KdbjJ_ItP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch\n",
        "\n",
        "First, we need to cover a few basic concepts that may throw you off-balance if you don’t grasp them well enough before going full-force on modeling.\n",
        "\n",
        "In Deep Learning, we see **tensors** everywhere. Well, Google’s framework is called TensorFlow for a reason! What is a tensor, anyway?\n",
        "\n",
        "### Tensor\n",
        "In Numpy, you may have an **array** that has **three dimensions**, right? That is, technically speaking, a **tensor**.\n",
        "\n",
        "A **scalar** (a single number) has zero dimensions, a **vector has one** dimension, a **matrix has two** dimensions and a **tensor has three or more** dimensions. That’s it!\n",
        "\n",
        "But, to keep things simple, it is commonplace to call vectors and matrices tensors as well — so, from now on, **everything is either a scalar or a tensor**.\n",
        "\n",
        "![tensor](https://miro.medium.com/max/1144/1*PDC6NHVmFXFZqxFf4YRSDg.png)\n",
        "![dog_tensor](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F1600%2F1*GbwKkmA0NdndXRhOOwNclA.jpeg&f=1&nofb=1)"
      ],
      "metadata": {
        "id": "Y_FpTHif_SNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data, Devices and CUDA\n",
        "\n",
        "“*How do we go from Numpy’s arrays to PyTorch’s tensors*”, you ask? That’s what **`from_numpy`** is good for. It returns a **CPU tensor**, though.\n",
        "\n",
        "“*But I want to use my fancy GPU…*”, you say. No worries, that’s what **`to()`** is good for. It sends your tensor to whatever **device** you specify, including your **GPU** (referred to as `cuda` or `cuda:0`).\n",
        "\n",
        "“*What if I want my code to fallback to CPU if no GPU is available?*”, you may be wondering… PyTorch got your back once more — you can use **`cuda.is_available()`** to find out if you have a GPU at your disposal and set your device accordingly.\n",
        "\n",
        "You can also easily **cast** it to a lower precision (32-bit float) using `float()`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LQNqcKxEA6pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "# and then we send them to the chosen device\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "\n",
        "# Here we can see the difference - notice that .type() is more useful\n",
        "# since it also tells us WHERE the tensor is (device)\n",
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLxam0ko-t9k",
        "outputId": "d5e155ed-e2ef-4bde-b61b-e1c414fcd339"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you compare the **types** of both variables, you’ll get what you’d expect: `numpy.ndarray` for the first one and `torch.Tensor` for the second one.\n",
        "\n",
        "But where does your nice tensor “live”? In your CPU or your GPU? You can’t say… but if you use PyTorch’s **`type()`**, it will reveal its location — `torch.cuda.FloatTensor` — a GPU tensor in this case.\n",
        "\n",
        "We can also go the other way around, turning tensors back into Numpy arrays, using **`numpy()`**. It should be easy as `x_train_tensor.numpy()` **but…**"
      ],
      "metadata": {
        "id": "1IKxnVm-CNK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Ek2xN38ZCzPp",
        "outputId": "ffc7a3e9-fce0-4861-dd18-c660dc1de033"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1f2e1ca5ecef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, Numpy **cannot** handle GPU tensors… you need to make them CPU tensors first using **`cpu()`**."
      ],
      "metadata": {
        "id": "VcKiP6TbDW-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Parameters\n",
        "What distinguishes a tensor used for data — like the ones we’ve just created — from a tensor used as a (*trainable*) **parameter/weight**?\n",
        "\n",
        "The latter tensors require the **computation of its gradients**, so we can **update** their values (the parameters’ values, that is). That’s what the `requires_grad=True` argument is good for. It tells PyTorch we want it to compute gradients for us.\n",
        "\n",
        "You may be tempted to create a simple tensor for a parameter and, later on, send it to your chosen device, as we did with our data, right? Not so fast…"
      ],
      "metadata": {
        "id": "ho_7L78XpYWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST\n",
        "# Initializes parameters \"a\" and \"b\" randomly, ALMOST as we did in Numpy\n",
        "# since we want to apply gradient descent on these parameters, we need\n",
        "# to set REQUIRES_GRAD = TRUE\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "print(\"# First: \", a, b)\n",
        "\n",
        "# SECOND\n",
        "# But what if we want to run it on a GPU? We could just send them to device, right?\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "print(\"# Second: \", a, b)\n",
        "# Sorry, but NO! The to(device) \"shadows\" the gradient...\n",
        "\n",
        "# THIRD\n",
        "# We can either create regular tensors and send them to the device (as we did with our data)\n",
        "a = torch.randn(1, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, dtype=torch.float).to(device)\n",
        "# and THEN set them as requiring gradients...\n",
        "a.requires_grad_()\n",
        "b.requires_grad_()\n",
        "print(\"# Third: \", a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkkqNEXap7kZ",
        "outputId": "37125434-87ea-446b-885c-5148e8e2bdf3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# First:  tensor([-0.1509], requires_grad=True) tensor([2.3253], requires_grad=True)\n",
            "# Second:  tensor([-1.7058], device='cuda:0', grad_fn=<ToCopyBackward0>) tensor([-0.8768], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
            "# Third:  tensor([-0.3064], device='cuda:0', requires_grad=True) tensor([1.1929], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first chunk of code creates two nice tensors for our parameters, gradients and all. But they are **CPU** tensors.\n",
        "\n",
        "In the second chunk of code, we tried the **naive** approach of sending them to our GPU. We succeeded in sending them to another device, but we **”lost”** the **gradients** somehow…\n",
        "\n",
        "In the third chunk, we **first** send our tensors to the **device** and then use **`requires_grad_()`** method to set its `requires_grad` to `True` in place."
      ],
      "metadata": {
        "id": "5ctqnZCbqQDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*In PyTorch, every method that **ends** with an **underscore (_)** makes changes **in-place**, meaning, they will **modify** the underlying variable.*\n",
        ">"
      ],
      "metadata": {
        "id": "UlWvEJ5oq9Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the last approach worked fine, it is much better to **assign** tensors to a **device** at the moment of their **creation**."
      ],
      "metadata": {
        "id": "aQ5ZOzO0rMyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can specify the device at the moment of creation - RECOMMENDED!\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IB-tzTXrXw9",
        "outputId": "3ca06c0f-9691-4a2b-fb6e-59cb7dbf9d8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much easier, right?\n",
        "Now that we know how to create tensors that require gradients, let’s see how PyTorch handles them — that’s the role of the…"
      ],
      "metadata": {
        "id": "di7iEH3brexi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd\n",
        "Autograd is PyTorch’s automatic differentiation package. Thanks to it, we **don’t need to worry** about partial derivatives, chain rule or anything like it.\n",
        "\n",
        "So, how do we tell PyTorch to do its thing and **compute all gradients**? That’s what **`backward()`** is good for.\n",
        "\n",
        "Do you remember the **starting point** for **computing the gradients**? It was the **loss**, as we computed its partial derivatives w.r.t. our parameters. Hence, we need to invoke the `backward()` method from the corresponding Python variable, like, `loss.backward()`.\n",
        "\n",
        "What about the **actual values** of the **gradients**? We can inspect them by looking at the **`grad`** **attribute** of a tensor.\n",
        "\n",
        "If you check the method’s documentation, it clearly states that **gradients are accumulated**. So, every time we use the **gradients** to **update** the parameters, we need to **zero the gradients afterwards**. And that’s what **`zero_()`** is good for.\n",
        "\n",
        "So, let’s ditch the **manual computation of gradients** and use both `backward()` and `zero_()` methods instead.\n",
        "\n",
        "That’s it? Well, pretty much… but, there is always a **catch**, and this time it has to do with the **update of the parameters**…"
      ],
      "metadata": {
        "id": "Zzv8ZF56rjHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # No more manual computation of gradients! \n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We just tell PyTorch to work its way BACKWARDS from the specified loss!\n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    print(a.grad)\n",
        "    print(b.grad)\n",
        "    \n",
        "    # What about UPDATING the parameters? Not so fast...\n",
        "    \n",
        "    # FIRST ATTEMPT\n",
        "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
        "    # a = a - lr * a.grad\n",
        "    # b = b - lr * b.grad\n",
        "    # print(a)\n",
        "\n",
        "    # SECOND ATTEMPT\n",
        "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "    # a -= lr * a.grad\n",
        "    # b -= lr * b.grad        \n",
        "    \n",
        "    # THIRD ATTEMPT\n",
        "    # We need to use NO_GRAD to keep the update out of the gradient computation\n",
        "    # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\n",
        "    with torch.no_grad():\n",
        "        a -= lr * a.grad\n",
        "        b -= lr * b.grad\n",
        "    \n",
        "    # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    \n",
        "print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnR7Y4WguSSK",
        "outputId": "b18ff456-fe1a-404d-b36d-50de53648666"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.3881], device='cuda:0')\n",
            "tensor([-1.9439], device='cuda:0')\n",
            "tensor([-2.5268], device='cuda:0')\n",
            "tensor([-1.5005], device='cuda:0')\n",
            "tensor([-1.8796], device='cuda:0')\n",
            "tensor([-1.1666], device='cuda:0')\n",
            "tensor([-1.3935], device='cuda:0')\n",
            "tensor([-0.9151], device='cuda:0')\n",
            "tensor([-1.0283], device='cuda:0')\n",
            "tensor([-0.7254], device='cuda:0')\n",
            "tensor([-0.7541], device='cuda:0')\n",
            "tensor([-0.5822], device='cuda:0')\n",
            "tensor([-0.5483], device='cuda:0')\n",
            "tensor([-0.4741], device='cuda:0')\n",
            "tensor([-0.3938], device='cuda:0')\n",
            "tensor([-0.3922], device='cuda:0')\n",
            "tensor([-0.2780], device='cuda:0')\n",
            "tensor([-0.3301], device='cuda:0')\n",
            "tensor([-0.1912], device='cuda:0')\n",
            "tensor([-0.2829], device='cuda:0')\n",
            "tensor([-0.1262], device='cuda:0')\n",
            "tensor([-0.2469], device='cuda:0')\n",
            "tensor([-0.0777], device='cuda:0')\n",
            "tensor([-0.2193], device='cuda:0')\n",
            "tensor([-0.0414], device='cuda:0')\n",
            "tensor([-0.1981], device='cuda:0')\n",
            "tensor([-0.0144], device='cuda:0')\n",
            "tensor([-0.1816], device='cuda:0')\n",
            "tensor([0.0056], device='cuda:0')\n",
            "tensor([-0.1687], device='cuda:0')\n",
            "tensor([0.0205], device='cuda:0')\n",
            "tensor([-0.1586], device='cuda:0')\n",
            "tensor([0.0313], device='cuda:0')\n",
            "tensor([-0.1505], device='cuda:0')\n",
            "tensor([0.0393], device='cuda:0')\n",
            "tensor([-0.1439], device='cuda:0')\n",
            "tensor([0.0450], device='cuda:0')\n",
            "tensor([-0.1385], device='cuda:0')\n",
            "tensor([0.0491], device='cuda:0')\n",
            "tensor([-0.1339], device='cuda:0')\n",
            "tensor([0.0519], device='cuda:0')\n",
            "tensor([-0.1301], device='cuda:0')\n",
            "tensor([0.0538], device='cuda:0')\n",
            "tensor([-0.1268], device='cuda:0')\n",
            "tensor([0.0551], device='cuda:0')\n",
            "tensor([-0.1238], device='cuda:0')\n",
            "tensor([0.0557], device='cuda:0')\n",
            "tensor([-0.1212], device='cuda:0')\n",
            "tensor([0.0560], device='cuda:0')\n",
            "tensor([-0.1187], device='cuda:0')\n",
            "tensor([0.0561], device='cuda:0')\n",
            "tensor([-0.1165], device='cuda:0')\n",
            "tensor([0.0559], device='cuda:0')\n",
            "tensor([-0.1144], device='cuda:0')\n",
            "tensor([0.0555], device='cuda:0')\n",
            "tensor([-0.1124], device='cuda:0')\n",
            "tensor([0.0550], device='cuda:0')\n",
            "tensor([-0.1106], device='cuda:0')\n",
            "tensor([0.0545], device='cuda:0')\n",
            "tensor([-0.1088], device='cuda:0')\n",
            "tensor([0.0538], device='cuda:0')\n",
            "tensor([-0.1070], device='cuda:0')\n",
            "tensor([0.0532], device='cuda:0')\n",
            "tensor([-0.1053], device='cuda:0')\n",
            "tensor([0.0525], device='cuda:0')\n",
            "tensor([-0.1037], device='cuda:0')\n",
            "tensor([0.0518], device='cuda:0')\n",
            "tensor([-0.1020], device='cuda:0')\n",
            "tensor([0.0511], device='cuda:0')\n",
            "tensor([-0.1005], device='cuda:0')\n",
            "tensor([0.0504], device='cuda:0')\n",
            "tensor([-0.0989], device='cuda:0')\n",
            "tensor([0.0496], device='cuda:0')\n",
            "tensor([-0.0974], device='cuda:0')\n",
            "tensor([0.0489], device='cuda:0')\n",
            "tensor([-0.0959], device='cuda:0')\n",
            "tensor([0.0482], device='cuda:0')\n",
            "tensor([-0.0945], device='cuda:0')\n",
            "tensor([0.0475], device='cuda:0')\n",
            "tensor([-0.0930], device='cuda:0')\n",
            "tensor([0.0468], device='cuda:0')\n",
            "tensor([-0.0916], device='cuda:0')\n",
            "tensor([0.0461], device='cuda:0')\n",
            "tensor([-0.0902], device='cuda:0')\n",
            "tensor([0.0454], device='cuda:0')\n",
            "tensor([-0.0889], device='cuda:0')\n",
            "tensor([0.0447], device='cuda:0')\n",
            "tensor([-0.0875], device='cuda:0')\n",
            "tensor([0.0440], device='cuda:0')\n",
            "tensor([-0.0862], device='cuda:0')\n",
            "tensor([0.0434], device='cuda:0')\n",
            "tensor([-0.0849], device='cuda:0')\n",
            "tensor([0.0427], device='cuda:0')\n",
            "tensor([-0.0836], device='cuda:0')\n",
            "tensor([0.0421], device='cuda:0')\n",
            "tensor([-0.0823], device='cuda:0')\n",
            "tensor([0.0414], device='cuda:0')\n",
            "tensor([-0.0811], device='cuda:0')\n",
            "tensor([0.0408], device='cuda:0')\n",
            "tensor([-0.0799], device='cuda:0')\n",
            "tensor([0.0402], device='cuda:0')\n",
            "tensor([-0.0787], device='cuda:0')\n",
            "tensor([0.0396], device='cuda:0')\n",
            "tensor([-0.0775], device='cuda:0')\n",
            "tensor([0.0390], device='cuda:0')\n",
            "tensor([-0.0763], device='cuda:0')\n",
            "tensor([0.0384], device='cuda:0')\n",
            "tensor([-0.0752], device='cuda:0')\n",
            "tensor([0.0378], device='cuda:0')\n",
            "tensor([-0.0740], device='cuda:0')\n",
            "tensor([0.0373], device='cuda:0')\n",
            "tensor([-0.0729], device='cuda:0')\n",
            "tensor([0.0367], device='cuda:0')\n",
            "tensor([-0.0718], device='cuda:0')\n",
            "tensor([0.0361], device='cuda:0')\n",
            "tensor([-0.0707], device='cuda:0')\n",
            "tensor([0.0356], device='cuda:0')\n",
            "tensor([-0.0696], device='cuda:0')\n",
            "tensor([0.0351], device='cuda:0')\n",
            "tensor([-0.0686], device='cuda:0')\n",
            "tensor([0.0345], device='cuda:0')\n",
            "tensor([-0.0676], device='cuda:0')\n",
            "tensor([0.0340], device='cuda:0')\n",
            "tensor([-0.0665], device='cuda:0')\n",
            "tensor([0.0335], device='cuda:0')\n",
            "tensor([-0.0655], device='cuda:0')\n",
            "tensor([0.0330], device='cuda:0')\n",
            "tensor([-0.0645], device='cuda:0')\n",
            "tensor([0.0325], device='cuda:0')\n",
            "tensor([-0.0636], device='cuda:0')\n",
            "tensor([0.0320], device='cuda:0')\n",
            "tensor([-0.0626], device='cuda:0')\n",
            "tensor([0.0315], device='cuda:0')\n",
            "tensor([-0.0617], device='cuda:0')\n",
            "tensor([0.0310], device='cuda:0')\n",
            "tensor([-0.0607], device='cuda:0')\n",
            "tensor([0.0306], device='cuda:0')\n",
            "tensor([-0.0598], device='cuda:0')\n",
            "tensor([0.0301], device='cuda:0')\n",
            "tensor([-0.0589], device='cuda:0')\n",
            "tensor([0.0297], device='cuda:0')\n",
            "tensor([-0.0580], device='cuda:0')\n",
            "tensor([0.0292], device='cuda:0')\n",
            "tensor([-0.0571], device='cuda:0')\n",
            "tensor([0.0288], device='cuda:0')\n",
            "tensor([-0.0563], device='cuda:0')\n",
            "tensor([0.0283], device='cuda:0')\n",
            "tensor([-0.0554], device='cuda:0')\n",
            "tensor([0.0279], device='cuda:0')\n",
            "tensor([-0.0546], device='cuda:0')\n",
            "tensor([0.0275], device='cuda:0')\n",
            "tensor([-0.0538], device='cuda:0')\n",
            "tensor([0.0271], device='cuda:0')\n",
            "tensor([-0.0530], device='cuda:0')\n",
            "tensor([0.0267], device='cuda:0')\n",
            "tensor([-0.0522], device='cuda:0')\n",
            "tensor([0.0263], device='cuda:0')\n",
            "tensor([-0.0514], device='cuda:0')\n",
            "tensor([0.0259], device='cuda:0')\n",
            "tensor([-0.0506], device='cuda:0')\n",
            "tensor([0.0255], device='cuda:0')\n",
            "tensor([-0.0498], device='cuda:0')\n",
            "tensor([0.0251], device='cuda:0')\n",
            "tensor([-0.0491], device='cuda:0')\n",
            "tensor([0.0247], device='cuda:0')\n",
            "tensor([-0.0483], device='cuda:0')\n",
            "tensor([0.0243], device='cuda:0')\n",
            "tensor([-0.0476], device='cuda:0')\n",
            "tensor([0.0240], device='cuda:0')\n",
            "tensor([-0.0469], device='cuda:0')\n",
            "tensor([0.0236], device='cuda:0')\n",
            "tensor([-0.0462], device='cuda:0')\n",
            "tensor([0.0232], device='cuda:0')\n",
            "tensor([-0.0455], device='cuda:0')\n",
            "tensor([0.0229], device='cuda:0')\n",
            "tensor([-0.0448], device='cuda:0')\n",
            "tensor([0.0225], device='cuda:0')\n",
            "tensor([-0.0441], device='cuda:0')\n",
            "tensor([0.0222], device='cuda:0')\n",
            "tensor([-0.0434], device='cuda:0')\n",
            "tensor([0.0219], device='cuda:0')\n",
            "tensor([-0.0428], device='cuda:0')\n",
            "tensor([0.0215], device='cuda:0')\n",
            "tensor([-0.0421], device='cuda:0')\n",
            "tensor([0.0212], device='cuda:0')\n",
            "tensor([-0.0415], device='cuda:0')\n",
            "tensor([0.0209], device='cuda:0')\n",
            "tensor([-0.0409], device='cuda:0')\n",
            "tensor([0.0206], device='cuda:0')\n",
            "tensor([-0.0403], device='cuda:0')\n",
            "tensor([0.0203], device='cuda:0')\n",
            "tensor([-0.0397], device='cuda:0')\n",
            "tensor([0.0200], device='cuda:0')\n",
            "tensor([-0.0391], device='cuda:0')\n",
            "tensor([0.0197], device='cuda:0')\n",
            "tensor([-0.0385], device='cuda:0')\n",
            "tensor([0.0194], device='cuda:0')\n",
            "tensor([-0.0379], device='cuda:0')\n",
            "tensor([0.0191], device='cuda:0')\n",
            "tensor([-0.0373], device='cuda:0')\n",
            "tensor([0.0188], device='cuda:0')\n",
            "tensor([-0.0367], device='cuda:0')\n",
            "tensor([0.0185], device='cuda:0')\n",
            "tensor([-0.0362], device='cuda:0')\n",
            "tensor([0.0182], device='cuda:0')\n",
            "tensor([-0.0356], device='cuda:0')\n",
            "tensor([0.0179], device='cuda:0')\n",
            "tensor([-0.0351], device='cuda:0')\n",
            "tensor([0.0177], device='cuda:0')\n",
            "tensor([-0.0346], device='cuda:0')\n",
            "tensor([0.0174], device='cuda:0')\n",
            "tensor([-0.0341], device='cuda:0')\n",
            "tensor([0.0171], device='cuda:0')\n",
            "tensor([-0.0335], device='cuda:0')\n",
            "tensor([0.0169], device='cuda:0')\n",
            "tensor([-0.0330], device='cuda:0')\n",
            "tensor([0.0166], device='cuda:0')\n",
            "tensor([-0.0325], device='cuda:0')\n",
            "tensor([0.0164], device='cuda:0')\n",
            "tensor([-0.0320], device='cuda:0')\n",
            "tensor([0.0161], device='cuda:0')\n",
            "tensor([-0.0316], device='cuda:0')\n",
            "tensor([0.0159], device='cuda:0')\n",
            "tensor([-0.0311], device='cuda:0')\n",
            "tensor([0.0156], device='cuda:0')\n",
            "tensor([-0.0306], device='cuda:0')\n",
            "tensor([0.0154], device='cuda:0')\n",
            "tensor([-0.0302], device='cuda:0')\n",
            "tensor([0.0152], device='cuda:0')\n",
            "tensor([-0.0297], device='cuda:0')\n",
            "tensor([0.0149], device='cuda:0')\n",
            "tensor([-0.0292], device='cuda:0')\n",
            "tensor([0.0147], device='cuda:0')\n",
            "tensor([-0.0288], device='cuda:0')\n",
            "tensor([0.0145], device='cuda:0')\n",
            "tensor([-0.0284], device='cuda:0')\n",
            "tensor([0.0143], device='cuda:0')\n",
            "tensor([-0.0279], device='cuda:0')\n",
            "tensor([0.0141], device='cuda:0')\n",
            "tensor([-0.0275], device='cuda:0')\n",
            "tensor([0.0139], device='cuda:0')\n",
            "tensor([-0.0271], device='cuda:0')\n",
            "tensor([0.0136], device='cuda:0')\n",
            "tensor([-0.0267], device='cuda:0')\n",
            "tensor([0.0134], device='cuda:0')\n",
            "tensor([-0.0263], device='cuda:0')\n",
            "tensor([0.0132], device='cuda:0')\n",
            "tensor([-0.0259], device='cuda:0')\n",
            "tensor([0.0130], device='cuda:0')\n",
            "tensor([-0.0255], device='cuda:0')\n",
            "tensor([0.0128], device='cuda:0')\n",
            "tensor([-0.0251], device='cuda:0')\n",
            "tensor([0.0126], device='cuda:0')\n",
            "tensor([-0.0247], device='cuda:0')\n",
            "tensor([0.0125], device='cuda:0')\n",
            "tensor([-0.0244], device='cuda:0')\n",
            "tensor([0.0123], device='cuda:0')\n",
            "tensor([-0.0240], device='cuda:0')\n",
            "tensor([0.0121], device='cuda:0')\n",
            "tensor([-0.0236], device='cuda:0')\n",
            "tensor([0.0119], device='cuda:0')\n",
            "tensor([-0.0233], device='cuda:0')\n",
            "tensor([0.0117], device='cuda:0')\n",
            "tensor([-0.0229], device='cuda:0')\n",
            "tensor([0.0115], device='cuda:0')\n",
            "tensor([-0.0226], device='cuda:0')\n",
            "tensor([0.0114], device='cuda:0')\n",
            "tensor([-0.0222], device='cuda:0')\n",
            "tensor([0.0112], device='cuda:0')\n",
            "tensor([-0.0219], device='cuda:0')\n",
            "tensor([0.0110], device='cuda:0')\n",
            "tensor([-0.0216], device='cuda:0')\n",
            "tensor([0.0109], device='cuda:0')\n",
            "tensor([-0.0212], device='cuda:0')\n",
            "tensor([0.0107], device='cuda:0')\n",
            "tensor([-0.0209], device='cuda:0')\n",
            "tensor([0.0105], device='cuda:0')\n",
            "tensor([-0.0206], device='cuda:0')\n",
            "tensor([0.0104], device='cuda:0')\n",
            "tensor([-0.0203], device='cuda:0')\n",
            "tensor([0.0102], device='cuda:0')\n",
            "tensor([-0.0200], device='cuda:0')\n",
            "tensor([0.0101], device='cuda:0')\n",
            "tensor([-0.0197], device='cuda:0')\n",
            "tensor([0.0099], device='cuda:0')\n",
            "tensor([-0.0194], device='cuda:0')\n",
            "tensor([0.0098], device='cuda:0')\n",
            "tensor([-0.0191], device='cuda:0')\n",
            "tensor([0.0096], device='cuda:0')\n",
            "tensor([-0.0188], device='cuda:0')\n",
            "tensor([0.0095], device='cuda:0')\n",
            "tensor([-0.0185], device='cuda:0')\n",
            "tensor([0.0093], device='cuda:0')\n",
            "tensor([-0.0182], device='cuda:0')\n",
            "tensor([0.0092], device='cuda:0')\n",
            "tensor([-0.0180], device='cuda:0')\n",
            "tensor([0.0090], device='cuda:0')\n",
            "tensor([-0.0177], device='cuda:0')\n",
            "tensor([0.0089], device='cuda:0')\n",
            "tensor([-0.0174], device='cuda:0')\n",
            "tensor([0.0088], device='cuda:0')\n",
            "tensor([-0.0172], device='cuda:0')\n",
            "tensor([0.0086], device='cuda:0')\n",
            "tensor([-0.0169], device='cuda:0')\n",
            "tensor([0.0085], device='cuda:0')\n",
            "tensor([-0.0167], device='cuda:0')\n",
            "tensor([0.0084], device='cuda:0')\n",
            "tensor([-0.0164], device='cuda:0')\n",
            "tensor([0.0083], device='cuda:0')\n",
            "tensor([-0.0162], device='cuda:0')\n",
            "tensor([0.0081], device='cuda:0')\n",
            "tensor([-0.0159], device='cuda:0')\n",
            "tensor([0.0080], device='cuda:0')\n",
            "tensor([-0.0157], device='cuda:0')\n",
            "tensor([0.0079], device='cuda:0')\n",
            "tensor([-0.0154], device='cuda:0')\n",
            "tensor([0.0078], device='cuda:0')\n",
            "tensor([-0.0152], device='cuda:0')\n",
            "tensor([0.0077], device='cuda:0')\n",
            "tensor([-0.0150], device='cuda:0')\n",
            "tensor([0.0075], device='cuda:0')\n",
            "tensor([-0.0147], device='cuda:0')\n",
            "tensor([0.0074], device='cuda:0')\n",
            "tensor([-0.0145], device='cuda:0')\n",
            "tensor([0.0073], device='cuda:0')\n",
            "tensor([-0.0143], device='cuda:0')\n",
            "tensor([0.0072], device='cuda:0')\n",
            "tensor([-0.0141], device='cuda:0')\n",
            "tensor([0.0071], device='cuda:0')\n",
            "tensor([-0.0139], device='cuda:0')\n",
            "tensor([0.0070], device='cuda:0')\n",
            "tensor([-0.0137], device='cuda:0')\n",
            "tensor([0.0069], device='cuda:0')\n",
            "tensor([-0.0135], device='cuda:0')\n",
            "tensor([0.0068], device='cuda:0')\n",
            "tensor([-0.0133], device='cuda:0')\n",
            "tensor([0.0067], device='cuda:0')\n",
            "tensor([-0.0131], device='cuda:0')\n",
            "tensor([0.0066], device='cuda:0')\n",
            "tensor([-0.0129], device='cuda:0')\n",
            "tensor([0.0065], device='cuda:0')\n",
            "tensor([-0.0127], device='cuda:0')\n",
            "tensor([0.0064], device='cuda:0')\n",
            "tensor([-0.0125], device='cuda:0')\n",
            "tensor([0.0063], device='cuda:0')\n",
            "tensor([-0.0123], device='cuda:0')\n",
            "tensor([0.0062], device='cuda:0')\n",
            "tensor([-0.0121], device='cuda:0')\n",
            "tensor([0.0061], device='cuda:0')\n",
            "tensor([-0.0119], device='cuda:0')\n",
            "tensor([0.0060], device='cuda:0')\n",
            "tensor([-0.0117], device='cuda:0')\n",
            "tensor([0.0059], device='cuda:0')\n",
            "tensor([-0.0116], device='cuda:0')\n",
            "tensor([0.0058], device='cuda:0')\n",
            "tensor([-0.0114], device='cuda:0')\n",
            "tensor([0.0057], device='cuda:0')\n",
            "tensor([-0.0112], device='cuda:0')\n",
            "tensor([0.0056], device='cuda:0')\n",
            "tensor([-0.0110], device='cuda:0')\n",
            "tensor([0.0056], device='cuda:0')\n",
            "tensor([-0.0109], device='cuda:0')\n",
            "tensor([0.0055], device='cuda:0')\n",
            "tensor([-0.0107], device='cuda:0')\n",
            "tensor([0.0054], device='cuda:0')\n",
            "tensor([-0.0105], device='cuda:0')\n",
            "tensor([0.0053], device='cuda:0')\n",
            "tensor([-0.0104], device='cuda:0')\n",
            "tensor([0.0052], device='cuda:0')\n",
            "tensor([-0.0102], device='cuda:0')\n",
            "tensor([0.0051], device='cuda:0')\n",
            "tensor([-0.0101], device='cuda:0')\n",
            "tensor([0.0051], device='cuda:0')\n",
            "tensor([-0.0099], device='cuda:0')\n",
            "tensor([0.0050], device='cuda:0')\n",
            "tensor([-0.0098], device='cuda:0')\n",
            "tensor([0.0049], device='cuda:0')\n",
            "tensor([-0.0096], device='cuda:0')\n",
            "tensor([0.0048], device='cuda:0')\n",
            "tensor([-0.0095], device='cuda:0')\n",
            "tensor([0.0048], device='cuda:0')\n",
            "tensor([-0.0093], device='cuda:0')\n",
            "tensor([0.0047], device='cuda:0')\n",
            "tensor([-0.0092], device='cuda:0')\n",
            "tensor([0.0046], device='cuda:0')\n",
            "tensor([-0.0091], device='cuda:0')\n",
            "tensor([0.0046], device='cuda:0')\n",
            "tensor([-0.0089], device='cuda:0')\n",
            "tensor([0.0045], device='cuda:0')\n",
            "tensor([-0.0088], device='cuda:0')\n",
            "tensor([0.0044], device='cuda:0')\n",
            "tensor([-0.0087], device='cuda:0')\n",
            "tensor([0.0044], device='cuda:0')\n",
            "tensor([-0.0085], device='cuda:0')\n",
            "tensor([0.0043], device='cuda:0')\n",
            "tensor([-0.0084], device='cuda:0')\n",
            "tensor([0.0042], device='cuda:0')\n",
            "tensor([-0.0083], device='cuda:0')\n",
            "tensor([0.0042], device='cuda:0')\n",
            "tensor([-0.0081], device='cuda:0')\n",
            "tensor([0.0041], device='cuda:0')\n",
            "tensor([-0.0080], device='cuda:0')\n",
            "tensor([0.0040], device='cuda:0')\n",
            "tensor([-0.0079], device='cuda:0')\n",
            "tensor([0.0040], device='cuda:0')\n",
            "tensor([-0.0078], device='cuda:0')\n",
            "tensor([0.0039], device='cuda:0')\n",
            "tensor([-0.0077], device='cuda:0')\n",
            "tensor([0.0039], device='cuda:0')\n",
            "tensor([-0.0075], device='cuda:0')\n",
            "tensor([0.0038], device='cuda:0')\n",
            "tensor([-0.0074], device='cuda:0')\n",
            "tensor([0.0037], device='cuda:0')\n",
            "tensor([-0.0073], device='cuda:0')\n",
            "tensor([0.0037], device='cuda:0')\n",
            "tensor([-0.0072], device='cuda:0')\n",
            "tensor([0.0036], device='cuda:0')\n",
            "tensor([-0.0071], device='cuda:0')\n",
            "tensor([0.0036], device='cuda:0')\n",
            "tensor([-0.0070], device='cuda:0')\n",
            "tensor([0.0035], device='cuda:0')\n",
            "tensor([-0.0069], device='cuda:0')\n",
            "tensor([0.0035], device='cuda:0')\n",
            "tensor([-0.0068], device='cuda:0')\n",
            "tensor([0.0034], device='cuda:0')\n",
            "tensor([-0.0067], device='cuda:0')\n",
            "tensor([0.0034], device='cuda:0')\n",
            "tensor([-0.0066], device='cuda:0')\n",
            "tensor([0.0033], device='cuda:0')\n",
            "tensor([-0.0065], device='cuda:0')\n",
            "tensor([0.0033], device='cuda:0')\n",
            "tensor([-0.0064], device='cuda:0')\n",
            "tensor([0.0032], device='cuda:0')\n",
            "tensor([-0.0063], device='cuda:0')\n",
            "tensor([0.0032], device='cuda:0')\n",
            "tensor([-0.0062], device='cuda:0')\n",
            "tensor([0.0031], device='cuda:0')\n",
            "tensor([-0.0061], device='cuda:0')\n",
            "tensor([0.0031], device='cuda:0')\n",
            "tensor([-0.0060], device='cuda:0')\n",
            "tensor([0.0030], device='cuda:0')\n",
            "tensor([-0.0059], device='cuda:0')\n",
            "tensor([0.0030], device='cuda:0')\n",
            "tensor([-0.0058], device='cuda:0')\n",
            "tensor([0.0029], device='cuda:0')\n",
            "tensor([-0.0057], device='cuda:0')\n",
            "tensor([0.0029], device='cuda:0')\n",
            "tensor([-0.0057], device='cuda:0')\n",
            "tensor([0.0028], device='cuda:0')\n",
            "tensor([-0.0056], device='cuda:0')\n",
            "tensor([0.0028], device='cuda:0')\n",
            "tensor([-0.0055], device='cuda:0')\n",
            "tensor([0.0028], device='cuda:0')\n",
            "tensor([-0.0054], device='cuda:0')\n",
            "tensor([0.0027], device='cuda:0')\n",
            "tensor([-0.0053], device='cuda:0')\n",
            "tensor([0.0027], device='cuda:0')\n",
            "tensor([-0.0052], device='cuda:0')\n",
            "tensor([0.0026], device='cuda:0')\n",
            "tensor([-0.0052], device='cuda:0')\n",
            "tensor([0.0026], device='cuda:0')\n",
            "tensor([-0.0051], device='cuda:0')\n",
            "tensor([0.0026], device='cuda:0')\n",
            "tensor([-0.0050], device='cuda:0')\n",
            "tensor([0.0025], device='cuda:0')\n",
            "tensor([-0.0049], device='cuda:0')\n",
            "tensor([0.0025], device='cuda:0')\n",
            "tensor([-0.0049], device='cuda:0')\n",
            "tensor([0.0024], device='cuda:0')\n",
            "tensor([-0.0048], device='cuda:0')\n",
            "tensor([0.0024], device='cuda:0')\n",
            "tensor([-0.0047], device='cuda:0')\n",
            "tensor([0.0024], device='cuda:0')\n",
            "tensor([-0.0046], device='cuda:0')\n",
            "tensor([0.0023], device='cuda:0')\n",
            "tensor([-0.0046], device='cuda:0')\n",
            "tensor([0.0023], device='cuda:0')\n",
            "tensor([-0.0045], device='cuda:0')\n",
            "tensor([0.0023], device='cuda:0')\n",
            "tensor([-0.0044], device='cuda:0')\n",
            "tensor([0.0022], device='cuda:0')\n",
            "tensor([-0.0044], device='cuda:0')\n",
            "tensor([0.0022], device='cuda:0')\n",
            "tensor([-0.0043], device='cuda:0')\n",
            "tensor([0.0022], device='cuda:0')\n",
            "tensor([-0.0042], device='cuda:0')\n",
            "tensor([0.0021], device='cuda:0')\n",
            "tensor([-0.0042], device='cuda:0')\n",
            "tensor([0.0021], device='cuda:0')\n",
            "tensor([-0.0041], device='cuda:0')\n",
            "tensor([0.0021], device='cuda:0')\n",
            "tensor([-0.0040], device='cuda:0')\n",
            "tensor([0.0020], device='cuda:0')\n",
            "tensor([-0.0040], device='cuda:0')\n",
            "tensor([0.0020], device='cuda:0')\n",
            "tensor([-0.0039], device='cuda:0')\n",
            "tensor([0.0020], device='cuda:0')\n",
            "tensor([-0.0039], device='cuda:0')\n",
            "tensor([0.0019], device='cuda:0')\n",
            "tensor([-0.0038], device='cuda:0')\n",
            "tensor([0.0019], device='cuda:0')\n",
            "tensor([-0.0037], device='cuda:0')\n",
            "tensor([0.0019], device='cuda:0')\n",
            "tensor([-0.0037], device='cuda:0')\n",
            "tensor([0.0019], device='cuda:0')\n",
            "tensor([-0.0036], device='cuda:0')\n",
            "tensor([0.0018], device='cuda:0')\n",
            "tensor([-0.0036], device='cuda:0')\n",
            "tensor([0.0018], device='cuda:0')\n",
            "tensor([-0.0035], device='cuda:0')\n",
            "tensor([0.0018], device='cuda:0')\n",
            "tensor([-0.0035], device='cuda:0')\n",
            "tensor([0.0017], device='cuda:0')\n",
            "tensor([-0.0034], device='cuda:0')\n",
            "tensor([0.0017], device='cuda:0')\n",
            "tensor([-0.0034], device='cuda:0')\n",
            "tensor([0.0017], device='cuda:0')\n",
            "tensor([-0.0033], device='cuda:0')\n",
            "tensor([0.0017], device='cuda:0')\n",
            "tensor([-0.0033], device='cuda:0')\n",
            "tensor([0.0016], device='cuda:0')\n",
            "tensor([-0.0032], device='cuda:0')\n",
            "tensor([0.0016], device='cuda:0')\n",
            "tensor([-0.0032], device='cuda:0')\n",
            "tensor([0.0016], device='cuda:0')\n",
            "tensor([-0.0031], device='cuda:0')\n",
            "tensor([0.0016], device='cuda:0')\n",
            "tensor([-0.0031], device='cuda:0')\n",
            "tensor([0.0015], device='cuda:0')\n",
            "tensor([-0.0030], device='cuda:0')\n",
            "tensor([0.0015], device='cuda:0')\n",
            "tensor([-0.0030], device='cuda:0')\n",
            "tensor([0.0015], device='cuda:0')\n",
            "tensor([-0.0029], device='cuda:0')\n",
            "tensor([0.0015], device='cuda:0')\n",
            "tensor([-0.0029], device='cuda:0')\n",
            "tensor([0.0015], device='cuda:0')\n",
            "tensor([-0.0028], device='cuda:0')\n",
            "tensor([0.0014], device='cuda:0')\n",
            "tensor([-0.0028], device='cuda:0')\n",
            "tensor([0.0014], device='cuda:0')\n",
            "tensor([-0.0028], device='cuda:0')\n",
            "tensor([0.0014], device='cuda:0')\n",
            "tensor([-0.0027], device='cuda:0')\n",
            "tensor([0.0014], device='cuda:0')\n",
            "tensor([-0.0027], device='cuda:0')\n",
            "tensor([0.0013], device='cuda:0')\n",
            "tensor([-0.0026], device='cuda:0')\n",
            "tensor([0.0013], device='cuda:0')\n",
            "tensor([-0.0026], device='cuda:0')\n",
            "tensor([0.0013], device='cuda:0')\n",
            "tensor([-0.0026], device='cuda:0')\n",
            "tensor([0.0013], device='cuda:0')\n",
            "tensor([-0.0025], device='cuda:0')\n",
            "tensor([0.0013], device='cuda:0')\n",
            "tensor([-0.0025], device='cuda:0')\n",
            "tensor([0.0013], device='cuda:0')\n",
            "tensor([-0.0024], device='cuda:0')\n",
            "tensor([0.0012], device='cuda:0')\n",
            "tensor([-0.0024], device='cuda:0')\n",
            "tensor([0.0012], device='cuda:0')\n",
            "tensor([-0.0024], device='cuda:0')\n",
            "tensor([0.0012], device='cuda:0')\n",
            "tensor([-0.0023], device='cuda:0')\n",
            "tensor([0.0012], device='cuda:0')\n",
            "tensor([-0.0023], device='cuda:0')\n",
            "tensor([0.0012], device='cuda:0')\n",
            "tensor([-0.0023], device='cuda:0')\n",
            "tensor([0.0011], device='cuda:0')\n",
            "tensor([-0.0022], device='cuda:0')\n",
            "tensor([0.0011], device='cuda:0')\n",
            "tensor([-0.0022], device='cuda:0')\n",
            "tensor([0.0011], device='cuda:0')\n",
            "tensor([-0.0022], device='cuda:0')\n",
            "tensor([0.0011], device='cuda:0')\n",
            "tensor([-0.0021], device='cuda:0')\n",
            "tensor([0.0011], device='cuda:0')\n",
            "tensor([-0.0021], device='cuda:0')\n",
            "tensor([0.0011], device='cuda:0')\n",
            "tensor([-0.0021], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0020], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0020], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0020], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0019], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0019], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0019], device='cuda:0')\n",
            "tensor([0.0010], device='cuda:0')\n",
            "tensor([-0.0019], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0018], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0018], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0018], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0018], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0017], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0017], device='cuda:0')\n",
            "tensor([0.0009], device='cuda:0')\n",
            "tensor([-0.0017], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0016], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0016], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0016], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0016], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0015], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0015], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0015], device='cuda:0')\n",
            "tensor([0.0008], device='cuda:0')\n",
            "tensor([-0.0015], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0015], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0014], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0014], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0014], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0014], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0014], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0013], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0013], device='cuda:0')\n",
            "tensor([0.0007], device='cuda:0')\n",
            "tensor([-0.0013], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0013], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0013], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0012], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0012], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0012], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0012], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0012], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0011], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0011], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0011], device='cuda:0')\n",
            "tensor([0.0006], device='cuda:0')\n",
            "tensor([-0.0011], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0011], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0011], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0010], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0005], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0009], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0008], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0004], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0007], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0006], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0003], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0005], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0004], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0002], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0003], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([0.0001], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.9956e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.8363e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.6746e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.5335e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.3935e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.2434e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([9.0968e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.9746e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.8437e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.7133e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.5840e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.4552e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.3250e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.2023e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([8.0670e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([7.9434e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([7.8199e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([7.7009e-05], device='cuda:0')\n",
            "tensor([-0.0002], device='cuda:0')\n",
            "tensor([7.5817e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([7.4610e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([7.3466e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([7.2315e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([7.1194e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([7.0065e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.9061e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.8083e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.7089e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.6130e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.5297e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.4231e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.3159e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.2273e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.1347e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([6.0582e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.9600e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.8705e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.7837e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.6868e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.5869e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.5023e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.4283e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.3387e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.2570e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.1876e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.0930e-05], device='cuda:0')\n",
            "tensor([-0.0001], device='cuda:0')\n",
            "tensor([5.0169e-05], device='cuda:0')\n",
            "tensor([-9.8547e-05], device='cuda:0')\n",
            "tensor([4.9502e-05], device='cuda:0')\n",
            "tensor([-9.7011e-05], device='cuda:0')\n",
            "tensor([4.8589e-05], device='cuda:0')\n",
            "tensor([-9.5634e-05], device='cuda:0')\n",
            "tensor([4.7834e-05], device='cuda:0')\n",
            "tensor([-9.4200e-05], device='cuda:0')\n",
            "tensor([4.7192e-05], device='cuda:0')\n",
            "tensor([-9.2740e-05], device='cuda:0')\n",
            "tensor([4.6455e-05], device='cuda:0')\n",
            "tensor([-9.1340e-05], device='cuda:0')\n",
            "tensor([4.5818e-05], device='cuda:0')\n",
            "tensor([-8.9926e-05], device='cuda:0')\n",
            "tensor([4.5237e-05], device='cuda:0')\n",
            "tensor([-8.8515e-05], device='cuda:0')\n",
            "tensor([4.4490e-05], device='cuda:0')\n",
            "tensor([-8.7216e-05], device='cuda:0')\n",
            "tensor([4.3891e-05], device='cuda:0')\n",
            "tensor([-8.5865e-05], device='cuda:0')\n",
            "tensor([4.3168e-05], device='cuda:0')\n",
            "tensor([-8.4602e-05], device='cuda:0')\n",
            "tensor([4.2574e-05], device='cuda:0')\n",
            "tensor([-8.3295e-05], device='cuda:0')\n",
            "tensor([4.1888e-05], device='cuda:0')\n",
            "tensor([-8.2054e-05], device='cuda:0')\n",
            "tensor([4.1321e-05], device='cuda:0')\n",
            "tensor([-8.0774e-05], device='cuda:0')\n",
            "tensor([4.0635e-05], device='cuda:0')\n",
            "tensor([-7.9584e-05], device='cuda:0')\n",
            "tensor([4.0067e-05], device='cuda:0')\n",
            "tensor([-7.8353e-05], device='cuda:0')\n",
            "tensor([3.9421e-05], device='cuda:0')\n",
            "tensor([-7.7181e-05], device='cuda:0')\n",
            "tensor([3.8869e-05], device='cuda:0')\n",
            "tensor([-7.5986e-05], device='cuda:0')\n",
            "tensor([3.8201e-05], device='cuda:0')\n",
            "tensor([-7.4878e-05], device='cuda:0')\n",
            "tensor([3.7690e-05], device='cuda:0')\n",
            "tensor([-7.3698e-05], device='cuda:0')\n",
            "tensor([3.7032e-05], device='cuda:0')\n",
            "tensor([-7.2627e-05], device='cuda:0')\n",
            "tensor([3.6519e-05], device='cuda:0')\n",
            "tensor([-7.1515e-05], device='cuda:0')\n",
            "tensor([3.5852e-05], device='cuda:0')\n",
            "tensor([-7.0485e-05], device='cuda:0')\n",
            "tensor([3.5357e-05], device='cuda:0')\n",
            "tensor([-6.9396e-05], device='cuda:0')\n",
            "tensor([3.4759e-05], device='cuda:0')\n",
            "tensor([-6.8387e-05], device='cuda:0')\n",
            "tensor([3.4215e-05], device='cuda:0')\n",
            "tensor([-6.7374e-05], device='cuda:0')\n",
            "tensor([3.3793e-05], device='cuda:0')\n",
            "tensor([-6.6286e-05], device='cuda:0')\n",
            "tensor([3.3415e-05], device='cuda:0')\n",
            "tensor([-6.5217e-05], device='cuda:0')\n",
            "tensor([3.2903e-05], device='cuda:0')\n",
            "tensor([-6.4227e-05], device='cuda:0')\n",
            "tensor([3.2310e-05], device='cuda:0')\n",
            "tensor([-6.3300e-05], device='cuda:0')\n",
            "tensor([3.1865e-05], device='cuda:0')\n",
            "tensor([-6.2323e-05], device='cuda:0')\n",
            "tensor([3.1293e-05], device='cuda:0')\n",
            "tensor([-6.1436e-05], device='cuda:0')\n",
            "tensor([3.0906e-05], device='cuda:0')\n",
            "tensor([-6.0462e-05], device='cuda:0')\n",
            "tensor([3.0484e-05], device='cuda:0')\n",
            "tensor([-5.9514e-05], device='cuda:0')\n",
            "tensor([2.9916e-05], device='cuda:0')\n",
            "tensor([-5.8667e-05], device='cuda:0')\n",
            "tensor([2.9469e-05], device='cuda:0')\n",
            "tensor([-5.7781e-05], device='cuda:0')\n",
            "tensor([2.8909e-05], device='cuda:0')\n",
            "tensor([-5.6971e-05], device='cuda:0')\n",
            "tensor([2.8582e-05], device='cuda:0')\n",
            "tensor([-5.6057e-05], device='cuda:0')\n",
            "tensor([2.8132e-05], device='cuda:0')\n",
            "tensor([-5.5226e-05], device='cuda:0')\n",
            "tensor([2.7623e-05], device='cuda:0')\n",
            "tensor([-5.4429e-05], device='cuda:0')\n",
            "tensor([2.7330e-05], device='cuda:0')\n",
            "tensor([-5.3543e-05], device='cuda:0')\n",
            "tensor([2.6908e-05], device='cuda:0')\n",
            "tensor([-5.2735e-05], device='cuda:0')\n",
            "tensor([2.6417e-05], device='cuda:0')\n",
            "tensor([-5.1972e-05], device='cuda:0')\n",
            "tensor([2.6084e-05], device='cuda:0')\n",
            "tensor([-5.1157e-05], device='cuda:0')\n",
            "tensor([2.5687e-05], device='cuda:0')\n",
            "tensor([-5.0378e-05], device='cuda:0')\n",
            "tensor([2.5200e-05], device='cuda:0')\n",
            "tensor([-4.9672e-05], device='cuda:0')\n",
            "tensor([2.4891e-05], device='cuda:0')\n",
            "tensor([-4.8881e-05], device='cuda:0')\n",
            "tensor([2.4524e-05], device='cuda:0')\n",
            "tensor([-4.8139e-05], device='cuda:0')\n",
            "tensor([2.4014e-05], device='cuda:0')\n",
            "tensor([-4.7486e-05], device='cuda:0')\n",
            "tensor([2.3760e-05], device='cuda:0')\n",
            "tensor([-4.6708e-05], device='cuda:0')\n",
            "tensor([2.3380e-05], device='cuda:0')\n",
            "tensor([-4.6015e-05], device='cuda:0')\n",
            "tensor([2.3023e-05], device='cuda:0')\n",
            "tensor([-4.5311e-05], device='cuda:0')\n",
            "tensor([2.2780e-05], device='cuda:0')\n",
            "tensor([-4.4573e-05], device='cuda:0')\n",
            "tensor([2.2422e-05], device='cuda:0')\n",
            "tensor([-4.3913e-05], device='cuda:0')\n",
            "tensor([2.2026e-05], device='cuda:0')\n",
            "tensor([-4.3276e-05], device='cuda:0')\n",
            "tensor([2.1787e-05], device='cuda:0')\n",
            "tensor([-4.2586e-05], device='cuda:0')\n",
            "tensor([2.1523e-05], device='cuda:0')\n",
            "tensor([-4.1913e-05], device='cuda:0')\n",
            "tensor([2.1241e-05], device='cuda:0')\n",
            "tensor([-4.1248e-05], device='cuda:0')\n",
            "tensor([2.0909e-05], device='cuda:0')\n",
            "tensor([-4.0620e-05], device='cuda:0')\n",
            "tensor([2.0402e-05], device='cuda:0')\n",
            "tensor([-4.0107e-05], device='cuda:0')\n",
            "tensor([2.0184e-05], device='cuda:0')\n",
            "tensor([-3.9445e-05], device='cuda:0')\n",
            "tensor([1.9832e-05], device='cuda:0')\n",
            "tensor([-3.8888e-05], device='cuda:0')\n",
            "tensor([1.9510e-05], device='cuda:0')\n",
            "tensor([-3.8284e-05], device='cuda:0')\n",
            "tensor([1.9295e-05], device='cuda:0')\n",
            "tensor([-3.7682e-05], device='cuda:0')\n",
            "tensor([1.9086e-05], device='cuda:0')\n",
            "tensor([-3.7067e-05], device='cuda:0')\n",
            "tensor([1.8766e-05], device='cuda:0')\n",
            "tensor([-3.6524e-05], device='cuda:0')\n",
            "tensor([1.8439e-05], device='cuda:0')\n",
            "tensor([-3.5983e-05], device='cuda:0')\n",
            "tensor([1.8247e-05], device='cuda:0')\n",
            "tensor([-3.5401e-05], device='cuda:0')\n",
            "tensor([1.8055e-05], device='cuda:0')\n",
            "tensor([-3.4827e-05], device='cuda:0')\n",
            "tensor([1.7741e-05], device='cuda:0')\n",
            "tensor([-3.4322e-05], device='cuda:0')\n",
            "tensor([1.7422e-05], device='cuda:0')\n",
            "tensor([-3.3830e-05], device='cuda:0')\n",
            "tensor([1.7026e-05], device='cuda:0')\n",
            "tensor([-3.3389e-05], device='cuda:0')\n",
            "tensor([1.6818e-05], device='cuda:0')\n",
            "tensor([-3.2868e-05], device='cuda:0')\n",
            "tensor([1.6635e-05], device='cuda:0')\n",
            "tensor([-3.2323e-05], device='cuda:0')\n",
            "tensor([1.6343e-05], device='cuda:0')\n",
            "tensor([-3.1858e-05], device='cuda:0')\n",
            "tensor([1.6061e-05], device='cuda:0')\n",
            "tensor([-3.1382e-05], device='cuda:0')\n",
            "tensor([1.5871e-05], device='cuda:0')\n",
            "tensor([-3.0891e-05], device='cuda:0')\n",
            "tensor([1.5704e-05], device='cuda:0')\n",
            "tensor([-3.0394e-05], device='cuda:0')\n",
            "tensor([1.5428e-05], device='cuda:0')\n",
            "tensor([-2.9955e-05], device='cuda:0')\n",
            "tensor([1.5133e-05], device='cuda:0')\n",
            "tensor([-2.9550e-05], device='cuda:0')\n",
            "tensor([1.4863e-05], device='cuda:0')\n",
            "tensor([-2.9112e-05], device='cuda:0')\n",
            "tensor([1.4690e-05], device='cuda:0')\n",
            "tensor([-2.8662e-05], device='cuda:0')\n",
            "tensor([1.4562e-05], device='cuda:0')\n",
            "tensor([-2.8175e-05], device='cuda:0')\n",
            "tensor([1.4402e-05], device='cuda:0')\n",
            "tensor([-2.7720e-05], device='cuda:0')\n",
            "tensor([1.4111e-05], device='cuda:0')\n",
            "tensor([-2.7338e-05], device='cuda:0')\n",
            "tensor([1.3834e-05], device='cuda:0')\n",
            "tensor([-2.6960e-05], device='cuda:0')\n",
            "tensor([1.3559e-05], device='cuda:0')\n",
            "tensor([-2.6578e-05], device='cuda:0')\n",
            "tensor([1.3422e-05], device='cuda:0')\n",
            "tensor([-2.6149e-05], device='cuda:0')\n",
            "tensor([1.3288e-05], device='cuda:0')\n",
            "tensor([-2.5716e-05], device='cuda:0')\n",
            "tensor([1.3147e-05], device='cuda:0')\n",
            "tensor([-2.5298e-05], device='cuda:0')\n",
            "tensor([1.2866e-05], device='cuda:0')\n",
            "tensor([-2.4954e-05], device='cuda:0')\n",
            "tensor([1.2611e-05], device='cuda:0')\n",
            "tensor([-2.4608e-05], device='cuda:0')\n",
            "tensor([1.2333e-05], device='cuda:0')\n",
            "tensor([-2.4277e-05], device='cuda:0')\n",
            "tensor([1.2227e-05], device='cuda:0')\n",
            "tensor([-2.3868e-05], device='cuda:0')\n",
            "tensor([1.2118e-05], device='cuda:0')\n",
            "tensor([-2.3473e-05], device='cuda:0')\n",
            "tensor([1.1960e-05], device='cuda:0')\n",
            "tensor([-2.3111e-05], device='cuda:0')\n",
            "tensor([1.1732e-05], device='cuda:0')\n",
            "tensor([-2.2784e-05], device='cuda:0')\n",
            "tensor([1.1500e-05], device='cuda:0')\n",
            "tensor([-2.2470e-05], device='cuda:0')\n",
            "tensor([1.1255e-05], device='cuda:0')\n",
            "tensor([-2.2158e-05], device='cuda:0')\n",
            "tensor([1.1197e-05], device='cuda:0')\n",
            "tensor([-2.1774e-05], device='cuda:0')\n",
            "tensor([1.1108e-05], device='cuda:0')\n",
            "tensor([-2.1408e-05], device='cuda:0')\n",
            "tensor([1.0944e-05], device='cuda:0')\n",
            "tensor([-2.1092e-05], device='cuda:0')\n",
            "tensor([1.0894e-05], device='cuda:0')\n",
            "tensor([-2.0701e-05], device='cuda:0')\n",
            "tensor([1.0646e-05], device='cuda:0')\n",
            "tensor([-2.0449e-05], device='cuda:0')\n",
            "tensor([1.0426e-05], device='cuda:0')\n",
            "tensor([-2.0162e-05], device='cuda:0')\n",
            "tensor([1.0183e-05], device='cuda:0')\n",
            "tensor([-1.9893e-05], device='cuda:0')\n",
            "tensor([9.9610e-06], device='cuda:0')\n",
            "tensor([-1.9617e-05], device='cuda:0')\n",
            "tensor([9.8436e-06], device='cuda:0')\n",
            "tensor([-1.9318e-05], device='cuda:0')\n",
            "tensor([9.7593e-06], device='cuda:0')\n",
            "tensor([-1.8998e-05], device='cuda:0')\n",
            "tensor([9.6248e-06], device='cuda:0')\n",
            "tensor([-1.8713e-05], device='cuda:0')\n",
            "tensor([9.5335e-06], device='cuda:0')\n",
            "tensor([-1.8394e-05], device='cuda:0')\n",
            "tensor([9.3249e-06], device='cuda:0')\n",
            "tensor([-1.8163e-05], device='cuda:0')\n",
            "tensor([9.1176e-06], device='cuda:0')\n",
            "tensor([-1.7921e-05], device='cuda:0')\n",
            "tensor([8.8513e-06], device='cuda:0')\n",
            "tensor([-1.7729e-05], device='cuda:0')\n",
            "tensor([8.8899e-06], device='cuda:0')\n",
            "tensor([-1.7365e-05], device='cuda:0')\n",
            "tensor([8.9221e-06], device='cuda:0')\n",
            "tensor([-1.7004e-05], device='cuda:0')\n",
            "tensor([8.8266e-06], device='cuda:0')\n",
            "tensor([-1.6739e-05], device='cuda:0')\n",
            "tensor([8.7204e-06], device='cuda:0')\n",
            "tensor([-1.6479e-05], device='cuda:0')\n",
            "tensor([8.6301e-06], device='cuda:0')\n",
            "tensor([-1.6205e-05], device='cuda:0')\n",
            "tensor([8.5412e-06], device='cuda:0')\n",
            "tensor([-1.5935e-05], device='cuda:0')\n",
            "tensor([8.3540e-06], device='cuda:0')\n",
            "tensor([-1.5724e-05], device='cuda:0')\n",
            "tensor([8.1728e-06], device='cuda:0')\n",
            "tensor([-1.5519e-05], device='cuda:0')\n",
            "tensor([7.9498e-06], device='cuda:0')\n",
            "tensor([-1.5337e-05], device='cuda:0')\n",
            "tensor([7.7011e-06], device='cuda:0')\n",
            "tensor([-1.5183e-05], device='cuda:0')\n",
            "tensor([7.7696e-06], device='cuda:0')\n",
            "tensor([-1.4850e-05], device='cuda:0')\n",
            "tensor([7.4347e-06], device='cuda:0')\n",
            "tensor([-1.4742e-05], device='cuda:0')\n",
            "tensor([7.3607e-06], device='cuda:0')\n",
            "tensor([-1.4507e-05], device='cuda:0')\n",
            "tensor([7.2904e-06], device='cuda:0')\n",
            "tensor([-1.4265e-05], device='cuda:0')\n",
            "tensor([7.2028e-06], device='cuda:0')\n",
            "tensor([-1.4039e-05], device='cuda:0')\n",
            "tensor([7.1423e-06], device='cuda:0')\n",
            "tensor([-1.3802e-05], device='cuda:0')\n",
            "tensor([7.0538e-06], device='cuda:0')\n",
            "tensor([-1.3573e-05], device='cuda:0')\n",
            "tensor([6.8587e-06], device='cuda:0')\n",
            "tensor([-1.3419e-05], device='cuda:0')\n",
            "tensor([6.6655e-06], device='cuda:0')\n",
            "tensor([-1.3267e-05], device='cuda:0')\n",
            "tensor([6.4922e-06], device='cuda:0')\n",
            "tensor([-1.3106e-05], device='cuda:0')\n",
            "tensor([6.5039e-06], device='cuda:0')\n",
            "tensor([-1.2854e-05], device='cuda:0')\n",
            "tensor([6.5705e-06], device='cuda:0')\n",
            "tensor([-1.2582e-05], device='cuda:0')\n",
            "tensor([6.3824e-06], device='cuda:0')\n",
            "tensor([-1.2418e-05], device='cuda:0')\n",
            "tensor([6.2967e-06], device='cuda:0')\n",
            "tensor([-1.2238e-05], device='cuda:0')\n",
            "tensor([6.2725e-06], device='cuda:0')\n",
            "tensor([-1.2016e-05], device='cuda:0')\n",
            "tensor([6.1761e-06], device='cuda:0')\n",
            "tensor([-1.1849e-05], device='cuda:0')\n",
            "tensor([6.1439e-06], device='cuda:0')\n",
            "tensor([-1.1634e-05], device='cuda:0')\n",
            "tensor([6.0527e-06], device='cuda:0')\n",
            "tensor([-1.1453e-05], device='cuda:0')\n",
            "tensor([5.9982e-06], device='cuda:0')\n",
            "tensor([-1.1247e-05], device='cuda:0')\n",
            "tensor([5.8026e-06], device='cuda:0')\n",
            "tensor([-1.1143e-05], device='cuda:0')\n",
            "tensor([5.6527e-06], device='cuda:0')\n",
            "tensor([-1.1011e-05], device='cuda:0')\n",
            "tensor([5.4855e-06], device='cuda:0')\n",
            "tensor([-1.0888e-05], device='cuda:0')\n",
            "tensor([5.2811e-06], device='cuda:0')\n",
            "tensor([-1.0778e-05], device='cuda:0')\n",
            "tensor([5.3523e-06], device='cuda:0')\n",
            "tensor([-1.0558e-05], device='cuda:0')\n",
            "tensor([5.4017e-06], device='cuda:0')\n",
            "tensor([-1.0326e-05], device='cuda:0')\n",
            "tensor([5.1912e-06], device='cuda:0')\n",
            "tensor([-1.0234e-05], device='cuda:0')\n",
            "tensor([5.2974e-06], device='cuda:0')\n",
            "tensor([-9.9698e-06], device='cuda:0')\n",
            "tensor([5.2573e-06], device='cuda:0')\n",
            "tensor([-9.8108e-06], device='cuda:0')\n",
            "tensor([5.1735e-06], device='cuda:0')\n",
            "tensor([-9.6809e-06], device='cuda:0')\n",
            "tensor([5.1148e-06], device='cuda:0')\n",
            "tensor([-9.5202e-06], device='cuda:0')\n",
            "tensor([5.0650e-06], device='cuda:0')\n",
            "tensor([-9.3797e-06], device='cuda:0')\n",
            "tensor([4.9826e-06], device='cuda:0')\n",
            "tensor([-9.2407e-06], device='cuda:0')\n",
            "tensor([4.9775e-06], device='cuda:0')\n",
            "tensor([-9.0533e-06], device='cuda:0')\n",
            "tensor([4.9020e-06], device='cuda:0')\n",
            "tensor([-8.9157e-06], device='cuda:0')\n",
            "tensor([4.7684e-06], device='cuda:0')\n",
            "tensor([-8.8162e-06], device='cuda:0')\n",
            "tensor([4.5653e-06], device='cuda:0')\n",
            "tensor([-8.7569e-06], device='cuda:0')\n",
            "tensor([4.4196e-06], device='cuda:0')\n",
            "tensor([-8.6701e-06], device='cuda:0')\n",
            "tensor([4.2468e-06], device='cuda:0')\n",
            "tensor([-8.5948e-06], device='cuda:0')\n",
            "tensor([4.0708e-06], device='cuda:0')\n",
            "tensor([-8.5250e-06], device='cuda:0')\n",
            "tensor([4.1812e-06], device='cuda:0')\n",
            "tensor([-8.3117e-06], device='cuda:0')\n",
            "tensor([3.9991e-06], device='cuda:0')\n",
            "tensor([-8.2400e-06], device='cuda:0')\n",
            "tensor([4.0582e-06], device='cuda:0')\n",
            "tensor([-8.0593e-06], device='cuda:0')\n",
            "tensor([4.1458e-06], device='cuda:0')\n",
            "tensor([-7.8599e-06], device='cuda:0')\n",
            "tensor([4.2217e-06], device='cuda:0')\n",
            "tensor([-7.6693e-06], device='cuda:0')\n",
            "tensor([3.9320e-06], device='cuda:0')\n",
            "tensor([-7.6713e-06], device='cuda:0')\n",
            "tensor([3.9185e-06], device='cuda:0')\n",
            "tensor([-7.5359e-06], device='cuda:0')\n",
            "tensor([3.8478e-06], device='cuda:0')\n",
            "tensor([-7.4474e-06], device='cuda:0')\n",
            "tensor([3.8319e-06], device='cuda:0')\n",
            "tensor([-7.3165e-06], device='cuda:0')\n",
            "tensor([3.7975e-06], device='cuda:0')\n",
            "tensor([-7.1952e-06], device='cuda:0')\n",
            "tensor([3.7551e-06], device='cuda:0')\n",
            "tensor([-7.0798e-06], device='cuda:0')\n",
            "tensor([3.6932e-06], device='cuda:0')\n",
            "tensor([-6.9782e-06], device='cuda:0')\n",
            "tensor([3.6866e-06], device='cuda:0')\n",
            "tensor([-6.8402e-06], device='cuda:0')\n",
            "tensor([3.6387e-06], device='cuda:0')\n",
            "tensor([-6.7421e-06], device='cuda:0')\n",
            "tensor([3.5954e-06], device='cuda:0')\n",
            "tensor([-6.6198e-06], device='cuda:0')\n",
            "tensor([3.5497e-06], device='cuda:0')\n",
            "tensor([-6.5109e-06], device='cuda:0')\n",
            "tensor([3.3774e-06], device='cuda:0')\n",
            "tensor([-6.4840e-06], device='cuda:0')\n",
            "tensor([3.2471e-06], device='cuda:0')\n",
            "tensor([-6.4202e-06], device='cuda:0')\n",
            "tensor([3.0855e-06], device='cuda:0')\n",
            "tensor([-6.3956e-06], device='cuda:0')\n",
            "tensor([2.9425e-06], device='cuda:0')\n",
            "tensor([-6.3473e-06], device='cuda:0')\n",
            "tensor([3.0221e-06], device='cuda:0')\n",
            "tensor([-6.2000e-06], device='cuda:0')\n",
            "tensor([2.8866e-06], device='cuda:0')\n",
            "tensor([-6.1546e-06], device='cuda:0')\n",
            "tensor([2.9677e-06], device='cuda:0')\n",
            "tensor([-5.9927e-06], device='cuda:0')\n",
            "tensor([3.0301e-06], device='cuda:0')\n",
            "tensor([-5.8714e-06], device='cuda:0')\n",
            "tensor([2.9001e-06], device='cuda:0')\n",
            "tensor([-5.8106e-06], device='cuda:0')\n",
            "tensor([2.9565e-06], device='cuda:0')\n",
            "tensor([-5.6766e-06], device='cuda:0')\n",
            "tensor([3.0580e-06], device='cuda:0')\n",
            "tensor([-5.5155e-06], device='cuda:0')\n",
            "tensor([2.9006e-06], device='cuda:0')\n",
            "tensor([-5.4773e-06], device='cuda:0')\n",
            "tensor([2.9970e-06], device='cuda:0')\n",
            "tensor([-5.3159e-06], device='cuda:0')\n",
            "tensor([2.7409e-06], device='cuda:0')\n",
            "tensor([-5.3510e-06], device='cuda:0')\n",
            "tensor([2.7316e-06], device='cuda:0')\n",
            "tensor([-5.2548e-06], device='cuda:0')\n",
            "tensor([2.6627e-06], device='cuda:0')\n",
            "tensor([-5.2089e-06], device='cuda:0')\n",
            "tensor([2.6552e-06], device='cuda:0')\n",
            "tensor([-5.1172e-06], device='cuda:0')\n",
            "tensor([2.6259e-06], device='cuda:0')\n",
            "tensor([-5.0471e-06], device='cuda:0')\n",
            "tensor([2.6161e-06], device='cuda:0')\n",
            "tensor([-4.9580e-06], device='cuda:0')\n",
            "tensor([2.5821e-06], device='cuda:0')\n",
            "tensor([-4.8858e-06], device='cuda:0')\n",
            "tensor([2.5565e-06], device='cuda:0')\n",
            "tensor([-4.8155e-06], device='cuda:0')\n",
            "tensor([2.5011e-06], device='cuda:0')\n",
            "tensor([-4.7556e-06], device='cuda:0')\n",
            "tensor([2.5053e-06], device='cuda:0')\n",
            "tensor([-4.6529e-06], device='cuda:0')\n",
            "tensor([2.4876e-06], device='cuda:0')\n",
            "tensor([-4.5736e-06], device='cuda:0')\n",
            "tensor([2.4019e-06], device='cuda:0')\n",
            "tensor([-4.5378e-06], device='cuda:0')\n",
            "tensor([2.4252e-06], device='cuda:0')\n",
            "tensor([-4.4265e-06], device='cuda:0')\n",
            "tensor([2.3986e-06], device='cuda:0')\n",
            "tensor([-4.3471e-06], device='cuda:0')\n",
            "tensor([2.3651e-06], device='cuda:0')\n",
            "tensor([-4.2728e-06], device='cuda:0')\n",
            "tensor([2.3558e-06], device='cuda:0')\n",
            "tensor([-4.1875e-06], device='cuda:0')\n",
            "tensor([2.3199e-06], device='cuda:0')\n",
            "tensor([-4.1242e-06], device='cuda:0')\n",
            "tensor([2.1812e-06], device='cuda:0')\n",
            "tensor([-4.1171e-06], device='cuda:0')\n",
            "tensor([2.0424e-06], device='cuda:0')\n",
            "tensor([-4.1140e-06], device='cuda:0')\n",
            "tensor([1.9097e-06], device='cuda:0')\n",
            "tensor([-4.1103e-06], device='cuda:0')\n",
            "tensor([1.7472e-06], device='cuda:0')\n",
            "tensor([-4.1240e-06], device='cuda:0')\n",
            "tensor([1.8645e-06], device='cuda:0')\n",
            "tensor([-3.9962e-06], device='cuda:0')\n",
            "tensor([1.7453e-06], device='cuda:0')\n",
            "tensor([-3.9778e-06], device='cuda:0')\n",
            "tensor([1.7872e-06], device='cuda:0')\n",
            "tensor([-3.9107e-06], device='cuda:0')\n",
            "tensor([1.9302e-06], device='cuda:0')\n",
            "tensor([-3.7625e-06], device='cuda:0')\n",
            "tensor([1.7956e-06], device='cuda:0')\n",
            "tensor([-3.7511e-06], device='cuda:0')\n",
            "tensor([1.6289e-06], device='cuda:0')\n",
            "tensor([-3.7815e-06], device='cuda:0')\n",
            "tensor([1.7225e-06], device='cuda:0')\n",
            "tensor([-3.6594e-06], device='cuda:0')\n",
            "tensor([1.8515e-06], device='cuda:0')\n",
            "tensor([-3.5281e-06], device='cuda:0')\n",
            "tensor([1.7001e-06], device='cuda:0')\n",
            "tensor([-3.5380e-06], device='cuda:0')\n",
            "tensor([1.8058e-06], device='cuda:0')\n",
            "tensor([-3.4195e-06], device='cuda:0')\n",
            "tensor([1.6396e-06], device='cuda:0')\n",
            "tensor([-3.4353e-06], device='cuda:0')\n",
            "tensor([1.7467e-06], device='cuda:0')\n",
            "tensor([-3.3187e-06], device='cuda:0')\n",
            "tensor([1.8608e-06], device='cuda:0')\n",
            "tensor([-3.1956e-06], device='cuda:0')\n",
            "tensor([1.7048e-06], device='cuda:0')\n",
            "tensor([-3.2071e-06], device='cuda:0')\n",
            "tensor([1.8179e-06], device='cuda:0')\n",
            "tensor([-3.0807e-06], device='cuda:0')\n",
            "tensor([1.6862e-06], device='cuda:0')\n",
            "tensor([-3.0713e-06], device='cuda:0')\n",
            "tensor([1.7881e-06], device='cuda:0')\n",
            "tensor([-2.9614e-06], device='cuda:0')\n",
            "tensor([1.5316e-06], device='cuda:0')\n",
            "tensor([-3.0362e-06], device='cuda:0')\n",
            "tensor([1.6419e-06], device='cuda:0')\n",
            "tensor([-2.9121e-06], device='cuda:0')\n",
            "tensor([1.6056e-06], device='cuda:0')\n",
            "tensor([-2.8972e-06], device='cuda:0')\n",
            "tensor([1.5730e-06], device='cuda:0')\n",
            "tensor([-2.8723e-06], device='cuda:0')\n",
            "tensor([1.6266e-06], device='cuda:0')\n",
            "tensor([-2.7751e-06], device='cuda:0')\n",
            "tensor([1.6005e-06], device='cuda:0')\n",
            "tensor([-2.7437e-06], device='cuda:0')\n",
            "tensor([1.5683e-06], device='cuda:0')\n",
            "tensor([-2.7182e-06], device='cuda:0')\n",
            "tensor([1.5306e-06], device='cuda:0')\n",
            "tensor([-2.7084e-06], device='cuda:0')\n",
            "tensor([1.5143e-06], device='cuda:0')\n",
            "tensor([-2.6734e-06], device='cuda:0')\n",
            "tensor([1.5344e-06], device='cuda:0')\n",
            "tensor([-2.6140e-06], device='cuda:0')\n",
            "tensor([1.5260e-06], device='cuda:0')\n",
            "tensor([-2.5649e-06], device='cuda:0')\n",
            "tensor([1.5139e-06], device='cuda:0')\n",
            "tensor([-2.5260e-06], device='cuda:0')\n",
            "tensor([1.4794e-06], device='cuda:0')\n",
            "tensor([-2.5074e-06], device='cuda:0')\n",
            "tensor([1.5041e-06], device='cuda:0')\n",
            "tensor([-2.4403e-06], device='cuda:0')\n",
            "tensor([1.4780e-06], device='cuda:0')\n",
            "tensor([-2.4120e-06], device='cuda:0')\n",
            "tensor([1.4734e-06], device='cuda:0')\n",
            "tensor([-2.3652e-06], device='cuda:0')\n",
            "tensor([1.4366e-06], device='cuda:0')\n",
            "tensor([-2.3388e-06], device='cuda:0')\n",
            "tensor([1.4170e-06], device='cuda:0')\n",
            "tensor([-2.3081e-06], device='cuda:0')\n",
            "tensor([1.4068e-06], device='cuda:0')\n",
            "tensor([-2.2665e-06], device='cuda:0')\n",
            "tensor([1.3835e-06], device='cuda:0')\n",
            "tensor([-2.2353e-06], device='cuda:0')\n",
            "tensor([1.3746e-06], device='cuda:0')\n",
            "tensor([-2.1966e-06], device='cuda:0')\n",
            "tensor([1.3583e-06], device='cuda:0')\n",
            "tensor([-2.1588e-06], device='cuda:0')\n",
            "tensor([1.3663e-06], device='cuda:0')\n",
            "tensor([-2.1034e-06], device='cuda:0')\n",
            "tensor([1.3444e-06], device='cuda:0')\n",
            "tensor([-2.0685e-06], device='cuda:0')\n",
            "tensor([1.3267e-06], device='cuda:0')\n",
            "tensor([-2.0347e-06], device='cuda:0')\n",
            "tensor([1.2876e-06], device='cuda:0')\n",
            "tensor([-2.0212e-06], device='cuda:0')\n",
            "tensor([1.3122e-06], device='cuda:0')\n",
            "tensor([-1.9550e-06], device='cuda:0')\n",
            "tensor([1.2782e-06], device='cuda:0')\n",
            "tensor([-1.9288e-06], device='cuda:0')\n",
            "tensor([1.2564e-06], device='cuda:0')\n",
            "tensor([-1.8963e-06], device='cuda:0')\n",
            "tensor([1.2452e-06], device='cuda:0')\n",
            "tensor([-1.8576e-06], device='cuda:0')\n",
            "tensor([1.2191e-06], device='cuda:0')\n",
            "tensor([-1.8271e-06], device='cuda:0')\n",
            "tensor([1.2130e-06], device='cuda:0')\n",
            "tensor([-1.7826e-06], device='cuda:0')\n",
            "tensor([1.1069e-06], device='cuda:0')\n",
            "tensor([-1.8111e-06], device='cuda:0')\n",
            "tensor([1.0990e-06], device='cuda:0')\n",
            "tensor([-1.7625e-06], device='cuda:0')\n",
            "tensor([9.7556e-07], device='cuda:0')\n",
            "tensor([-1.7985e-06], device='cuda:0')\n",
            "tensor([9.7882e-07], device='cuda:0')\n",
            "tensor([-1.7594e-06], device='cuda:0')\n",
            "tensor([8.0466e-07], device='cuda:0')\n",
            "tensor([-1.8210e-06], device='cuda:0')\n",
            "tensor([8.1584e-07], device='cuda:0')\n",
            "tensor([-1.7645e-06], device='cuda:0')\n",
            "tensor([6.8871e-07], device='cuda:0')\n",
            "tensor([-1.8049e-06], device='cuda:0')\n",
            "tensor([6.7148e-07], device='cuda:0')\n",
            "tensor([-1.7703e-06], device='cuda:0')\n",
            "tensor([5.7044e-07], device='cuda:0')\n",
            "tensor([-1.7962e-06], device='cuda:0')\n",
            "tensor([7.9535e-07], device='cuda:0')\n",
            "tensor([-1.6383e-06], device='cuda:0')\n",
            "tensor([6.8545e-07], device='cuda:0')\n",
            "tensor([-1.6617e-06], device='cuda:0')\n",
            "tensor([5.5507e-07], device='cuda:0')\n",
            "tensor([-1.7000e-06], device='cuda:0')\n",
            "tensor([6.3144e-07], device='cuda:0')\n",
            "tensor([-1.6505e-06], device='cuda:0')\n",
            "tensor([5.2433e-07], device='cuda:0')\n",
            "tensor([-1.6758e-06], device='cuda:0')\n",
            "tensor([6.0443e-07], device='cuda:0')\n",
            "tensor([-1.6289e-06], device='cuda:0')\n",
            "tensor([5.0291e-07], device='cuda:0')\n",
            "tensor([-1.6551e-06], device='cuda:0')\n",
            "tensor([5.9884e-07], device='cuda:0')\n",
            "tensor([-1.5885e-06], device='cuda:0')\n",
            "tensor([4.6194e-07], device='cuda:0')\n",
            "tensor([-1.6287e-06], device='cuda:0')\n",
            "tensor([6.1281e-07], device='cuda:0')\n",
            "tensor([-1.5271e-06], device='cuda:0')\n",
            "tensor([4.5495e-07], device='cuda:0')\n",
            "tensor([-1.5791e-06], device='cuda:0')\n",
            "tensor([5.9698e-07], device='cuda:0')\n",
            "tensor([-1.4872e-06], device='cuda:0')\n",
            "tensor([4.4517e-07], device='cuda:0')\n",
            "tensor([-1.5334e-06], device='cuda:0')\n",
            "tensor([5.7835e-07], device='cuda:0')\n",
            "tensor([-1.4502e-06], device='cuda:0')\n",
            "tensor([7.1246e-07], device='cuda:0')\n",
            "tensor([-1.3686e-06], device='cuda:0')\n",
            "tensor([5.7416e-07], device='cuda:0')\n",
            "tensor([-1.4128e-06], device='cuda:0')\n",
            "tensor([6.8732e-07], device='cuda:0')\n",
            "tensor([-1.3302e-06], device='cuda:0')\n",
            "tensor([5.7183e-07], device='cuda:0')\n",
            "tensor([-1.3623e-06], device='cuda:0')\n",
            "tensor([6.6496e-07], device='cuda:0')\n",
            "tensor([-1.3039e-06], device='cuda:0')\n",
            "tensor([5.4156e-07], device='cuda:0')\n",
            "tensor([-1.3335e-06], device='cuda:0')\n",
            "tensor([6.3609e-07], device='cuda:0')\n",
            "tensor([-1.2717e-06], device='cuda:0')\n",
            "tensor([5.1875e-07], device='cuda:0')\n",
            "tensor([-1.2987e-06], device='cuda:0')\n",
            "tensor([6.1933e-07], device='cuda:0')\n",
            "tensor([-1.2359e-06], device='cuda:0')\n",
            "tensor([5.0291e-07], device='cuda:0')\n",
            "tensor([-1.2635e-06], device='cuda:0')\n",
            "tensor([6.1281e-07], device='cuda:0')\n",
            "tensor([-1.1919e-06], device='cuda:0')\n",
            "tensor([4.8801e-07], device='cuda:0')\n",
            "tensor([-1.2334e-06], device='cuda:0')\n",
            "tensor([5.9977e-07], device='cuda:0')\n",
            "tensor([-1.1527e-06], device='cuda:0')\n",
            "tensor([4.8010e-07], device='cuda:0')\n",
            "tensor([-1.1889e-06], device='cuda:0')\n",
            "tensor([6.0117e-07], device='cuda:0')\n",
            "tensor([-1.1039e-06], device='cuda:0')\n",
            "tensor([4.7311e-07], device='cuda:0')\n",
            "tensor([-1.1445e-06], device='cuda:0')\n",
            "tensor([5.8766e-07], device='cuda:0')\n",
            "tensor([-1.0635e-06], device='cuda:0')\n",
            "tensor([6.9430e-07], device='cuda:0')\n",
            "tensor([-1.0040e-06], device='cuda:0')\n",
            "tensor([5.5600e-07], device='cuda:0')\n",
            "tensor([-1.0434e-06], device='cuda:0')\n",
            "tensor([6.6496e-07], device='cuda:0')\n",
            "tensor([-9.7021e-07], device='cuda:0')\n",
            "tensor([5.3365e-07], device='cuda:0')\n",
            "tensor([-1.0058e-06], device='cuda:0')\n",
            "tensor([6.4494e-07], device='cuda:0')\n",
            "tensor([-9.3086e-07], device='cuda:0')\n",
            "tensor([5.2759e-07], device='cuda:0')\n",
            "tensor([-9.6869e-07], device='cuda:0')\n",
            "tensor([6.5519e-07], device='cuda:0')\n",
            "tensor([-8.7474e-07], device='cuda:0')\n",
            "tensor([5.4669e-07], device='cuda:0')\n",
            "tensor([-9.0536e-07], device='cuda:0')\n",
            "tensor([6.3749e-07], device='cuda:0')\n",
            "tensor([-8.4157e-07], device='cuda:0')\n",
            "tensor([5.1083e-07], device='cuda:0')\n",
            "tensor([-8.8313e-07], device='cuda:0')\n",
            "tensor([6.2957e-07], device='cuda:0')\n",
            "tensor([-8.0210e-07], device='cuda:0')\n",
            "tensor([5.2433e-07], device='cuda:0')\n",
            "tensor([-8.2317e-07], device='cuda:0')\n",
            "tensor([6.1933e-07], device='cuda:0')\n",
            "tensor([-7.6508e-07], device='cuda:0')\n",
            "tensor([4.7870e-07], device='cuda:0')\n",
            "tensor([-8.0641e-07], device='cuda:0')\n",
            "tensor([5.8487e-07], device='cuda:0')\n",
            "tensor([-7.2981e-07], device='cuda:0')\n",
            "tensor([7.1432e-07], device='cuda:0')\n",
            "tensor([-6.4203e-07], device='cuda:0')\n",
            "tensor([5.8999e-07], device='cuda:0')\n",
            "tensor([-6.8254e-07], device='cuda:0')\n",
            "tensor([6.7241e-07], device='cuda:0')\n",
            "tensor([-6.2922e-07], device='cuda:0')\n",
            "tensor([5.8161e-07], device='cuda:0')\n",
            "tensor([-6.5134e-07], device='cuda:0')\n",
            "tensor([6.8638e-07], device='cuda:0')\n",
            "tensor([-5.7544e-07], device='cuda:0')\n",
            "tensor([4.5635e-07], device='cuda:0')\n",
            "tensor([-6.8953e-07], device='cuda:0')\n",
            "tensor([5.7742e-07], device='cuda:0')\n",
            "tensor([-6.0338e-07], device='cuda:0')\n",
            "tensor([6.7707e-07], device='cuda:0')\n",
            "tensor([-5.3342e-07], device='cuda:0')\n",
            "tensor([4.4052e-07], device='cuda:0')\n",
            "tensor([-6.4319e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([5.4762e-07], device='cuda:0')\n",
            "tensor([-5.7358e-07], device='cuda:0')\n",
            "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first attempt, if we use the same update structure as in our Numpy code, we’ll get the **weird** error below… but we can get a hint of what’s going on by looking at the tensor itself — once again we **“lost”** the **gradient** while reassigning the update results to our parameters. Thus, the **`grad`** attribute turns out to be **`None`** and it raises the error…\n",
        "\n",
        "```\n",
        "# FIRST ATTEMPT\n",
        "tensor([0.7518], device='cuda:0', grad_fn=<SubBackward0>)\n",
        "AttributeError: 'NoneType' object has no attribute 'zero_'\n",
        "```\n",
        "\n",
        "We then change it slightly, using a familiar **in-place Python assignment** in our second attempt. And, once again, PyTorch complains about it and raises an **error**.\n",
        "\n",
        "```\n",
        "# SECOND ATTEMPT\n",
        "RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "```\n",
        "\n",
        "<br />\n",
        "\n",
        ">\n",
        ">*Why?! It turns out to be a case of “too much of a good thing”. The culprit is PyTorch’s ability to build a dynamic computation graph from every Python operation that involves any gradient-computing tensor or its dependencies.*\n",
        "\n",
        ">*We’ll go deeper into the inner workings of the dynamic computation graph in the next section.*\n",
        ">\n",
        "\n",
        "<br />\n",
        "\n",
        "So, how do we tell PyTorch to **“back off”** and let us **update our parameters** without messing up with its fancy dynamic computation graph? That’s what **`torch.no_grad()`** is good for. It allows us to **perform regular Python operations on tensors, independent of PyTorch’s computation graph**.\n",
        "\n",
        "Finally, we managed to successfully run our model and get the **resulting parameters**. Surely enough, they **match** the ones we got in our *Numpy-only* implementation.\n",
        "\n",
        "```\n",
        "# THIRD ATTEMPT\n",
        "tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
        "```"
      ],
      "metadata": {
        "id": "da30ENrDv7I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Computation Graph\n",
        "\n",
        "So, let’s stick with the **bare minimum**: two (gradient computing) **tensors** for our parameters, predictions, errors and loss."
      ],
      "metadata": {
        "id": "5ZubakezgmPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*The [PyTorchViz](https://github.com/szagoruyko/pytorchviz) package and its `make_dot(variable)` method allows us to easily visualize a graph associated with a given Python variable.*\n",
        ">"
      ],
      "metadata": {
        "id": "ECjmNzYKtb2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saXHzSGbtEJN",
        "outputId": "805ef582-1d63-447b-f3bd-e80f6d4ba633"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.10.0+cu111)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.10.0.2)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=de2ceb016905a0ea560efa8e74806b8faf2289c0a7c1327afffcf040b5ec007f\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()"
      ],
      "metadata": {
        "id": "aek95AOBtJHV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we call **`make_dot(yhat)`** we’ll get the Figure below:\n"
      ],
      "metadata": {
        "id": "qpKj-3qktf0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchviz\n",
        "\n",
        "torchviz.make_dot(var=yhat, params = {\"yhat\":yhat, \"a\": a, \"b\": b}, show_attrs=True, show_saved=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "ChQQVbautfhV",
        "outputId": "1611967f-d8b8-46fb-8eea-b368fca76dc5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f1c5e251e90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"270pt\" height=\"335pt\"\n viewBox=\"0.00 0.00 270.00 335.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 331)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-331 266,-331 266,4 -4,4\"/>\n<!-- 139764073882352 -->\n<g id=\"node1\" class=\"node\">\n<title>139764073882352</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"106,-30 41,-30 41,0 106,0 106,-30\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">yhat</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759815299728 -->\n<g id=\"node2\" class=\"node\">\n<title>139759815299728</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-107 29,-107 29,-66 118,-66 118,-107\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759815299728&#45;&gt;139764073882352 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139759815299728&#45;&gt;139764073882352</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.5,-65.8192C73.5,-57.8154 73.5,-48.5781 73.5,-40.1923\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.0001,-40.1824 73.5,-30.1824 70.0001,-40.1825 77.0001,-40.1824\"/>\n</g>\n<!-- 139759815300112 -->\n<g id=\"node3\" class=\"node\">\n<title>139759815300112</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-178.5 0,-178.5 0,-159.5 101,-159.5 101,-178.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-166.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759815300112&#45;&gt;139759815299728 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139759815300112&#45;&gt;139759815299728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.2287,-159.2122C56.1098,-148.8777 60.7994,-132.0566 64.9426,-117.1951\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"68.3806,-117.8958 67.6947,-107.3232 61.6378,-116.016 68.3806,-117.8958\"/>\n</g>\n<!-- 139764315517008 -->\n<g id=\"node4\" class=\"node\">\n<title>139764315517008</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-261 23.5,-261 23.5,-231 77.5,-231 77.5,-261\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">a</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139764315517008&#45;&gt;139759815300112 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139764315517008&#45;&gt;139759815300112</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-230.7873C50.5,-218.855 50.5,-202.1423 50.5,-189.1069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-188.8107 50.5,-178.8107 47.0001,-188.8108 54.0001,-188.8107\"/>\n</g>\n<!-- 139759815300368 -->\n<g id=\"node5\" class=\"node\">\n<title>139759815300368</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"262,-195 119,-195 119,-143 262,-143 262,-195\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-150\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759815300368&#45;&gt;139759815299728 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139759815300368&#45;&gt;139759815299728</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M153.4805,-142.8965C139.9528,-133.3577 124.6456,-122.5642 111.0703,-112.9919\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.0626,-110.1141 102.873,-107.2117 109.0287,-115.8349 113.0626,-110.1141\"/>\n</g>\n<!-- 139759828313296 -->\n<g id=\"node6\" class=\"node\">\n<title>139759828313296</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"223,-101.5 158,-101.5 158,-71.5 223,-71.5 223,-101.5\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-89.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-78.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759815300368&#45;&gt;139759828313296 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139759815300368&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-142.8965C190.5,-129.3009 190.5,-113.1562 190.5,-101.6318\"/>\n</g>\n<!-- 139759815299216 -->\n<g id=\"node7\" class=\"node\">\n<title>139759815299216</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"241,-255.5 140,-255.5 140,-236.5 241,-236.5 241,-255.5\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-243.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759815299216&#45;&gt;139759815300368 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139759815299216&#45;&gt;139759815300368</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-236.2479C190.5,-228.3781 190.5,-216.7851 190.5,-205.4325\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.0001,-205.1879 190.5,-195.1879 187.0001,-205.1879 194.0001,-205.1879\"/>\n</g>\n<!-- 139764315517392 -->\n<g id=\"node8\" class=\"node\">\n<title>139764315517392</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"217.5,-327 163.5,-327 163.5,-297 217.5,-297 217.5,-327\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-315\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">b</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-304\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139764315517392&#45;&gt;139759815299216 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139764315517392&#45;&gt;139759815299216</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-296.6924C190.5,-287.5067 190.5,-275.7245 190.5,-265.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.0001,-265.703 190.5,-255.7031 187.0001,-265.7031 194.0001,-265.703\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*Set `show_attrs=True` and `show_saved=True` to see what **autograd** saves for the backward pass. (Note that this is only available for pytorch >= 1.9.)*"
      ],
      "metadata": {
        "id": "Db358NvisQu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s take a closer look at its components:\n",
        "\n",
        "* **blue boxes**: these correspond to the **tensors** we use as **parameters**, the ones we’re asking PyTorch to **compute gradients** for;\n",
        "\n",
        "* **gray box**: a **Python operation** that involves a **gradient-computing tensor** or **its dependencies**;\n",
        "\n"
      ],
      "metadata": {
        "id": "T_WTABVpphAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, take a closer look at the **`AddBackward0`** box of the graph: there are two arrows pointing to it, since it is **adding** up **two variables**, $a$ and $b*x$. Seems obvious, right?\n",
        "\n",
        "Then, look at the **`MulBackward0`** box: it is performing a **multiplication**, namely, $b*x$. But there is only one arrow pointing to it! The arrow comes from the **blue box** that corresponds to our **parameter b**.\n",
        "\n",
        "Why don’t we have a box for our **data x**? The answer is: we **do not compute gradients** for it! So, even though there are more tensors involved in the operations performed by the computation graph, it **only** shows **gradient-computing tensors** and **its dependencies**.\n",
        "\n",
        "What would happen to the computation graph if we set `requires_grad` to `False` for our **parameter a**?"
      ],
      "metadata": {
        "id": "4pzQtcYhtQrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=False, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "torchviz.make_dot(var=yhat, params = {\"yhat\":yhat, \"a\": a, \"b\": b}, show_attrs=True, show_saved=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "sBBEW_nYuLhM",
        "outputId": "b126bf73-f002-4256-9859-d2421836c816"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f1c5bb17ed0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"180pt\" height=\"324pt\"\n viewBox=\"0.00 0.00 180.00 324.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 320)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-320 176,-320 176,4 -4,4\"/>\n<!-- 139759774071024 -->\n<g id=\"node1\" class=\"node\">\n<title>139759774071024</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"77,-30 12,-30 12,0 77,0 77,-30\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">yhat</text>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759773957584 -->\n<g id=\"node2\" class=\"node\">\n<title>139759773957584</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"89,-107 0,-107 0,-66 89,-66 89,-107\"/>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"44.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759773957584&#45;&gt;139759774071024 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139759773957584&#45;&gt;139759774071024</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M44.5,-65.8192C44.5,-57.8154 44.5,-48.5781 44.5,-40.1923\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"48.0001,-40.1824 44.5,-30.1824 41.0001,-40.1825 48.0001,-40.1824\"/>\n</g>\n<!-- 139759773956304 -->\n<g id=\"node3\" class=\"node\">\n<title>139759773956304</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163,-195 20,-195 20,-143 163,-143 163,-195\"/>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-150\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759773956304&#45;&gt;139759773957584 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139759773956304&#45;&gt;139759773957584</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M76.6289,-142.8965C71.7586,-134.3476 66.3142,-124.7908 61.311,-116.0086\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.2906,-114.1681 56.2994,-107.2117 58.2084,-117.6332 64.2906,-114.1681\"/>\n</g>\n<!-- 139759828313296 -->\n<g id=\"node4\" class=\"node\">\n<title>139759828313296</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"172,-101.5 107,-101.5 107,-71.5 172,-71.5 172,-101.5\"/>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-89.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-78.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759773956304&#45;&gt;139759828313296 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139759773956304&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.6875,-142.8965C114.5977,-129.3009 123.991,-113.1562 130.6961,-101.6318\"/>\n</g>\n<!-- 139759774170704 -->\n<g id=\"node5\" class=\"node\">\n<title>139759774170704</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"142,-250 41,-250 41,-231 142,-231 142,-250\"/>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774170704&#45;&gt;139759773956304 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139759774170704&#45;&gt;139759773956304</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M91.5,-230.8572C91.5,-224.1389 91.5,-214.7159 91.5,-205.2465\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.0001,-205.0786 91.5,-195.0787 88.0001,-205.0787 95.0001,-205.0786\"/>\n</g>\n<!-- 139759774071216 -->\n<g id=\"node6\" class=\"node\">\n<title>139759774071216</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"118.5,-316 64.5,-316 64.5,-286 118.5,-286 118.5,-316\"/>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-304\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">b</text>\n<text text-anchor=\"middle\" x=\"91.5\" y=\"-293\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774071216&#45;&gt;139759774170704 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139759774071216&#45;&gt;139759774170704</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M91.5,-285.7333C91.5,-278.0322 91.5,-268.5977 91.5,-260.3414\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.0001,-260.0864 91.5,-250.0864 88.0001,-260.0864 95.0001,-260.0864\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsurprisingly, the **blue box** corresponding to the **parameter a** is no more! Simple enough: **no gradients, no graph**."
      ],
      "metadata": {
        "id": "B4qMmRMruUrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "torchviz.make_dot(var=yhat, params = {\"yhat\":yhat, \"a\": a, \"b\": b}, show_attrs=True, show_saved=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "9oZKBJ1XuiG6",
        "outputId": "4cb7347d-ea9b-4123-e0ec-2a290fdae863"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f1c5bafe450>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"270pt\" height=\"335pt\"\n viewBox=\"0.00 0.00 270.00 335.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 331)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-331 266,-331 266,4 -4,4\"/>\n<!-- 139759774087600 -->\n<g id=\"node1\" class=\"node\">\n<title>139759774087600</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"106,-30 41,-30 41,0 106,0 106,-30\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">yhat</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759774170448 -->\n<g id=\"node2\" class=\"node\">\n<title>139759774170448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-107 29,-107 29,-66 118,-66 118,-107\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759774170448&#45;&gt;139759774087600 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139759774170448&#45;&gt;139759774087600</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.5,-65.8192C73.5,-57.8154 73.5,-48.5781 73.5,-40.1923\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.0001,-40.1824 73.5,-30.1824 70.0001,-40.1825 77.0001,-40.1824\"/>\n</g>\n<!-- 139759774170192 -->\n<g id=\"node3\" class=\"node\">\n<title>139759774170192</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-178.5 0,-178.5 0,-159.5 101,-159.5 101,-178.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-166.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774170192&#45;&gt;139759774170448 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139759774170192&#45;&gt;139759774170448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.2287,-159.2122C56.1098,-148.8777 60.7994,-132.0566 64.9426,-117.1951\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"68.3806,-117.8958 67.6947,-107.3232 61.6378,-116.016 68.3806,-117.8958\"/>\n</g>\n<!-- 139759774088368 -->\n<g id=\"node4\" class=\"node\">\n<title>139759774088368</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-261 23.5,-261 23.5,-231 77.5,-231 77.5,-261\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">a</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774088368&#45;&gt;139759774170192 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139759774088368&#45;&gt;139759774170192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-230.7873C50.5,-218.855 50.5,-202.1423 50.5,-189.1069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-188.8107 50.5,-178.8107 47.0001,-188.8108 54.0001,-188.8107\"/>\n</g>\n<!-- 139759774170960 -->\n<g id=\"node5\" class=\"node\">\n<title>139759774170960</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"262,-195 119,-195 119,-143 262,-143 262,-195\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-150\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759774170960&#45;&gt;139759774170448 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139759774170960&#45;&gt;139759774170448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M153.4805,-142.8965C139.9528,-133.3577 124.6456,-122.5642 111.0703,-112.9919\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.0626,-110.1141 102.873,-107.2117 109.0287,-115.8349 113.0626,-110.1141\"/>\n</g>\n<!-- 139759828313296 -->\n<g id=\"node6\" class=\"node\">\n<title>139759828313296</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"223,-101.5 158,-101.5 158,-71.5 223,-71.5 223,-101.5\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-89.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-78.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759774170960&#45;&gt;139759828313296 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139759774170960&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-142.8965C190.5,-129.3009 190.5,-113.1562 190.5,-101.6318\"/>\n</g>\n<!-- 139759774065360 -->\n<g id=\"node7\" class=\"node\">\n<title>139759774065360</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"241,-255.5 140,-255.5 140,-236.5 241,-236.5 241,-255.5\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-243.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774065360&#45;&gt;139759774170960 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139759774065360&#45;&gt;139759774170960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-236.2479C190.5,-228.3781 190.5,-216.7851 190.5,-205.4325\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.0001,-205.1879 190.5,-195.1879 187.0001,-205.1879 194.0001,-205.1879\"/>\n</g>\n<!-- 139759774087792 -->\n<g id=\"node8\" class=\"node\">\n<title>139759774087792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"217.5,-327 163.5,-327 163.5,-297 217.5,-297 217.5,-327\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-315\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">b</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-304\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774087792&#45;&gt;139759774065360 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139759774087792&#45;&gt;139759774065360</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-296.6924C190.5,-287.5067 190.5,-275.7245 190.5,-265.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.0001,-265.703 190.5,-255.7031 187.0001,-265.7031 194.0001,-265.703\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we plot graphs for the loss and error **variables**, the **only difference** between them and the first one is the number of **intermediate steps (gray boxes)**."
      ],
      "metadata": {
        "id": "ozlw28mUs4Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchviz.make_dot(var=loss, params = {\"loss\":loss, \"a\": a, \"b\": b}, show_attrs=True, show_saved=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "IF9uiK7lrSoa",
        "outputId": "bd54f994-03a6-4e62-828a-cb905a881305"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f1d5bfad950>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"320pt\" height=\"588pt\"\n viewBox=\"0.00 0.00 320.00 588.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 584)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-584 316,-584 316,4 -4,4\"/>\n<!-- 139759774087888 -->\n<g id=\"node1\" class=\"node\">\n<title>139759774087888</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"92.5,-30 38.5,-30 38.5,0 92.5,0 92.5,-30\"/>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">loss</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n</g>\n<!-- 139759773997776 -->\n<g id=\"node2\" class=\"node\">\n<title>139759773997776</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"131,-118 0,-118 0,-66 131,-66 131,-118\"/>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-106\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MeanBackward0</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_numel: &#160;&#160;&#160;&#160;&#160;80</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_sizes: (80, 1)</text>\n</g>\n<!-- 139759773997776&#45;&gt;139759774087888 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139759773997776&#45;&gt;139759774087888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M65.5,-65.9313C65.5,-57.6799 65.5,-48.575 65.5,-40.3731\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"69.0001,-40.2587 65.5,-30.2587 62.0001,-40.2588 69.0001,-40.2587\"/>\n</g>\n<!-- 139764843245328 -->\n<g id=\"node3\" class=\"node\">\n<title>139764843245328</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"204,-206 43,-206 43,-154 204,-154 204,-206\"/>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-194\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">exponent: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self &#160;&#160;&#160;: [saved tensor]</text>\n</g>\n<!-- 139764843245328&#45;&gt;139759773997776 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139764843245328&#45;&gt;139759773997776</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.0981,-153.5971C100.4845,-145.0799 94.1767,-135.5095 88.237,-126.4976\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.1153,-124.5045 82.6898,-118.081 85.2706,-128.3567 91.1153,-124.5045\"/>\n</g>\n<!-- 139759774087504 -->\n<g id=\"node4\" class=\"node\">\n<title>139759774087504</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"214,-107 149,-107 149,-77 214,-77 214,-107\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self</text>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139764843245328&#45;&gt;139759774087504 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139764843245328&#45;&gt;139759774087504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M140.9019,-153.5971C150.9122,-138.409 163.1299,-119.8718 171.5315,-107.1246\"/>\n</g>\n<!-- 139764843175184 -->\n<g id=\"node5\" class=\"node\">\n<title>139764843175184</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"168,-283 79,-283 79,-242 168,-242 168,-283\"/>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-271\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139764843175184&#45;&gt;139764843245328 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139764843175184&#45;&gt;139764843245328</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.5,-241.6818C123.5,-233.9279 123.5,-224.8855 123.5,-216.1526\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.0001,-216.1389 123.5,-206.1389 120.0001,-216.139 127.0001,-216.1389\"/>\n</g>\n<!-- 139759774170448 -->\n<g id=\"node6\" class=\"node\">\n<title>139759774170448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"168,-360 79,-360 79,-319 168,-319 168,-360\"/>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-348\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"123.5\" y=\"-326\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759774170448&#45;&gt;139764843175184 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139759774170448&#45;&gt;139764843175184</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.5,-318.8654C123.5,-311.0111 123.5,-301.8822 123.5,-293.2879\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.0001,-293.1915 123.5,-283.1915 120.0001,-293.1916 127.0001,-293.1915\"/>\n</g>\n<!-- 139759774170192 -->\n<g id=\"node7\" class=\"node\">\n<title>139759774170192</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-431.5 50,-431.5 50,-412.5 151,-412.5 151,-431.5\"/>\n<text text-anchor=\"middle\" x=\"100.5\" y=\"-419.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774170192&#45;&gt;139759774170448 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139759774170192&#45;&gt;139759774170448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.2287,-412.2122C106.1098,-401.8777 110.7994,-385.0566 114.9426,-370.1951\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.3806,-370.8958 117.6947,-360.3232 111.6378,-369.016 118.3806,-370.8958\"/>\n</g>\n<!-- 139759774088368 -->\n<g id=\"node8\" class=\"node\">\n<title>139759774088368</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"127.5,-514 73.5,-514 73.5,-484 127.5,-484 127.5,-514\"/>\n<text text-anchor=\"middle\" x=\"100.5\" y=\"-502\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">a</text>\n<text text-anchor=\"middle\" x=\"100.5\" y=\"-491\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774088368&#45;&gt;139759774170192 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139759774088368&#45;&gt;139759774170192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M100.5,-483.7873C100.5,-471.855 100.5,-455.1423 100.5,-442.1069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.0001,-441.8107 100.5,-431.8107 97.0001,-441.8108 104.0001,-441.8107\"/>\n</g>\n<!-- 139759774170960 -->\n<g id=\"node9\" class=\"node\">\n<title>139759774170960</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"312,-448 169,-448 169,-396 312,-396 312,-448\"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-436\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-425\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-414\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-403\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759774170960&#45;&gt;139759774170448 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139759774170960&#45;&gt;139759774170448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M203.4805,-395.8965C189.9528,-386.3577 174.6456,-375.5642 161.0703,-365.9919\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"163.0626,-363.1141 152.873,-360.2117 159.0287,-368.8349 163.0626,-363.1141\"/>\n</g>\n<!-- 139759828313296 -->\n<g id=\"node10\" class=\"node\">\n<title>139759828313296</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"273,-354.5 208,-354.5 208,-324.5 273,-324.5 273,-354.5\"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-342.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-331.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759774170960&#45;&gt;139759828313296 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139759774170960&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.5,-395.8965C240.5,-382.3009 240.5,-366.1562 240.5,-354.6318\"/>\n</g>\n<!-- 139759774065360 -->\n<g id=\"node11\" class=\"node\">\n<title>139759774065360</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"291,-508.5 190,-508.5 190,-489.5 291,-489.5 291,-508.5\"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-496.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774065360&#45;&gt;139759774170960 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139759774065360&#45;&gt;139759774170960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.5,-489.2479C240.5,-481.3781 240.5,-469.7851 240.5,-458.4325\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.0001,-458.1879 240.5,-448.1879 237.0001,-458.1879 244.0001,-458.1879\"/>\n</g>\n<!-- 139759774087792 -->\n<g id=\"node12\" class=\"node\">\n<title>139759774087792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"267.5,-580 213.5,-580 213.5,-550 267.5,-550 267.5,-580\"/>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-568\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">b</text>\n<text text-anchor=\"middle\" x=\"240.5\" y=\"-557\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774087792&#45;&gt;139759774065360 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139759774087792&#45;&gt;139759774065360</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.5,-549.6924C240.5,-540.5067 240.5,-528.7245 240.5,-518.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.0001,-518.703 240.5,-508.7031 237.0001,-518.7031 244.0001,-518.703\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torchviz.make_dot(var=error, params = {\"error\":error, \"a\": a, \"b\": b}, show_attrs=True, show_saved=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "j08kojuCsmRr",
        "outputId": "8a7bdaaf-054a-48f6-94d9-eab5e596508b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f1c5badf6d0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"270pt\" height=\"412pt\"\n viewBox=\"0.00 0.00 270.00 412.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 408)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-408 266,-408 266,4 -4,4\"/>\n<!-- 139759774087504 -->\n<g id=\"node1\" class=\"node\">\n<title>139759774087504</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"106,-30 41,-30 41,0 106,0 106,-30\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">error</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139764843175184 -->\n<g id=\"node2\" class=\"node\">\n<title>139764843175184</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-107 29,-107 29,-66 118,-66 118,-107\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139764843175184&#45;&gt;139759774087504 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139764843175184&#45;&gt;139759774087504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.5,-65.8192C73.5,-57.8154 73.5,-48.5781 73.5,-40.1923\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.0001,-40.1824 73.5,-30.1824 70.0001,-40.1825 77.0001,-40.1824\"/>\n</g>\n<!-- 139759774170448 -->\n<g id=\"node3\" class=\"node\">\n<title>139759774170448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-184 29,-184 29,-143 118,-143 118,-184\"/>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"73.5\" y=\"-150\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759774170448&#45;&gt;139764843175184 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139759774170448&#45;&gt;139764843175184</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M73.5,-142.8654C73.5,-135.0111 73.5,-125.8822 73.5,-117.2879\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.0001,-117.1915 73.5,-107.1915 70.0001,-117.1916 77.0001,-117.1915\"/>\n</g>\n<!-- 139759774170192 -->\n<g id=\"node4\" class=\"node\">\n<title>139759774170192</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-255.5 0,-255.5 0,-236.5 101,-236.5 101,-255.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-243.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774170192&#45;&gt;139759774170448 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139759774170192&#45;&gt;139759774170448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.2287,-236.2122C56.1098,-225.8777 60.7994,-209.0566 64.9426,-194.1951\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"68.3806,-194.8958 67.6947,-184.3232 61.6378,-193.016 68.3806,-194.8958\"/>\n</g>\n<!-- 139759774088368 -->\n<g id=\"node5\" class=\"node\">\n<title>139759774088368</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-338 23.5,-338 23.5,-308 77.5,-308 77.5,-338\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-326\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">a</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-315\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774088368&#45;&gt;139759774170192 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139759774088368&#45;&gt;139759774170192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-307.7873C50.5,-295.855 50.5,-279.1423 50.5,-266.1069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-265.8107 50.5,-255.8107 47.0001,-265.8108 54.0001,-265.8107\"/>\n</g>\n<!-- 139759774170960 -->\n<g id=\"node6\" class=\"node\">\n<title>139759774170960</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"262,-272 119,-272 119,-220 262,-220 262,-272\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759774170960&#45;&gt;139759774170448 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139759774170960&#45;&gt;139759774170448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M153.4805,-219.8965C139.9528,-210.3577 124.6456,-199.5642 111.0703,-189.9919\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.0626,-187.1141 102.873,-184.2117 109.0287,-192.8349 113.0626,-187.1141\"/>\n</g>\n<!-- 139759828313296 -->\n<g id=\"node7\" class=\"node\">\n<title>139759828313296</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"223,-178.5 158,-178.5 158,-148.5 223,-148.5 223,-178.5\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-166.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-155.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759774170960&#45;&gt;139759828313296 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139759774170960&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-219.8965C190.5,-206.3009 190.5,-190.1562 190.5,-178.6318\"/>\n</g>\n<!-- 139759774065360 -->\n<g id=\"node8\" class=\"node\">\n<title>139759774065360</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"241,-332.5 140,-332.5 140,-313.5 241,-313.5 241,-332.5\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-320.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759774065360&#45;&gt;139759774170960 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139759774065360&#45;&gt;139759774170960</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-313.2479C190.5,-305.3781 190.5,-293.7851 190.5,-282.4325\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.0001,-282.1879 190.5,-272.1879 187.0001,-282.1879 194.0001,-282.1879\"/>\n</g>\n<!-- 139759774087792 -->\n<g id=\"node9\" class=\"node\">\n<title>139759774087792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"217.5,-404 163.5,-404 163.5,-374 217.5,-374 217.5,-404\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-392\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">b</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-381\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774087792&#45;&gt;139759774065360 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139759774087792&#45;&gt;139759774065360</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.5,-373.6924C190.5,-364.5067 190.5,-352.7245 190.5,-342.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"194.0001,-342.703 190.5,-332.7031 187.0001,-342.7031 194.0001,-342.703\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best thing about the dynamic computing graph is the fact that you can make it **as complex as you want** it. You can even use control flow statements (e.g., if statements) to **control the flow of the gradients** (obviously!) :-)\n",
        "\n",
        "Here is an example of this. And yes, I do know that the computation itself is completely *nonsense…*"
      ],
      "metadata": {
        "id": "p_-NrdkRuufR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "\n",
        "loss = (error**2).mean()\n",
        "\n",
        "if loss > 0:\n",
        "  yhat2 = b* x_train_tensor\n",
        "  error2 = y_train_tensor - yhat2\n",
        "\n",
        "loss += error2.mean()\n",
        "\n",
        "torchviz.make_dot(var=loss, params = {\"loss\":loss, \"a\": a, \"b\": b}, show_attrs=True, show_saved=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "id": "8j2FWHwzvSQS",
        "outputId": "25a35ab7-3703-4e33-b43a-073add56b66c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f1c5bae3690>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"431pt\" height=\"665pt\"\n viewBox=\"0.00 0.00 431.00 665.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 661)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-661 427,-661 427,4 -4,4\"/>\n<!-- 139759774150192 -->\n<g id=\"node1\" class=\"node\">\n<title>139759774150192</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"285.5,-30 231.5,-30 231.5,0 285.5,0 285.5,-30\"/>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">loss</text>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n</g>\n<!-- 139759773941328 -->\n<g id=\"node2\" class=\"node\">\n<title>139759773941328</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"303,-107 214,-107 214,-66 303,-66 303,-107\"/>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"258.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759773941328&#45;&gt;139759774150192 -->\n<g id=\"edge17\" class=\"edge\">\n<title>139759773941328&#45;&gt;139759774150192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M258.5,-65.8192C258.5,-57.8154 258.5,-48.5781 258.5,-40.1923\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"262.0001,-40.1824 258.5,-30.1824 255.0001,-40.1825 262.0001,-40.1824\"/>\n</g>\n<!-- 139759773939472 -->\n<g id=\"node3\" class=\"node\">\n<title>139759773939472</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"236,-195 105,-195 105,-143 236,-143 236,-195\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MeanBackward0</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_numel: &#160;&#160;&#160;&#160;&#160;80</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-150\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_sizes: (80, 1)</text>\n</g>\n<!-- 139759773939472&#45;&gt;139759773941328 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139759773939472&#45;&gt;139759773941328</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M198.3438,-142.8965C208.1345,-133.7177 219.1645,-123.377 229.0807,-114.0806\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"231.5059,-116.6046 236.4075,-107.2117 226.7183,-111.4978 231.5059,-116.6046\"/>\n</g>\n<!-- 139764843175184 -->\n<g id=\"node4\" class=\"node\">\n<title>139764843175184</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"251,-283 90,-283 90,-231 251,-231 251,-283\"/>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-271\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">exponent: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;2</text>\n<text text-anchor=\"middle\" x=\"170.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self &#160;&#160;&#160;: [saved tensor]</text>\n</g>\n<!-- 139764843175184&#45;&gt;139759773939472 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139764843175184&#45;&gt;139759773939472</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M170.5,-230.5971C170.5,-222.6068 170.5,-213.6894 170.5,-205.1759\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.0001,-205.081 170.5,-195.081 167.0001,-205.081 174.0001,-205.081\"/>\n</g>\n<!-- 139759774150576 -->\n<g id=\"node5\" class=\"node\">\n<title>139759774150576</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"319,-184 254,-184 254,-154 319,-154 319,-184\"/>\n<text text-anchor=\"middle\" x=\"286.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self</text>\n<text text-anchor=\"middle\" x=\"286.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139764843175184&#45;&gt;139759774150576 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139764843175184&#45;&gt;139759774150576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M204.9898,-230.8354C225.0251,-215.6361 249.5658,-197.019 266.4536,-184.2076\"/>\n</g>\n<!-- 139759773957008 -->\n<g id=\"node6\" class=\"node\">\n<title>139759773957008</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"209,-360 120,-360 120,-319 209,-319 209,-360\"/>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-348\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"164.5\" y=\"-326\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759773957008&#45;&gt;139764843175184 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139759773957008&#45;&gt;139764843175184</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M166.0141,-318.6818C166.578,-310.9279 167.2356,-301.8855 167.8707,-293.1526\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.3643,-293.3665 168.599,-283.1389 164.3828,-292.8587 171.3643,-293.3665\"/>\n</g>\n<!-- 139759773957072 -->\n<g id=\"node7\" class=\"node\">\n<title>139759773957072</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"206,-437 117,-437 117,-396 206,-396 206,-437\"/>\n<text text-anchor=\"middle\" x=\"161.5\" y=\"-425\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"161.5\" y=\"-414\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"161.5\" y=\"-403\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759773957072&#45;&gt;139759773957008 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139759773957072&#45;&gt;139759773957008</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M162.3039,-395.8654C162.61,-388.0111 162.9656,-378.8822 163.3005,-370.2879\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"166.8018,-370.3203 163.6938,-360.1915 159.8071,-370.0477 166.8018,-370.3203\"/>\n</g>\n<!-- 139759773957392 -->\n<g id=\"node8\" class=\"node\">\n<title>139759773957392</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-508.5 0,-508.5 0,-489.5 101,-489.5 101,-508.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-496.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759773957392&#45;&gt;139759773957072 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139759773957392&#45;&gt;139759773957072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M63.669,-489.2122C78.7769,-477.9834 104.1881,-459.0967 125.3257,-443.3863\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.5452,-446.0976 133.4833,-437.3232 123.3695,-440.4794 127.5452,-446.0976\"/>\n</g>\n<!-- 139759774088368 -->\n<g id=\"node9\" class=\"node\">\n<title>139759774088368</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-591 23.5,-591 23.5,-561 77.5,-561 77.5,-591\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-579\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">a</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-568\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774088368&#45;&gt;139759773957392 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139759774088368&#45;&gt;139759773957392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-560.7873C50.5,-548.855 50.5,-532.1423 50.5,-519.1069\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-518.8107 50.5,-508.8107 47.0001,-518.8108 54.0001,-518.8107\"/>\n</g>\n<!-- 139759758609744 -->\n<g id=\"node10\" class=\"node\">\n<title>139759758609744</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"262,-525 119,-525 119,-473 262,-473 262,-525\"/>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-513\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-502\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-491\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"190.5\" y=\"-480\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759758609744&#45;&gt;139759773957072 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139759758609744&#45;&gt;139759773957072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M181.3242,-472.8965C178.4141,-464.6176 175.1716,-455.3934 172.166,-446.8429\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"175.3987,-445.4852 168.7805,-437.2117 168.7948,-447.8066 175.3987,-445.4852\"/>\n</g>\n<!-- 139759828313296 -->\n<g id=\"node11\" class=\"node\">\n<title>139759828313296</title>\n<polygon fill=\"#ffa500\" stroke=\"#000000\" points=\"289,-431.5 224,-431.5 224,-401.5 289,-401.5 289,-431.5\"/>\n<text text-anchor=\"middle\" x=\"256.5\" y=\"-419.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other</text>\n<text text-anchor=\"middle\" x=\"256.5\" y=\"-408.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 139759758609744&#45;&gt;139759828313296 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139759758609744&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M211.3828,-472.8965C222.2593,-459.3009 235.1751,-443.1562 244.3946,-431.6318\"/>\n</g>\n<!-- 139759758610064 -->\n<g id=\"node12\" class=\"node\">\n<title>139759758610064</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"321,-585.5 220,-585.5 220,-566.5 321,-566.5 321,-585.5\"/>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-573.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 139759758610064&#45;&gt;139759758609744 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139759758610064&#45;&gt;139759758609744</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M260.3679,-566.2479C251.4407,-557.6554 237.9019,-544.6244 225.1118,-532.3139\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"227.3402,-529.6009 217.7082,-525.1879 222.4859,-534.6443 227.3402,-529.6009\"/>\n</g>\n<!-- 139759773956304 -->\n<g id=\"node16\" class=\"node\">\n<title>139759773956304</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"423,-525 280,-525 280,-473 423,-473 423,-525\"/>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-513\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-502\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-491\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-480\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;None</text>\n</g>\n<!-- 139759758610064&#45;&gt;139759773956304 -->\n<g id=\"edge16\" class=\"edge\">\n<title>139759758610064&#45;&gt;139759773956304</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M280.7587,-566.2479C289.7976,-557.6554 303.5055,-544.6244 316.4555,-532.3139\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.1154,-534.6145 323.9517,-525.1879 314.2925,-529.541 319.1154,-534.6145\"/>\n</g>\n<!-- 139759774087792 -->\n<g id=\"node13\" class=\"node\">\n<title>139759774087792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"297.5,-657 243.5,-657 243.5,-627 297.5,-627 297.5,-657\"/>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-645\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">b</text>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-634\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139759774087792&#45;&gt;139759758610064 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139759774087792&#45;&gt;139759758610064</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M270.5,-626.6924C270.5,-617.5067 270.5,-605.7245 270.5,-595.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"274.0001,-595.703 270.5,-585.7031 267.0001,-595.7031 274.0001,-595.703\"/>\n</g>\n<!-- 139764843262992 -->\n<g id=\"node14\" class=\"node\">\n<title>139764843262992</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"415,-283 284,-283 284,-231 415,-231 415,-283\"/>\n<text text-anchor=\"middle\" x=\"349.5\" y=\"-271\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MeanBackward0</text>\n<text text-anchor=\"middle\" x=\"349.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"349.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_numel: &#160;&#160;&#160;&#160;&#160;80</text>\n<text text-anchor=\"middle\" x=\"349.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self_sizes: (80, 1)</text>\n</g>\n<!-- 139764843262992&#45;&gt;139759773941328 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139764843262992&#45;&gt;139759773941328</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M349.7414,-230.7537C348.8439,-206.408 344.5586,-169.9766 328.5,-143 321.7553,-131.6697 311.8455,-121.6675 301.592,-113.3496\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"303.419,-110.3406 293.3491,-107.0468 299.167,-115.9014 303.419,-110.3406\"/>\n</g>\n<!-- 139759773955920 -->\n<g id=\"node15\" class=\"node\">\n<title>139759773955920</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"396,-437 307,-437 307,-396 396,-396 396,-437\"/>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-425\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-414\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"351.5\" y=\"-403\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 139759773955920&#45;&gt;139764843262992 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139759773955920&#45;&gt;139764843262992</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M351.2426,-395.9747C350.9185,-370.1221 350.3558,-325.247 349.9576,-293.4922\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.4546,-293.2278 349.8294,-283.2725 346.4552,-293.3157 353.4546,-293.2278\"/>\n</g>\n<!-- 139759773956304&#45;&gt;139759828313296 -->\n<g id=\"edge15\" class=\"edge\">\n<title>139759773956304&#45;&gt;139759828313296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.4414,-472.8965C305.7859,-459.3009 287.195,-443.1562 273.9245,-431.6318\"/>\n</g>\n<!-- 139759773956304&#45;&gt;139759773955920 -->\n<g id=\"edge14\" class=\"edge\">\n<title>139759773956304&#45;&gt;139759773955920</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M351.5,-472.8965C351.5,-464.7976 351.5,-455.794 351.5,-447.4015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"355.0001,-447.2117 351.5,-437.2117 348.0001,-447.2118 355.0001,-447.2117\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer\n",
        "\n",
        "So far, we’ve been **manually** updating the parameters using the computed gradients. That’s probably fine for *two parameters*… but what if we had a **whole lot of them**?! We use one of PyTorch’s **optimizers**, like [SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) or [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam).\n",
        "\n",
        "An optimizer takes the **parameters** we want to update, the **learning rate** we want to use (and possibly many other hyper-parameters as well!) and **performs the updates** through its **`step()`** method.\n",
        "\n",
        "Besides, we also don’t need to zero the gradients one by one anymore. We just invoke the optimizer’s **`zero_grad()`** method and that’s it!\n",
        "\n",
        "In the code below, we create a *Stochastic Gradient Descent (SGD)* optimizer to update our parameters $a$ and $b$."
      ],
      "metadata": {
        "id": "UNkW7a3kv4_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(\"# Before: \", a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    loss.backward()    \n",
        "    \n",
        "    # No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    #     a -= lr * a.grad\n",
        "    #     b -= lr * b.grad\n",
        "    optimizer.step()\n",
        "    \n",
        "    # No more telling PyTorch to let gradients go!\n",
        "    # a.grad.zero_()\n",
        "    # b.grad.zero_()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(\"# After: \",a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP8VKQrR0T68",
        "outputId": "3c911482-b2dd-4329-b234-bd0ffcd3ef42"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Before:  tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "# After:  tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check our two parameters, before and after, just to make sure everything is still working fine.\n",
        "\n",
        "Cool! We’ve optimized the **optimization** process :-) What’s left?\n"
      ],
      "metadata": {
        "id": "mnXmwOdr0QEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss\n",
        "\n",
        "We now tackle the **loss computation**. As expected, PyTorch got us covered once again. There are many [loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions) to choose from, depending on the task at hand. Since ours is a regression, we are using the [Mean Square Error (MSE) loss](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss).\n",
        "\n",
        "<br />\n",
        "\n",
        ">\n",
        ">*Notice that `nn.MSELoss` actually **creates a loss function** for us — it is NOT the loss function itself. Moreover, you can specify a **reduction method** to be applied, that is, **how do you want to aggregate the results for individual points** — you can average them (*reduction=’mean’*) or simply sum them up (*reduction=’sum’*).*\n",
        ">\n",
        "\n",
        "<br />\n",
        "\n",
        "We then use the created loss function later, to compute the loss given our **predictions** and our **labels**.\n",
        "\n",
        "Our code looks like this now:"
      ],
      "metadata": {
        "id": "nBDdGlOn0_KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(\"# Before: \", a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # No more manual loss!\n",
        "    # error = y_tensor - yhat\n",
        "    # loss = (error ** 2).mean()\n",
        "    loss = loss_fn(y_train_tensor, yhat)\n",
        "\n",
        "    loss.backward()    \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(\"# After: \", a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M4gXh5m15hF",
        "outputId": "d4bfd1b7-a9db-4cba-8b21-31a80b9beb05"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Before:  tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "# After:  tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, there’s only one piece of code left to change: the **predictions**.\n",
        "\n",
        "It is then time to introduce PyTorch’s way of implementing a…"
      ],
      "metadata": {
        "id": "Q3p3utvI2GFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "In PyTorch, a **model** is represented by a regular **Python class** that inherits from the [Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class.\n",
        "\n",
        "The most fundamental methods it needs to implement are:\n",
        "\n",
        "* `__init__(self)`: **it defines the parts that make up the model** —in our case, two parameters, $a$ and $b$."
      ],
      "metadata": {
        "id": "8v7EV1ek2ObF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*You are not limited to defining **parameters**, though… **models can contain other models (or layers) as its attributes** as well, so you can easily nest them. We’ll see an example of this shortly as well.*\n",
        ">"
      ],
      "metadata": {
        "id": "becoiTVh2nrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `forward(self, x)`: it performs the actual computation, that is, it outputs a prediction, given the input $x$."
      ],
      "metadata": {
        "id": "Uvex13Y_20ZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*You should **NOT call the** `forward(x)` method, though. You should **call the whole model itself**, as in `model(x)` to perform a forward pass and output predictions.*\n",
        ">"
      ],
      "metadata": {
        "id": "EMGFEHA223Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s build a proper (yet simple) model for our regression task. It should look like this:"
      ],
      "metadata": {
        "id": "rf2wC7gy3C97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ManualLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
        "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Computes the outputs / predictions\n",
        "        return self.a + self.b * x"
      ],
      "metadata": {
        "id": "FKaYYEsn2NNU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the `__init__` method, we define our **two parameters**, $a$ and $b$, using the [`Parameter()`](https://pytorch.org/docs/stable/nn.html#torch.nn.Parameter) class, to tell PyTorch these **tensors should be considered parameters of the model they are an attribute of**.\n",
        "\n",
        "Why should we care about that? By doing so, we can use our model’s [`parameters`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.parameters) method to retrieve **an iterator over all model’s parameters**, even those parameters of **nested models**, that we can use to feed our optimizer (instead of building a list of parameters ourselves!).\n",
        "\n",
        "Moreover, we can get the **current values for all parameters** using our model’s [`state_dict()`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.state_dict) method."
      ],
      "metadata": {
        "id": "JDmc3uvK3L_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">**IMPORTANT**: we need to **send our model to the same device where the data is**. If our data is made of GPU tensors, our model must *“live”* inside the GPU as well.\n",
        ">"
      ],
      "metadata": {
        "id": "Z4kfhBLy3x98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use all these handy methods to change our code, which should be looking like this:"
      ],
      "metadata": {
        "id": "D_-lvL-b4Hgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = ManualLinearRegression().to(device)\n",
        "# We can also inspect its parameters using its state_dict\n",
        "print(model.state_dict())\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # What is this?!?\n",
        "    model.train()\n",
        "\n",
        "    # No more manual prediction!\n",
        "    # yhat = a + b * x_tensor\n",
        "    yhat = model(x_train_tensor)\n",
        "    \n",
        "    loss = loss_fn(y_train_tensor, yhat)\n",
        "    loss.backward()    \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPH6vHLh3KDx",
        "outputId": "d56f9c20-38a7-46c7-e0dc-ee04383b51e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('a', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])\n",
            "OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the printed statements will look like this — final values for parameters $a$ and $b$ are still the same, so everything is ok :-)"
      ],
      "metadata": {
        "id": "tE_YWayU4PSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I hope you noticed one particular statement in the code, to which I assigned a comment “What is this?!?” — **`model.train()`**."
      ],
      "metadata": {
        "id": "s25HtW_Z4xIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*In PyTorch, models have a **`train()`** method which, somewhat disappointingly, **does NOT perform a training step**. Its only purpose is to **set the model to training mode**. Why is this important? Some models may use mechanisms like [Dropout](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout), for instance, which have **distinct behaviors in training and evaluation** phases.*\n",
        ">"
      ],
      "metadata": {
        "id": "j0IJMuBi48gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nested Models\n",
        "\n",
        "In our model, we manually created two parameters to perform a linear regression. Let’s use PyTorch’s [Linear](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear) model as an attribute of our own, thus creating a nested model.\n",
        "\n",
        "Even though this clearly is a contrived example, as we are pretty much wrapping the underlying model without adding anything useful (or, at all!) to it, it illustrates well the concept.\n",
        "\n",
        "In the `__init__` method, we created an **attribute** that contains our **nested** `Linear` **model**.\n",
        "\n",
        "In the `forward()` method, we **call the nested model itself** to perform the forward pass (notice, we are **not** calling `self.linear.forward(x)`!)."
      ],
      "metadata": {
        "id": "Dgbzf8gx5dnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        # Now it only takes a call to the layer to make predictions\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "GkB8X8B84LKY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if we call the **`parameters()`** method of this model, **PyTorch will figure the parameters of its attributes in a recursive way**. You can try it yourself using something like: `[*LayerLinearRegression().parameters()]` to get a list of all parameters. You can also add new Linear attributes and, even if you don’t use them at all in the forward pass, they will still be listed under `parameters()`."
      ],
      "metadata": {
        "id": "VtJEkT7A6QHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[*LayerLinearRegression().parameters()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1akA3U36kvs",
        "outputId": "74c1929e-8702-412f-9d60-e4e110a93af8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.2191]], requires_grad=True), Parameter containing:\n",
              " tensor([0.2018], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Models\n",
        "\n",
        "Our model was simple enough… You may be thinking: *“why even bother to build a class for it?!”* Well, you have a point…\n",
        "\n",
        "For **straightforward models**, that use **run-of-the-mill layers**, where the output of a layer is sequentially fed as an input to the next, we can use a, er… [**Sequential**](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) model :-)\n",
        "\n",
        "In our case, we would build a Sequential model with a single argument, that is, the `Linear` layer we used to train our linear regression. The model would look like this:"
      ],
      "metadata": {
        "id": "a_EIpDnd67nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively, you can use a Sequential model\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)"
      ],
      "metadata": {
        "id": "S-ii6sNb6Hhr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Step\n",
        "\n",
        "So far, we’ve defined an **optimizer**, a **loss function** and a **model**. Scroll up a bit and take a quick look at the code inside the loop. Would it change if we were using a **different optimizer**, or **loss**, or even **model**? If not, how can we make it **more generic**?\n",
        "\n",
        "Well, I guess we could say all these lines of code **perform a training step**, given those **three elements** (*optimizer, loss and model*),the **features** and the **labels**.\n",
        "\n",
        "So, how about **writing a function that takes those three elements** and **returns another function that performs a training step**, taking a set of features and labels as arguments and returning the corresponding loss?\n",
        "\n",
        "Then we can use this general-purpose function to build a `train_step()` function to be called inside our training loop. Now our code should look like this… see how **tiny** the training loop is now?"
      ],
      "metadata": {
        "id": "nz6CHcak7gqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def train_step(x, y):\n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "        # Makes predictions\n",
        "        yhat = model(x)\n",
        "        # Computes loss\n",
        "        loss = loss_fn(y, yhat)\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "        # Updates parameters and zeroes gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "    \n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return train_step\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "    # Performs one train step and returns the corresponding loss\n",
        "    loss = train_step(x_train_tensor, y_train_tensor)\n",
        "    losses.append(loss)\n",
        "    \n",
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyf-s3_E7aqB",
        "outputId": "1838df6d-e852-4a78-fdc8-d49c7f84e9e0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[-0.4869]], device='cuda:0')), ('0.bias', tensor([0.5873], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s give our training loop a rest and focus on our **data** for a while… so far, we’ve simply used our Numpy arrays turned **PyTorch tensors**. But we can do better, we can build a…"
      ],
      "metadata": {
        "id": "HzZALU0-8umd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "In PyTorch, a **dataset** is represented by a regular **Python class** that inherits from the [**Dataset**](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class. You can think of it as a kind of a Python **list of tuples**, each tuple corresponding to **one point (features, label)**.\n",
        "\n",
        "\n",
        "The most fundamental methods it needs to implement are:\n",
        "\n",
        "* **`__init__(self)`** : it takes **whatever arguments** needed to build a **list of tuples** — it may be the name of a CSV file that will be loaded and processed; it may be two tensors, one for features, another one for labels; or anything else, depending on the task at hand."
      ],
      "metadata": {
        "id": "zwCPqSmy803j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*There is no need to load the whole dataset in the constructor method (`__init__`). If your dataset is big (tens of thousands of image files, for instance), loading it at once would not be memory efficient. It is recommended to load them on demand (whenever `__get_item__` is called).*\n",
        ">"
      ],
      "metadata": {
        "id": "bEkR5pfXK_Mv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **`__get_item__(self, index)`**: it allows the dataset to be **indexed**, so it can work like a list (**dataset[i]**) — it must **return a tuple (features, label)** corresponding to the requested data point. We can either return the **corresponding slices** of our **pre-loaded** dataset or tensors or, as mentioned above, **load them on demand** (like in this [example](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class)).\n",
        "\n",
        "\n",
        "* **`__len__(self)`**: it should simply return the **size** of the whole dataset so, whenever it is sampled, its indexing is limited to the actual size.\n",
        "\n",
        "\n",
        "Let’s build a simple custom dataset that takes two tensors as arguments: one for the features, one for the labels. For any given index, our dataset class will return the corresponding slice of each of those tensors. It should look like this:"
      ],
      "metadata": {
        "id": "S3W5ehRtLGel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])\n",
        "\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN3ImHX28VuY",
        "outputId": "79bd4c20-def7-4ba1-d9ae-dea8799084d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n",
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once again, you may be thinking *“why go through all this trouble to wrap a couple of tensors in a class?”*. And, once again, you do have a point… if a dataset is nothing else but a **couple of tensors**, we can use PyTorch’s [**TensorDataset**](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset) class, which will do pretty much what we did in our custom dataset above."
      ],
      "metadata": {
        "id": "AtMLSj2DMRtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*Did you notice we built our **training tensors** out of Numpy arrays but we **did not send them to a device**? So, they are **CPU** tensors now! Why?*\n",
        ">\n",
        ">*We **don’t want our whole training data to be loaded into GPU tensors**, as we have been doing in our example so far, because it takes up space in our precious **graphics card’s RAM**.*\n",
        ">"
      ],
      "metadata": {
        "id": "S0bn5JInMcPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, fine, but then again, **why** are we building a dataset anyway? We’re doing it because we want to use a…"
      ],
      "metadata": {
        "id": "CWX3JZxlMu9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader\n",
        "\n",
        "Until now, we have used the **whole training data** at every training step. It has been **batch gradient descent** all along. This is fine for our ridiculously small dataset, sure, but if we want to go serious about all this, we **must** use **mini-batch** gradient descent. Thus, we need mini-batches. Thus, we need to slice our dataset accordingly. Do you want to do it manually?! Me neither!\n",
        "\n",
        "\n",
        "So we use PyTorch’s [**DataLoader**](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class for this job. We tell it which **dataset** to use (the one we just built in the previous section), the desired **mini-batch size** and if we’d like to **shuffle** it or not. That’s it!\n",
        "\n",
        "\n",
        "Our **loader** will behave like an **iterator**, so we can **loop over it** and **fetch a different mini-batch** every time."
      ],
      "metadata": {
        "id": "WK1VhpHWMy6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "hfyqZK-tMblv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To retrieve a sample mini-batch, one can simply run the command below — it will return a list containing two tensors, one for the features, another one for the labels."
      ],
      "metadata": {
        "id": "NO4hWS_LNpmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDiqAkBONm40",
        "outputId": "91810333-0a53-4921-ad24-a0306943ee09"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.1834],\n",
              "         [0.0452],\n",
              "         [0.8022],\n",
              "         [0.1395],\n",
              "         [0.7132],\n",
              "         [0.4722],\n",
              "         [0.0885],\n",
              "         [0.0055],\n",
              "         [0.6011],\n",
              "         [0.7320],\n",
              "         [0.5979],\n",
              "         [0.4952],\n",
              "         [0.8084],\n",
              "         [0.8324],\n",
              "         [0.3309],\n",
              "         [0.3745]]), tensor([[1.4637],\n",
              "         [0.9985],\n",
              "         [2.6229],\n",
              "         [1.3051],\n",
              "         [2.6162],\n",
              "         [1.9857],\n",
              "         [1.0708],\n",
              "         [1.0632],\n",
              "         [2.1214],\n",
              "         [2.4732],\n",
              "         [2.0407],\n",
              "         [1.8735],\n",
              "         [2.6141],\n",
              "         [2.6119],\n",
              "         [1.5427],\n",
              "         [1.7578]])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does this change our training loop? Let’s check it out!"
      ],
      "metadata": {
        "id": "KlqhM9yNNtXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
        "        # therefore, we need to send those mini-batches to the\n",
        "        # device where the model \"lives\"\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        \n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDM1cIBlNvnS",
        "outputId": "7c65cb2f-7bf4-49d4-a114-3a1ce1baeecc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[-0.4869]], device='cuda:0')), ('0.bias', tensor([0.5873], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two things are different now: not only we have an *inner loop* to load each and every mini-batch from our `DataLoader` but, more importantly, we are now **sending only one mini-batch to the device**."
      ],
      "metadata": {
        "id": "-zUKZmrYOJ4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        ">*For bigger datasets, **loading data sample by sample** (into a *CPU* tensor) using Dataset’s `__get_item__` and then **sending all samples** that belong to the same **mini-batch at once to your GPU** (device) is the way to go in order to make the **best use of your graphics card’s RAM**.*\n",
        ">\n",
        ">*Moreover, if you have **many GPUs** to train your model on, it is best to keep your dataset “agnostic” and assign the batches to different GPUs during training.*\n",
        ">"
      ],
      "metadata": {
        "id": "ltZJl9zNOcfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we’ve focused on the **training data** only. We built a dataset and a *data loader* for it. We could do the same for the **validation data**, using the **split** we performed at the beginning of this post… or we could use `random_split`instead."
      ],
      "metadata": {
        "id": "z921pj3HOxwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Split\n",
        "\n",
        "PyTorch’s [`random_split()`](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) method is an easy and familiar way of performing a **training-validation split**. Just keep in mind that, in our example, we need to apply it to the **whole dataset** (*not the training dataset we built in two sections ago*).\n",
        "\n",
        "\n",
        "Then, for each subset of data, we build a corresponding `DataLoader`, so our code looks like this:"
      ],
      "metadata": {
        "id": "GKEhtrfxPDWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
      ],
      "metadata": {
        "id": "osAt1Y_eOQC4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a **data loader** for our **validation set**, so, it makes sense to use it for the…"
      ],
      "metadata": {
        "id": "SQTOw7qgPZI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "This is the **last** part of our journey — we need to change the training loop to include the **evaluation of our model**, that is, computing the **validation loss**. The first step is to include another inner loop to handle the mini-batches that come from the validation loader , sending them to the same device as our model. Next, we make **predictions** using our model and compute the corresponding loss.\n",
        "\n",
        "\n",
        "That’s pretty much it, but there are **two small, yet important**, things to consider:\n",
        "\n",
        "* [**`torch.no_grad()`**](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad): even though it won’t make a difference in our simple model, it is a **good practice** to wrap the validation inner loop with this **context manager to disable any gradient calculation** that you may inadvertently trigger — **gradients belong in training**, not in validation steps;\n",
        "\n",
        "* [**`eval()`**](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval): the only thing it does is **setting the model to evaluation mode** (just like its `train()` counterpart did), so the model can adjust its behavior regarding some operations, like [Dropout](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout).\n",
        "\n",
        "Now, our training loop should look like this:"
      ],
      "metadata": {
        "id": "-J8o4nzkPf2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "val_losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            model.eval()\n",
        "\n",
        "            yhat = model(x_val)\n",
        "            val_loss = loss_fn(y_val, yhat)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi8cGc70Pc2D",
        "outputId": "e63a3629-b493-4fb9-c4ee-d912032fb783"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[-0.4869]], device='cuda:0')), ('0.bias', tensor([0.5873], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there **anything else** we can improve or change? Sure, there is **always something else** to add to your model — using a [**learning rate scheduler**](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate), for instance. But this post is already waaaay too long, so I will stop right here."
      ],
      "metadata": {
        "id": "u5ApZpB9QvUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Thoughts\n",
        "\n",
        "Although this tutorial was much longer than I anticipated when I started writing it, I wouldn’t make it any different — I believe it has **most of the necessary steps** one needs go to trough in order to **learn**, in a **structured** and **incremental** way, how to **develop Deep Learning models using PyTorch**.\n",
        "\n",
        "\n",
        "Hopefully, after finishing working through all code in this post, you’ll be able to better appreciate and more easily work your way through PyTorch’s official [tutorials](https://pytorch.org/tutorials/)."
      ],
      "metadata": {
        "id": "_nv6whFhRAIy"
      }
    }
  ]
}