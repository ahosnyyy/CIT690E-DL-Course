{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TUT#1: Basic Pytorch Tensor Manipulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKEwMoFUT5yrb1zSbUVF0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhHosny/CIT690E-DL-Course/blob/master/TUT_1_Basic_Pytorch_Tensor_Manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6xhcihAbzkv"
      },
      "source": [
        "## What is PyTorch\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is an open-source machine learning library developed by Facebook that supports multiple languages, such as Python and C++ PyTorch is among the most famous and widely used libraries for machine learning in the world. Many software tools and products are built on top of PyTorch, including Tesla Autopilot, Uber’s Pyro, and HuggingFace’s Transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YfkOhuBc65i"
      },
      "source": [
        "## What is a PyTorch tensor\n",
        "\n",
        "In short, a PyTorch<font color='red'>`tensor`</font> is an n-dimensional array that is the same as a NumPy array or TensorFlow tensor. You can consider a <font color='red'>`rank 0`</font> tensor as a scalar, a <font color='red'>`rank 1`</font> tensor as a vector, and a <font color='red'>`rank 2`</font> tensor as a matrix. For higher-dimensional, they are rank <font color='red'>`n`</font> tensor. This difference between the ranks is shown in the figure below.\n",
        "\n",
        "![tensor_1](https://d3i71xaburhd42.cloudfront.net/82750a1533ca30a705d3325290ee8de471073773/3-Figure3-1.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbYHfQBHWmPs"
      },
      "source": [
        "Tensors are just higher-dimensional matrices.\n",
        "![tensor_2](https://drek4537l1klr.cloudfront.net/stevens2/v-12/Figures/p1ch3_tensors.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYcQ64i8Vtj0"
      },
      "source": [
        "**Make sure to check [this version](http://karlstratos.com/drawings/linear_dogs.jpg) out!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00tsftDtqE7w"
      },
      "source": [
        "First things first, let's import the PyTorch module. We'll also add Python's math module to facilitate some of the examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4zZH1lNqHAZ"
      },
      "source": [
        "import torch\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hUlX_Gsn949"
      },
      "source": [
        "## Creating Tensors\n",
        "\n",
        "### 1. Empty Tensor\n",
        "\n",
        "The simplest way to create a tensor is with the <font color='red'>`torch.empty()`</font> call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eMsRFThp0jf",
        "outputId": "db16c453-7b22-4895-f1b3-965f4efeb440"
      },
      "source": [
        "x = torch.empty(3, 4)\n",
        "print(type(x))\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[5.9400e+25, 3.0952e-41, 3.3631e-44, 0.0000e+00],\n",
            "        [       nan, 3.0952e-41, 1.1578e+27, 1.1362e+30],\n",
            "        [7.1547e+22, 4.5828e+30, 1.2121e+04, 7.1846e+22]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASjV0VhqqXcj"
      },
      "source": [
        "Let's unpack what we just did:\n",
        "\n",
        "* We created a tensor using one of the numerous factory methods attached to the <font color='red'>`torch`</font> module.\n",
        "* The tensor itself is 2-dimensional, having 3 rows and 4 columns.\n",
        "* The type of the object returned is <font color='red'>`torch.Tensor`</font>, which is an alias for <font color='red'>`torch.FloatTensor`</font>; by default, PyTorch tensors are populated with 32-bit floating point numbers. (More on data types below.)\n",
        "* You will probably see some random-looking values when printing your tensor. The <font color='red'>`torch.empty()`</font> call allocates memory for the tensor, but does not initialize it with any values - so what you're seeing is whatever was in memory at the time of allocation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQNsrqZXpd4D"
      },
      "source": [
        "### 2. Creating a tensor from a list\n",
        "\n",
        "Creating a tensor from a list or a nested list is easy. First, we need to import the <font color='red'>`torch`</font> library and call the  <font color='red'>`tensor`</font> function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MknRPN6hb8DI",
        "outputId": "a5a70d71-8559-4d3c-ef88-8245041bed80"
      },
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "print(a)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIa56-iJrZxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10707b68-499e-4fdc-8295-d0739fa69e46"
      },
      "source": [
        "b = torch.tensor([[1], [2], [3]])\n",
        "print(b)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi1Qw9ekpBv_"
      },
      "source": [
        "The <font color='red'>```tensor```</font> function supports different types, which will be discussed in a later lesson. In this example, we use the default type,<font color='red'>```torch.int64```</font>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfCp60Zfuzic"
      },
      "source": [
        "### 3. Creating a tensor from a NumPy array\n",
        "\n",
        "If we have a NumPy array and want to convert it to a PyTorch <font color='red'>`tensor`</font>, we just pass it to the tensor function as an argument, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TGE-YLQvDgV"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "na = np.array([1, 2, 3])\n",
        "a = torch.tensor(na)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgHDU0jvI9V"
      },
      "source": [
        "We can also use the <font color='red'>`from_numpy`</font> function to convert a NumPy array to a PyTorch tensor. You just have to pass the NumPy array object as an argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSRXYE50vYJx"
      },
      "source": [
        "b = torch.from_numpy(na)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63cvjAtbvb4o"
      },
      "source": [
        "#### 4. Creating special tensors\n",
        "\n",
        "**PyTorch** provides some useful functions to create special tensors, such as the identity tensor and tensors having all zeros or ones.\n",
        "*  <font color='red'>`eye()`</font>: Creates an identity tensor with an integer.\n",
        "*  <font color='red'>`zeros()`</font>: Creates a tensor with all zeros. The parameter could be an integer or a tuple that defines the shape of the tensor.\n",
        "*  <font color='red'>`ones()`</font>: Creates a tensor with all ones like ones. The parameter could be an integer or a tuple that defines the shape of the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiHZo_EXwK82",
        "outputId": "e50a88bf-1c98-40e4-bfcd-f020e7af0629"
      },
      "source": [
        "# Create a identity tensor with 3*3 shape.\n",
        "eys = torch.eye(3)\n",
        "print(eys)\n",
        "\n",
        "# Create a tensor with 2*2 shape whose values are all 1.\n",
        "ones = torch.ones((2, 2))\n",
        "print(ones)\n",
        "\n",
        "# Create a tensor with 3*3 shape whose values are all 0.\n",
        "zeros = torch.zeros((3, 3))\n",
        "print(zeros)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2Jgpq2mwZvB"
      },
      "source": [
        "### 5. Creating a random tensor\n",
        "\n",
        "**PyTorch** provides some useful functions to create a tensor with a random value.\n",
        "\n",
        "*  <font color='red'>`rand()`</font>: It creates a tensor filled with random numbers from a uniform distribution. The parameter is a sequence of integers defining the shape of the output tensor. It can be a variable number of arguments or a collection like a <font color='red'>`list`</font> or a <font color='red'>`tuple`</font>.\n",
        "*  <font color='red'>`randn()`</font>: It creates a tensor filled with random numbers from a normal distribution with mean 0 and variance 1. The parameter is the same as the <font color='red'>`rand()`</font>.\n",
        "*  <font color='red'>`randint()`</font>: Unlike the functions above, this function creates a <font color='red'>`tensor`</font> with integer values with <font color='red'>`low`</font>, <font color='red'>`high`</font> and <font color='red'>`size`</font> parameters. <font color='red'>`low`</font> means the lowest value, it’s optional and the default value is 0. <font color='red'>`high`</font> means the highest value, and <font color='red'>`size`</font> is a tuple that defines the shape of the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V08SyMYxR_q",
        "outputId": "cd33ec99-d50e-44ca-a3d0-dec1ba9db6fb"
      },
      "source": [
        "# Create a tensor with 1*10 shape with random value between 0 and 1\n",
        "r0 = torch.rand(10)\n",
        "print(r0)\n",
        "print(\"************************************************\")\n",
        "# Create a tensor with 10*1 shape with random value between 0 and 1\n",
        "r1 = torch.rand((10, 1))\n",
        "print(r1)\n",
        "print(\"************************************************\")\n",
        "# Create a tensor with 2*2 shape with random value between 0 and 1\n",
        "r2 = torch.rand((2, 2))\n",
        "print(r2)\n",
        "print(\"************************************************\")\n",
        "# Create a tensor with 2*2 shape with random value from a normal distribution.\n",
        "r3 = torch.randn((2,2))\n",
        "print(r3)\n",
        "print(\"************************************************\")\n",
        "# Create an integer type tensor with 3*3 shape with random value between 0 and 10.\n",
        "r4 = torch.randint(high=10, size=(3, 3))\n",
        "print(r4)\n",
        "print(\"************************************************\")\n",
        "# Create an integer type tensor with 3*3 shape with random value between 5 and 10.\n",
        "r5 = torch.randint(low=5, high=10, size=(3, 3))\n",
        "print(r5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5738, 0.4545, 0.4875, 0.0501, 0.0176, 0.0471, 0.5054, 0.9491, 0.3337,\n",
            "        0.5506])\n",
            "************************************************\n",
            "tensor([[0.3863],\n",
            "        [0.3577],\n",
            "        [0.5707],\n",
            "        [0.4629],\n",
            "        [0.8836],\n",
            "        [0.8632],\n",
            "        [0.7276],\n",
            "        [0.5459],\n",
            "        [0.1114],\n",
            "        [0.6585]])\n",
            "************************************************\n",
            "tensor([[0.4633, 0.0426],\n",
            "        [0.2548, 0.3268]])\n",
            "************************************************\n",
            "tensor([[ 0.0998, -0.3802],\n",
            "        [ 0.1119,  0.2327]])\n",
            "************************************************\n",
            "tensor([[2, 8, 5],\n",
            "        [8, 4, 9],\n",
            "        [3, 7, 7]])\n",
            "************************************************\n",
            "tensor([[9, 8, 5],\n",
            "        [6, 7, 9],\n",
            "        [5, 6, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYcc2oOwyL_S"
      },
      "source": [
        "**Random Tensors and Seeding**\n",
        "\n",
        "Speaking of the random tensor, did you notice the call to <font color='red'>`torch.manual_seed()`</font> immediately preceding it? Initializing tensors, such as a model's learning weights, with random values is common but there are times - especially in research settings - where you'll want some assurance of the reproducibility of your results. Manually setting your random number generator's seed is the way to do this. Let's look more closely:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOQMBOmAyJEW",
        "outputId": "e624c150-abff-46de-a6ce-d50250280bf8"
      },
      "source": [
        "torch.manual_seed(1729)\n",
        "random1 = torch.rand(2, 3)\n",
        "print(random1)\n",
        "\n",
        "random2 = torch.rand(2, 3)\n",
        "print(random2)\n",
        "\n",
        "torch.manual_seed(1729)\n",
        "random3 = torch.rand(2, 3)\n",
        "print(random3)\n",
        "\n",
        "random4 = torch.rand(2, 3)\n",
        "print(random4)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n",
            "tensor([[0.3126, 0.3791, 0.3087],\n",
            "        [0.0736, 0.4216, 0.0691]])\n",
            "tensor([[0.2332, 0.4047, 0.2162],\n",
            "        [0.9927, 0.4128, 0.5938]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h0gbmKExWP5"
      },
      "source": [
        "### 6. Creating a range tensor\n",
        "\n",
        "PyTorch also provides a function <font color='red'>`arange`</font> that generates values in <font color='red'>`[start; end)`</font>, like NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErvOA1smysZO"
      },
      "source": [
        "**Tensor Shapes**\n",
        "\n",
        "Often, when you're performing operations on two or more tensors, they will need to be of the same *shape* - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the <font color='red'>`torch.*_like()`</font> methods:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ29u3e_yxWv",
        "outputId": "e8891759-6eec-4ba4-a223-03f095ce6e7f"
      },
      "source": [
        "x = torch.empty(2, 2, 3)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "empty_like_x = torch.empty_like(x)\n",
        "print(empty_like_x.shape)\n",
        "print(empty_like_x)\n",
        "\n",
        "zeros_like_x = torch.zeros_like(x)\n",
        "print(zeros_like_x.shape)\n",
        "print(zeros_like_x)\n",
        "\n",
        "ones_like_x = torch.ones_like(x)\n",
        "print(ones_like_x.shape)\n",
        "print(ones_like_x)\n",
        "\n",
        "rand_like_x = torch.rand_like(x)\n",
        "print(rand_like_x.shape)\n",
        "print(rand_like_x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[5.9402e+25, 3.0952e-41, 3.3631e-44],\n",
            "         [0.0000e+00,        nan, 0.0000e+00]],\n",
            "\n",
            "        [[4.4721e+21, 1.5956e+25, 4.7399e+16],\n",
            "         [3.7293e-08, 1.4838e-41, 0.0000e+00]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[5.9399e+25, 3.0952e-41, 3.3631e-44],\n",
            "         [0.0000e+00,        nan, 5.9382e-01]],\n",
            "\n",
            "        [[1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "         [4.5828e+30, 1.2121e+04, 7.1846e+22]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.6128, 0.1519, 0.0453],\n",
            "         [0.5035, 0.9978, 0.3884]],\n",
            "\n",
            "        [[0.6929, 0.1703, 0.1384],\n",
            "         [0.4759, 0.7481, 0.0361]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEerzG1QxkDk",
        "outputId": "9c121bc9-cc0c-46aa-c5c4-c25ff666af71"
      },
      "source": [
        "a = torch.arange(1, 10)\n",
        "print(a)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIhLG929zLg6"
      },
      "source": [
        "## Tensor Metadate\n",
        "\n",
        "### 1. Getting type from <font color='red'>`dtype`</font>\n",
        "\n",
        "The <font color='red'>`dtype`</font> attribute of a PyTorch tensor can be used to get its type information.\n",
        "\n",
        "The code below creates a tensor with the float type and prints the type information from dtype. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq_YJrkYyroi",
        "outputId": "99f84025-2ba7-40d3-a227-7feb382d72aa"
      },
      "source": [
        "a = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "print(a.dtype)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2npQOT61PDV"
      },
      "source": [
        "### 2. Getting size from <font color='red'>`shape`</font> and <font color='red'>`size()`</font>\n",
        "PyTorch provides two ways to get the tensor size; these are <font color='red'>`shape`</font>, an attribute, and <font color='red'>`size()`</font>, which is a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoNBsowA1fWn",
        "outputId": "de3b9ab5-1774-4d88-a2de-20fe526dfd4d"
      },
      "source": [
        "a = torch.ones((3, 4))\n",
        "print(a.shape)\n",
        "print(a.size())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWegmPxZ1ujh"
      },
      "source": [
        "### 3. Getting the number of dim\n",
        "As shown in the code below, the number of dimensions of a tensor in Pytorch can be obtained using the attribute <font color='red'>`ndim`</font> or using the function <font color='red'>`dim()`</font> or its alias <font color='red'>`ndimension()`</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnbyCt4p19vh",
        "outputId": "83426398-c803-49b5-c175-12d6bf1b39e3"
      },
      "source": [
        "a = torch.ones((3, 4, 6))\n",
        "print(a.ndim)\n",
        "print(a.dim())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRLhWkQ54XYy"
      },
      "source": [
        "### 4. Getting the number of elements\n",
        "\n",
        "PyTorch provides two ways to get the number of elements of a tensor, <font color='red'>`nelement()`</font> and <font color='red'>`numel()`</font>. Both of them are functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KBzGqXM4sCu",
        "outputId": "4c7e6856-51e6-4773-b3dc-5fbe2a7dd0c9"
      },
      "source": [
        "a = torch.ones((3, 4, 6))\n",
        "print(a.numel())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aVWaosQ4u-n"
      },
      "source": [
        "## Tensor Types\n",
        "\n",
        "### Why tensor type is important#\n",
        "Similar to other frameworks, PyTorch too defines its types for its tensor. Some frequently used types are listed in the table below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECWIzNz-5Hl5"
      },
      "source": [
        "| Data Type  | dtype | CPU tensor | GPU tensor |\n",
        "| --- | --- | --- |---|\n",
        "| 32-bit floating point | torch.float32/torch.float | torch.FloatTensor | torch.cuda.FloatTensor |\n",
        "|64-bit floating point|torch.float64/torch.double|torch.DoubleTensor|torch.cuda.DoubleTensor|\n",
        "|8-bit integer (signed)|torch.int16|torch.ShortTensor|torch.cuda.ShortTensor|\n",
        "|boolean|torch.bool|torch.BoolTensor|torch.cuda.BoolTensor|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdKYSGyG6p1d"
      },
      "source": [
        "The tensor type is vital. There are two main reasons.\n",
        "\n",
        "*  It affects speed and memory usage because the GPU has video memory limitations. More bits type takes up more memory and requires more computing resources. For example, a matrix <font color='red'>`A`</font> with size 1000x1000. If the <font color='red'>`dtype`</font> is <font color='red'>`torch.float32`</font>, this matrix would consume about **3.81MB GPU memory** (1000x1000x4bytes, each <font color='red'>`float32`</font> uses 4 bytes.). If the <font color='red'>`dtype`</font> is <font color='red'>`torch.double`</font>, this matrix would consume about **7.62MB GPU memory** (1000x1000x8bytes, each <font color='red'>`double`</font> uses 8 bytes.).\n",
        "\n",
        "* Some APIs have strong requirements for types. For example, when you train a model about a classification task, you need to calculate some metrics. The tensor type of input of some API requires the torch.long type. You could check this [example](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u00vO5Tc8OBa"
      },
      "source": [
        "### 1. Creating tensors from specified APIs\n",
        "\n",
        "**PyTorch** provides some useful functions to create tensors with the specified type.\n",
        "\n",
        "* <font color='red'>`FloatTensor`</font>: This function creates tensors with <font color='red'>`torch.float32`</font> type.\n",
        "* <font color='red'>`IntTensor`</font>: This function creates tensors with <font color='red'>`torch.int32`</font> type.\n",
        "* <font color='red'>`DoubleTensor`</font>: This function creates tensors with <font color='red'>`torch.float64`</font> type.\n",
        "* <font color='red'>`LongTensor`</font>: This function creates tensors with <font color='red'>`torch.long`</font> type.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rJdW8DS6mwp"
      },
      "source": [
        "d = torch.FloatTensor([1, 2, 3])\n",
        "e = torch.IntTensor([1, 2, 3])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHjRc7Vd8-Zj"
      },
      "source": [
        "### 2. Casting tensors into different types\n",
        "\n",
        "The Tensor class has the method <font color='red'>`to()`</font>, which can cast tensors into different types. To cast a tensor, call its <font color='red'>`to()`</font> method and pass the dtype as the argument, as shown in the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4otQZVx786Q2",
        "outputId": "90f77e43-716b-4250-9ed3-dc545d34a6f2"
      },
      "source": [
        "b = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "print(\"The dtype for b is {}\".format(b.dtype))\n",
        "\n",
        "c = b.to(dtype=torch.int64)\n",
        "print(\"The dtype for c is {}\".format(c.dtype))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dtype for b is torch.float32\n",
            "The dtype for c is torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUbuS4gM9Sk3"
      },
      "source": [
        "**Notice**: The <font color='red'>`to()`</font> cast is not an in-place operation, which means the original tensor wouldn’t be modified. It would return a new tensor with the new type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je_id49-9qXG"
      },
      "source": [
        "## Selecting Elements from a Tensor\n",
        "\n",
        "### 1. Selecting tensor with index\n",
        "\n",
        "If you are already familiar with the NumPy array, you can use the same methods to select tensors by <font color='red'>`[]`</font> operations.\n",
        "\n",
        "Take a 2-dimensional tensor as an example. Let’s consider it as a matrix.\n",
        "\n",
        "* <font color='red'>`tensor[2, 3]`</font>: Get only one value.\n",
        "* <font color='red'>`tensor[:, 1]`</font>: Get the second column from the tensor.\n",
        "* <font color='red'>`tensor[1, :]`</font>: Get the second row from the tensor.\n",
        "For higher-dimensional tensors, the operations are the same. Such as <font color='red'>`tensor[:, 2, :]`</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3RkgB3m-N3P",
        "outputId": "42ed6be6-b905-4a45-c39d-88b3d86ec55c"
      },
      "source": [
        "a = torch.arange(1, 10).reshape((3, 3))\n",
        "# The output\n",
        "# tensor([[1, 2, 3],\n",
        "#         [4, 5, 6],\n",
        "#         [7, 8, 9]])\n",
        "print(\"The original tensor\")\n",
        "print(a)\n",
        "\n",
        "print(\"Select only one element\")\n",
        "print(a[1,1])\n",
        "\n",
        "print(\"Select the second column\")\n",
        "print(a[:, 1])\n",
        "\n",
        "print(\"Select the second row.\")\n",
        "print(a[1, :])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Select only one element\n",
            "tensor(5)\n",
            "Select the second column\n",
            "tensor([2, 5, 8])\n",
            "Select the second row.\n",
            "tensor([4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yJ243nM-QNk"
      },
      "source": [
        "### 2. Selelcting tensor with <font color='red'>`index_select`</font>\n",
        "\n",
        "**PyTorch** provides a function <font color='red'>`index_select`</font> which enables us to select some elements from a tensor with indices.\n",
        "\n",
        "At first, we need to create a tensor (<font color='red'>`Long`</font> type) that indicates the indices we want to select. Since we want to use <font color='red'>`index`</font> to locate the element in a tensor, this tensor must be of <font color='red'>`Long`</font> type.\n",
        "\n",
        "<font color='red'>`index_select`</font> requires the following parameters:\n",
        "\n",
        "* The first parameter is the tensor we want to select.\n",
        "* <font color='red'>`dim`</font>: It indicates the dimension in which we index. In this example, the tensor is a 2-dimensions tensor. <font color='red'>`dim=0`</font> means the row, <font color='red'>`dim=1`</font> means the column.\n",
        "* <font color='red'>`index`</font>: The 1-D tensor containing the indices to index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whmAd35LAQwI",
        "outputId": "8c69960d-ac73-4550-8cd3-11da911f95d5"
      },
      "source": [
        "a = torch.arange(1, 10).reshape((3, 3))\n",
        "\n",
        "indices = torch.LongTensor([0, 2])\n",
        "result = torch.index_select(a, dim=0, index=indices)\n",
        "print(result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtwiWLJsAR6D"
      },
      "source": [
        "### 3. Selecting tensor with a mask\n",
        "\n",
        "The mask tensor is <font color='red'>`BoolTensor`</font>, which identifies which elements are chosen. The <font color='red'>`shape`</font> of the mask tensor and the original tensor doesn’t need to match, but they must be broadcastable.\n",
        "\n",
        "In short, PyTorch enables us to pass a tensor of Boolean type to <font color='red'>`masked_select`</font>, which selects desired elements from another tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4YvQknRA50w",
        "outputId": "b7132b35-627d-4103-b280-e5a159bdccbe"
      },
      "source": [
        "a = torch.arange(1, 10).reshape((3, 3))\n",
        "\n",
        "mask = torch.BoolTensor([[True, False, True],\n",
        "                        [False, False, True],\n",
        "                        [True, False, False]])\n",
        "print(\"The mask tensor is: \\n{}\".format(mask))\n",
        "print(\"The original tensor is: \\n{}\".format(a))\n",
        "result = torch.masked_select(a, mask)\n",
        "print(\"The result is {}\".format(result))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mask tensor is: \n",
            "tensor([[ True, False,  True],\n",
            "        [False, False,  True],\n",
            "        [ True, False, False]])\n",
            "The original tensor is: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "The result is tensor([1, 3, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbWf_jNDA7tO"
      },
      "source": [
        "## Changing the Shape of a Tensor\n",
        "\n",
        "### 1. Reshaping a tensor\n",
        "\n",
        "If you already have one tensor, but the <font color='red'>`shape`</font> is not what you expect, <font color='red'>`shape()`</font> is the function you need. It allows us to create a tensor with the same data and number of original tensor elements.\n",
        "\n",
        "<font color='red'>`shape()`</font> requires two parameters. The first parameter **input** is the tensor to be reshaped. The second parameter is the <font color='red'>`shape`</font> which is a tuple of int, the new shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mA-GLETBmZK",
        "outputId": "ac26ee43-d648-4c22-cdea-925e32e46ef6"
      },
      "source": [
        "a = torch.arange(1, 9)\n",
        "print(\"The original tensor\\n.\")\n",
        "print(a)\n",
        "\n",
        "b = torch.reshape(a, (2, 4))\n",
        "print(\"The reshape tensor with shape (2, 4)\\n\")\n",
        "print(b)\n",
        "\n",
        "c = torch.reshape(a, (2, -1))\n",
        "print(\"The reshape tensor with shape (2, -1)\\n\")\n",
        "print(c)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor\n",
            ".\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "The reshape tensor with shape (2, 4)\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "The reshape tensor with shape (2, -1)\n",
            "\n",
            "tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IRu-ITRBnIM"
      },
      "source": [
        "### 2. Squeezing a tensor\n",
        "\n",
        "Sometimes, the size of some dimensions of a tensor is 1. For example, a tensor’s shape is (10, 2, 1, 5), and we want to remove the third dimension. <font color='red'>`squeeze()`</font> is the function we need.\n",
        "\n",
        "* We can’t squeeze a dimension if the size is greater than 1.\n",
        "* We can squeeze multiple dimensions simultaneously in one function call. But, it would squeeze all.\n",
        "\n",
        "<font color='red'>`squeeze()`</font> has two parameters:\n",
        "\n",
        "* <font color='red'>`input`</font>: The tensor we want to perform squeeze on.\n",
        "* <font color='red'>`dim`</font>: The dimension we want to perform squeeze on. It’s optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN1beWGBCGAg",
        "outputId": "dc572153-ccf6-4cff-cb00-c8665e0f6d13"
      },
      "source": [
        "a = torch.ones((3, 1, 2))\n",
        "print(\"The original shape of a is {}\".format(a.shape))\n",
        "print(\"The original a tensor is {}\".format(a))\n",
        "\n",
        "a = torch.squeeze(a, dim=1)\n",
        "print(\"The new shape of a is {}\".format(a.shape))\n",
        "print(\"The new tensor is {}\".format(a))\n",
        "\n",
        "b = torch.ones((3,1,2,1,2))\n",
        "print(\"The original shape of a is {}\".format(b.shape))\n",
        "print(\"The original b tensor is {}\".format(b))\n",
        "\n",
        "b = torch.squeeze(b)\n",
        "print(\"The new shape of a is {}\".format(b.shape))\n",
        "print(\"The new tensor is {}\".format(b))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original shape of a is torch.Size([3, 1, 2])\n",
            "The original a tensor is tensor([[[1., 1.]],\n",
            "\n",
            "        [[1., 1.]],\n",
            "\n",
            "        [[1., 1.]]])\n",
            "The new shape of a is torch.Size([3, 2])\n",
            "The new tensor is tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "The original shape of a is torch.Size([3, 1, 2, 1, 2])\n",
            "The original b tensor is tensor([[[[[1., 1.]],\n",
            "\n",
            "          [[1., 1.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[1., 1.]],\n",
            "\n",
            "          [[1., 1.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[1., 1.]],\n",
            "\n",
            "          [[1., 1.]]]]])\n",
            "The new shape of a is torch.Size([3, 2, 2])\n",
            "The new tensor is tensor([[[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd4LSvdECG6i"
      },
      "source": [
        "### 3. Un-squeezing a tensor#\n",
        "Since we can remove one dim from a tensor, we may want to add one more dim to a tensor as well. For example, a tensor’s shape is (3, 3), you could add one dim like (3, 1, 3) by <font color='red'>`unsqueeze()`</font>.\n",
        "\n",
        "* <font color='red'>`dim`</font>: This parameter indicates the index at which to insert the dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMXs4Cs_C3os",
        "outputId": "8ebe3cf7-84e1-40b8-9053-dfb92171e9d9"
      },
      "source": [
        "a = torch.ones((3, 3))\n",
        "print(\"The original shape of a is {}\".format(a.shape))\n",
        "print(\"The original a tensor is {}\".format(a))\n",
        "\n",
        "a = torch.unsqueeze(a, dim=1)\n",
        "print(\"The new shape of a is {}\".format(a.shape))\n",
        "print(\"The new tensor is {}\".format(a))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original shape of a is torch.Size([3, 3])\n",
            "The original a tensor is tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "The new shape of a is torch.Size([3, 1, 3])\n",
            "The new tensor is tensor([[[1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTvGou1PC4ke"
      },
      "source": [
        "### 4. Transposing a tensor\n",
        "\n",
        "Transposing a tensor is quite simple in **PyTorch**, just call the <font color='red'>`transpose()`</font>. This function requires two parameters, <font color='red'>`dim0`</font>, and <font color='red'>`dim1`</font>, which indicate the first and the second dim to be transposed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJUFdvD1DTPa",
        "outputId": "de58cdf1-5ae8-4336-bc6a-9219307e1fab"
      },
      "source": [
        "a = torch.ones((2, 4))\n",
        "print(\"The original shape of a is {}\".format(a.shape))\n",
        "print(\"The original tensor a is {}\".format(a))\n",
        "\n",
        "a = torch.transpose(a, 0, 1)\n",
        "print(\"The new shape of a is {}\".format(a.shape))\n",
        "print(\"The new tensor a is {}\".format(a))\n",
        "\n",
        "b = torch.ones((2, 4, 2))\n",
        "print(\"The original shape of b is {}\".format(b.shape))\n",
        "print(\"The original tensor b is {}\".format(b))\n",
        "\n",
        "b = torch.transpose(b, 1, 2)\n",
        "print(\"The new shape of b is {}\".format(b.shape))\n",
        "print(\"The new tensor b is {}\".format(b))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original shape of a is torch.Size([2, 4])\n",
            "The original tensor a is tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "The new shape of a is torch.Size([4, 2])\n",
            "The new tensor a is tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "The original shape of b is torch.Size([2, 4, 2])\n",
            "The original tensor b is tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]])\n",
            "The new shape of b is torch.Size([2, 2, 4])\n",
            "The new tensor b is tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPcMUXeBECtH"
      },
      "source": [
        "## Concatenating tensors\n",
        "\n",
        "### 1. Concatenate the tensors\n",
        "\n",
        "<font color='red'>`torch.cat()`</font> can concatenate a sequence of tensors in a given dimension. All tensors should have the same shape. Below are the important parameters.\n",
        "\n",
        "* <font color='red'>`tensors`</font>: A list of tensors must have the same shape.\n",
        "* <font color='red'>`dim`</font>: The dimension over which the tensors are concatenated. Take 2D tensors as an example, <font color='red'>`dim=0`</font> means the operation would be performed row-wise. <font color='red'>`dim=1`</font> means the operation would be performed column-wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWoN6q17EitN",
        "outputId": "be2879d4-a12c-4fe6-fef6-5f2274e01185"
      },
      "source": [
        "a = torch.randn((3, 3))\n",
        "print(\"The original tesnor a is\\n {}\".format(a))\n",
        "result = torch.cat((a, a), dim=0)\n",
        "print(\"The shape of result is {}\".format(result.shape))\n",
        "print(\"The new tensor is\\n {}\".format(result))\n",
        "\n",
        "b = torch.randn((3, 3))\n",
        "print(\"The original tesnor b is\\n {}\".format(b))\n",
        "result = torch.cat((b, b), dim=1)\n",
        "print(\"The shape of result is {}\".format(result.shape))\n",
        "print(\"The new tensor is\\n {}\".format(result))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tesnor a is\n",
            " tensor([[ 0.3645,  0.1179, -0.3338],\n",
            "        [ 1.2409, -1.2293, -0.4904],\n",
            "        [ 0.1263, -0.0732,  1.0363]])\n",
            "The shape of result is torch.Size([6, 3])\n",
            "The new tensor is\n",
            " tensor([[ 0.3645,  0.1179, -0.3338],\n",
            "        [ 1.2409, -1.2293, -0.4904],\n",
            "        [ 0.1263, -0.0732,  1.0363],\n",
            "        [ 0.3645,  0.1179, -0.3338],\n",
            "        [ 1.2409, -1.2293, -0.4904],\n",
            "        [ 0.1263, -0.0732,  1.0363]])\n",
            "The original tesnor b is\n",
            " tensor([[-0.5292,  0.6205,  1.7128],\n",
            "        [-1.2221, -1.1406,  1.1263],\n",
            "        [-1.7528, -0.5989, -2.3606]])\n",
            "The shape of result is torch.Size([3, 6])\n",
            "The new tensor is\n",
            " tensor([[-0.5292,  0.6205,  1.7128, -0.5292,  0.6205,  1.7128],\n",
            "        [-1.2221, -1.1406,  1.1263, -1.2221, -1.1406,  1.1263],\n",
            "        [-1.7528, -0.5989, -2.3606, -1.7528, -0.5989, -2.3606]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STtYSl5UEoeh"
      },
      "source": [
        "### 2. Stacking the tensors\n",
        "\n",
        "<font color='red'>`torch.cat()`</font> concatenates the given sequence of <font color='red'>`seq`</font> tensors in the <font color='red'>`given dimension`</font>.\n",
        "\n",
        "<font color='red'>`torch.stack()`</font> is similar to <font color='red'>`torch.cat()`</font>, <font color='red'>`torch.stack()`</font> concatenates the sequence of tensors along a new dimension.\n",
        "\n",
        "For example, there are two tensors with the shape (3, 4). We stack these two tensors with <font color='red'>`dim=1`</font>, then the shape of the return value would be (3, 2, 4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODKtelzTFSmb",
        "outputId": "ee0b9174-7f9c-4604-ceff-20e3430e7605"
      },
      "source": [
        "a = torch.randn((2, 2))\n",
        "b = torch.randn((2, 2))\n",
        "print(\"The original tesnor a is\\n {}\".format(a))\n",
        "print(\"The original tesnor b is\\n {}\".format(b))\n",
        "result = torch.stack((a, b), dim=1)\n",
        "print(\"The shape of result is {}\".format(result.shape))\n",
        "print(\"The new tensor is\\n {}\".format(result))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tesnor a is\n",
            " tensor([[ 0.0695, -0.4278],\n",
            "        [-0.4861, -0.7959]])\n",
            "The original tesnor b is\n",
            " tensor([[-0.5204, -0.7523],\n",
            "        [ 2.2930,  0.9971]])\n",
            "The shape of result is torch.Size([2, 2, 2])\n",
            "The new tensor is\n",
            " tensor([[[ 0.0695, -0.4278],\n",
            "         [-0.5204, -0.7523]],\n",
            "\n",
            "        [[-0.4861, -0.7959],\n",
            "         [ 2.2930,  0.9971]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHLMFuCQFjXj"
      },
      "source": [
        "## Element-wise Mathematical Operations on Tensors\n",
        "\n",
        "### Math operation with scalar\n",
        "\n",
        "If you have used the NumPy array before, you may already know that we can perform a math operation between a NumPy array and a scalar. PyTorch tensor supports almost the same operations. In PyTorch, we perform it in two ways:\n",
        "\n",
        "* The operators, such as <font color='red'>`+`</font>, <font color='red'>`-`</font>, and <font color='red'>`*`</font>.\n",
        "* The functions, such as <font color='red'>`add`</font>, <font color='red'>`sub`</font>, and <font color='red'>`mul`</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7tJmFH7F-bH"
      },
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "b = a + 3\n",
        "b = a.add(3)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_iL7NmGLOm"
      },
      "source": [
        "PyTorch supports most of the math functions under the native Python <font color='red'>`math`</font> module. You could find a complete list from the [official site](https://pytorch.org/docs/stable/torch.html#pointwise-ops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcaLkEMLGk2s",
        "outputId": "ccdb0714-6ad5-457d-adc1-44d4acf46b83"
      },
      "source": [
        "a = torch.tensor([1,2,3])\n",
        "print(\"The original tensor a is {}\".format(a))\n",
        "\n",
        "b = a + 3\n",
        "print(\"Th new tensor b is {}\".format(b))\n",
        "\n",
        "b = a.add(3)\n",
        "print(\"Th new tensor b is {}\".format(b))\n",
        "\n",
        "print(\"The tensor a is still {}\".format(a))\n",
        "\n",
        "a.add_(3)\n",
        "print(\"The new tensor a is {}\".format(a))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor a is tensor([1, 2, 3])\n",
            "Th new tensor b is tensor([4, 5, 6])\n",
            "Th new tensor b is tensor([4, 5, 6])\n",
            "The tensor a is still tensor([1, 2, 3])\n",
            "The new tensor a is tensor([4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDKyh07bGpEm"
      },
      "source": [
        "### 2. Math operation between tensors\n",
        "\n",
        "Since the tensors could be performed with a single scalar, it also works between two tensors with the same shape. It even works for 2D or higher ranked tensors. These operations are element-wise, which means these operations happen between two pairs of corresponding elements of these two tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncVwugk-G7do",
        "outputId": "27c92e21-0862-4442-a85b-cb29d7c9be1a"
      },
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([2, 4, 6])\n",
        "\n",
        "c = a * b\n",
        "print(\"The multiple between a an b is {}\".format(c))\n",
        "\n",
        "c = a.mul(b)\n",
        "print(\"The multiple between a an b is {}\".format(c))\n",
        "\n",
        "e = torch.tensor([[1, 2], [3, 4]])\n",
        "f = torch.tensor([[2, 2], [2, 2]])\n",
        "\n",
        "g = e*f \n",
        "print(\"The multiple between e an f is {}\".format(g))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The multiple between a an b is tensor([ 2,  8, 18])\n",
            "The multiple between a an b is tensor([ 2,  8, 18])\n",
            "The multiple between e an f is tensor([[2, 4],\n",
            "        [6, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB87B5TBKLcN"
      },
      "source": [
        "### 3. Altering Tensors in Place\n",
        "\n",
        "Most binary operations on tensors will return a third, new tensor. When we say <font color='red'>`c = a * b`</font> (where <font color='red'>`a`</font> and <font color='red'>`b`</font> are tensors), the new tensor <font color='red'>`c`</font> will occupy a region of memory distinct from the other tensors.\n",
        "\n",
        "There are times, though, that you may wish to alter a tensor in place - for example, if you're doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (<font color='red'>`_`</font>) that will alter a tensor in place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IMvkMa5Kpc5",
        "outputId": "16673bae-5112-4f68-a8a4-5d24d29bb9a0"
      },
      "source": [
        "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('a:')\n",
        "print(a)\n",
        "print(torch.sin(a))   # this operation creates a new tensor in memory\n",
        "print(a)              # a has not changed\n",
        "\n",
        "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print('\\nb:')\n",
        "print(b)\n",
        "print(torch.sin_(b))  # note the underscore\n",
        "print(b)              # b has changed"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "\n",
            "b:\n",
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNHkzE6TKx_S"
      },
      "source": [
        "For arithmetic operations, there are functions that behave similarly:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vNGlxTbKwVB",
        "outputId": "1c8b095d-714a-4ece-a384-3091f6bd6224"
      },
      "source": [
        "a = torch.ones(2, 2)\n",
        "b = torch.rand(2, 2)\n",
        "\n",
        "print('Before:')\n",
        "print(a)\n",
        "print(b)\n",
        "print('\\nAfter adding:')\n",
        "print(a.add_(b))\n",
        "print(a)\n",
        "print(b)\n",
        "print('\\nAfter multiplying')\n",
        "print(b.mul_(b))\n",
        "print(b)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[0.9883, 0.4762],\n",
            "        [0.7242, 0.0776]])\n",
            "\n",
            "After adding:\n",
            "tensor([[1.9883, 1.4762],\n",
            "        [1.7242, 1.0776]])\n",
            "tensor([[1.9883, 1.4762],\n",
            "        [1.7242, 1.0776]])\n",
            "tensor([[0.9883, 0.4762],\n",
            "        [0.7242, 0.0776]])\n",
            "\n",
            "After multiplying\n",
            "tensor([[0.9768, 0.2268],\n",
            "        [0.5245, 0.0060]])\n",
            "tensor([[0.9768, 0.2268],\n",
            "        [0.5245, 0.0060]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u-PZwcrHR6P"
      },
      "source": [
        "## Reduction and Comparison\n",
        "\n",
        "### 1. Reduction functions\n",
        "\n",
        "The reduction operator is a type of operator that is commonly used in parallel programming to reduce the elements of an array into a single result. For example, we can calculate the mean value of a float array is a reduction operation.\n",
        "\n",
        "**PyTorch** provides some useful functions for reduction. If you have used NumPy before, you may notice the usage and name are the same. Below are some important functions, they all have a parameter <font color='red'>`dim`</font>, which indicates on which dimension the summarization is performed. The default value for <font color='red'>`dim`</font> is 0.\n",
        "\n",
        "|Function | Name | Purpose|\n",
        "|---|---|---|\n",
        "|mean|\tGet the mean value of the tensor in the given dimension.|\n",
        "|sum|\tSum the values of the tensor over the given dimension.|\n",
        "|median|\tGet the median value of tensor in the given dimension.|\n",
        "|std|\tCompute the standard deviation of the tensor over the given dimension.|\n",
        "|prod|\tProduct the values of the tensor over the given dimension.|\n",
        "|cumsum|\tCumulative sum of values of the tensor over the given dimension.|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWmhN2ZIK4u",
        "outputId": "e5a2e958-8331-4244-cdaa-fb2b4ad6dc43"
      },
      "source": [
        "a = torch.randn((3,4))\n",
        "print(\"The original tensor is \\n {}\".format(a))\n",
        "\n",
        "print(\"=\"*30)\n",
        "b = torch.mean(a, dim=1)\n",
        "print(\"The mean value of dim=1 \\n {}\".format(b))\n",
        "\n",
        "print(\"=\"*30)\n",
        "c = torch.sum(a, dim=0)\n",
        "print(\"The sum value of dim=0 \\n {}\".format(c))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor is \n",
            " tensor([[ 0.2359,  0.7787, -0.1732, -0.1074],\n",
            "        [ 1.9456,  0.4525,  0.1014,  0.3339],\n",
            "        [ 1.6279,  1.0423, -0.6320,  1.4610]])\n",
            "==============================\n",
            "The mean value of dim=1 \n",
            " tensor([0.1835, 0.7084, 0.8748])\n",
            "==============================\n",
            "The sum value of dim=0 \n",
            " tensor([ 3.8094,  2.2735, -0.7038,  1.6875])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMRdaNBmIImG"
      },
      "source": [
        "### 2. Comparison functions\n",
        "\n",
        "**PyTorch** allows us to compare a tensor with another tensor or a scalar, element-wise. The return value is a <font color='red'>`Boolean`</font> tensor that contains a <font color='red'>`True`</font> at each location where the comparison is true.\n",
        "\n",
        "For these functions in the list, they require two parameters.\n",
        "\n",
        "* **inputs**: The tensor to compare.\n",
        "* **other**: The tensor or value to compare. If it’s a tensor, then the comparison is performed element-wise.\n",
        "\n",
        "|Function\t| Purpose|\n",
        "|---|---|\n",
        "|lt|\tLess than|\n",
        "|le|\tLess than or equal to|\n",
        "|gt|\tGreater than|\n",
        "|ge|\tGreater than or equal to|\n",
        "|eq|\tEqual to|\n",
        "|ne|\tNot Equal to|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viavjDqDI_ar",
        "outputId": "c6e239a5-a31e-4acb-e03c-c848ac5beb75"
      },
      "source": [
        "a = torch.randn((3,4))\n",
        "print(\"The original tensor is \\n {}\".format(a))\n",
        "\n",
        "print(\"=\"*30)\n",
        "print(\"The comparison between a tensor and a single value.\\n\")\n",
        "b = torch.lt(a, 0.5)\n",
        "print(\"The element is less than 0.5 \\n {}\".format(b))\n",
        "\n",
        "print(\"=\"*30)\n",
        "c = torch.randn((3, 4))\n",
        "print(\"The comparison between two tensors.\\n\")\n",
        "d = torch.gt(a, c)\n",
        "print(\"The comparison result between tesnor a and c \\n {}\".format(d))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original tensor is \n",
            " tensor([[ 2.3482,  0.1805, -0.5357,  1.2000],\n",
            "        [-0.6827, -0.1046, -0.9332, -0.8011],\n",
            "        [-0.1352,  0.0627,  0.9978, -1.1855]])\n",
            "==============================\n",
            "The comparison between a tensor and a single value.\n",
            "\n",
            "The element is less than 0.5 \n",
            " tensor([[False,  True,  True, False],\n",
            "        [ True,  True,  True,  True],\n",
            "        [ True,  True, False,  True]])\n",
            "==============================\n",
            "The comparison between two tensors.\n",
            "\n",
            "The comparison result between tesnor a and c \n",
            " tensor([[ True, False,  True,  True],\n",
            "        [ True, False, False,  True],\n",
            "        [False,  True,  True, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YE2lvXSJHWR"
      },
      "source": [
        "## Matrix Vector Multiplication\n",
        "\n",
        "### 1. Matrix multiplication with vectors\n",
        "\n",
        "Let us first see how we can multiply a matrix with a vector. **PyTorch** provides the <font color='red'>``</font>mv() function for this purpose.\n",
        "\n",
        "We can use <font color='red'>`mv()`</font> in two ways. <font color='red'>`mv()`</font> could be called from a tensor, or just call it from <font color='red'>`torch.mv()`</font>. The first parameter for <font color='red'>`torch.mv()`</font> is a matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77gcEapbJmCh",
        "outputId": "1082b4dc-614e-4613-bcf9-8d9ddb06f1a6"
      },
      "source": [
        "mat = torch.ones((2, 4))\n",
        "print(\"The matrix is \\n{}\".format(mat))\n",
        "\n",
        "print(\"=\"*30)\n",
        "vec = torch.tensor([1, 2, 3, 4], dtype=torch.float)\n",
        "print(\"The vector is \\n{}\".format(vec))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = mat.mv(vec)\n",
        "print(\"The result is \\n{}\".format(result))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = torch.mv(mat, vec)\n",
        "print(\"The result is \\n{}\".format(result))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The matrix is \n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "==============================\n",
            "The vector is \n",
            "tensor([1., 2., 3., 4.])\n",
            "==============================\n",
            "The result is \n",
            "tensor([10., 10.])\n",
            "==============================\n",
            "The result is \n",
            "tensor([10., 10.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft3_x2FaJsbz"
      },
      "source": [
        "**Note**: The order of the matrix and vector is critical, otherwise, you may trigger the runtime error. The first argument of <font color='red'>`mv`</font> should be the matrix, the second should be the vector. For example, if the matrix is an (<font color='red'>`n×m`</font>) tensor, then the vector should be is a 1-D tensor of size <font color='red'>`m`</font>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdU1C4FcJ-Ql"
      },
      "source": [
        "### 3. Matrix multiplication with matrices\n",
        "\n",
        "<font color='red'>`mm()`</font> is used in PyTorch to multiply two matrices. Similar to <font color='red'>`mv()`</font>, we have two ways to call <font color='red'>`mm()`</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5PYs7ZLKUU2",
        "outputId": "6c943546-5a02-47b5-f31d-c2dc7e23d9cc"
      },
      "source": [
        "mat1 = torch.ones((2, 4))\n",
        "mat2 = torch.ones((4, 3))\n",
        "\n",
        "result = torch.mm(mat1, mat2)\n",
        "print(\"The result is \\n {}\".format(result))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = mat1.mm(mat2)\n",
        "print(\"The result is \\n {}\".format(result))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is \n",
            " tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.]])\n",
            "==============================\n",
            "The result is \n",
            " tensor([[4., 4., 4.],\n",
            "        [4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFM5oBViKY48"
      },
      "source": [
        "### 4. Dot product between vectors\n",
        "\n",
        "The dot product is the sum of the products of the corresponding element of the two tensors. <font color='red'>`dot()`</font> is the function for this purpose.\n",
        "\n",
        "We can use <font color='red'>`dot()`</font> in two ways. <font color='red'>`dot()`</font> could be called from a 1D tensor, or just call it from <font color='red'>`torch.dot()`</font>, which requires two **1D** tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmgQKcxYKvs1",
        "outputId": "187c72f4-58fd-484e-dcc0-e38129452dfa"
      },
      "source": [
        "vec1 = torch.tensor([1, 2, 3, 4])\n",
        "vec2 = torch.tensor([2, 3, 4, 5])\n",
        "\n",
        "result = vec1.dot(vec2)\n",
        "print(\"The result is \\n {}\".format(result))\n",
        "\n",
        "print(\"=\"*30)\n",
        "result = torch.dot(vec1, vec2)\n",
        "print(\"The result is \\n {}\".format(result))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result is \n",
            " 40\n",
            "==============================\n",
            "The result is \n",
            " 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPJAdIuOK09X"
      },
      "source": [
        "## Saving and loading tensors\n",
        "\n",
        "### 1. Saving a single tensor\n",
        "\n",
        "Sometimes, we want to dump a tensor to the disk for future use immediately after an operation. It could save a lot of time in scenarios where the processing takes too long and we don’t want to go through the whole process again.\n",
        "\n",
        "**PyTorch** provides <font color='red'>`torch.save`</font> to save objects to a file-like object. In this lesson, we only save the object to a file. The first parameter is the object we want to save, in this example, it’s a tensor. In this example, the second parameter is a file path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzghSzVmLEye"
      },
      "source": [
        "a = torch.tensor([1, 2, 3])\n",
        "torch.save(a, \"./tensor.pt\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW4Rb9HsLOcp"
      },
      "source": [
        "### 2. Loading tensors from a file\n",
        "\n",
        "In the previous section, we learned how to dump a tensor into a local file. Now we look loading values into a tensor from a given file. It’s quite simple, just use the <font color='red'>`load()`</font> function and specify the file path as an argument. The function would return a tensor which can be copied into a variable, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ktw7Hw8LYPU",
        "outputId": "7b810e66-4451-4807-e1ca-303da3012924"
      },
      "source": [
        "b = torch.load(\"./tensor.pt\")\n",
        "print(\"The tensor b is {}\".format(b))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor b is tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohlp0_1hLiaJ"
      },
      "source": [
        "### 3. Saving multiple tensors\n",
        "\n",
        "There are many methods to save multiple objects to a local file. In this lesson, we use the simplest way to do it. We use a native Python map to store the objects and dump them with <font color='red'>`torch.save`</font>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMgD3orRLta3",
        "outputId": "df30d5d0-b8e1-442f-f64c-229082df3d4d"
      },
      "source": [
        "# m is a key-value structure to store variables.\n",
        "# In this example, \"t1\" is the key, and tensor([1, 2, 3]) is the value.\n",
        "m = {}\n",
        "m[\"t1\"] = torch.tensor([1, 2, 3])\n",
        "m[\"t2\"] = torch.tensor([2, 4, 6])\n",
        "torch.save(m, \"./m_tensor.pt\")\n",
        "\n",
        "m2 = torch.load(\"./m_tensor.pt\")\n",
        "print(\"The tensor map is {}\".format(m2))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensor map is {'t1': tensor([1, 2, 3]), 't2': tensor([2, 4, 6])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGLMwAXdMq7_"
      },
      "source": [
        "## Moving to GPU\n",
        "\n",
        "One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (\"CUDA\" stands for *Compute Unified Device Architecture*, which is Nvidia's platform for parallel computing.) So far, everything we've done has been on CPU. How do we move to the faster hardware?\n",
        "\n",
        "First, we should check whether a GPU is available, with the <font color='red'>`is_available()`</font> method.\n",
        "\n",
        "**Note: If you do not have a CUDA-compatible GPU and CUDA drivers installed, the executable cells in this section will not execute any GPU-related code.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6msIo-KPLLx",
        "outputId": "16c5ce46-b488-43ce-8637-b4439a6bedc0"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('We have a GPU!')\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, CPU only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imlkRnehPRAh"
      },
      "source": [
        "Once we've determined that one or more GPUs is available, we need to put our data someplace where the GPU can see it. Your CPU does computation on data in your computer's RAM. Your GPU has dedicated memory attached to it. Whenever you want to perform a computation on a device, you must move *all* the data needed for that computation to memory accessible by that device. (Colloquially, \"moving the data to memory accessible by the GPU\" is shorted to, \"moving the data to the GPU\".)\n",
        "\n",
        "There are multiple ways to get your data onto your target device. You may do it at creation time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHFTTvx9PZJD",
        "outputId": "8980a113-bda3-46a1-f299-2e7efa9bb5fe"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    gpu_rand = torch.rand(2, 2, device='cuda')\n",
        "    print(gpu_rand)\n",
        "else:\n",
        "    print('Sorry, CPU only.')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, CPU only.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3QBz5wrPleN"
      },
      "source": [
        "By default, new tensors are created on the CPU, so we have to specify when we want to create our tensor on the GPU with the optional <font color='red'>`device`</font> argument. You can see when we print the new tensor, PyTorch informs us which device it's on (if it's not on CPU).\n",
        "\n",
        "You can query the number of GPUs with <font color='red'>`torch.cuda.device_count()`</font>. If you have more than one GPU, you can specify them by index: <font color='red'>`device='cuda:0'`</font>, <font color='red'>`device='cuda:1'`</font>, etc.\n",
        "\n",
        "As a coding practice, specifying our devices everywhere with string constants is pretty fragile. In an ideal world, your code would perform robustly whether you're on CPU or GPU hardware. You can do this by creating a device handle that can be passed to your tensors instead of a string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RjFGZigP4QB",
        "outputId": "663ed25a-e4ee-493e-ac48-8de4f5b56bc7"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    my_device = torch.device('cuda')\n",
        "else:\n",
        "    my_device = torch.device('cpu')\n",
        "print('Device: {}'.format(my_device))\n",
        "\n",
        "x = torch.rand(2, 2, device=my_device)\n",
        "print(x)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "tensor([[0.1986, 0.1779],\n",
            "        [0.6366, 0.2301]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G49xVxIyP_jh"
      },
      "source": [
        "### 1. Casting into different device type\n",
        "\n",
        "If you have an existing tensor living on one device, you can move it to another with the <font color='red'>`to()`</font> method. The following line of code creates a tensor on CPU, and moves it to whichever device you specify.\n",
        "\n",
        "If you have only one GPU, you can use the code below to get the GPU ID and cast it. If you have multiple GPUs, then you can use <font color='red'>`cuda:0`</font>, <font color='red'>`cuda:1`</font>, or <font color='red'>`cuda:2`</font> to get a different GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEG-BWGPQESB"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "a = torch.tensor([1, 2, 3])\n",
        "c = a.to(device)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRSwljaXQSeC"
      },
      "source": [
        "**Note**: It is important to know that in order to do computation involving two or more tensors, *all of the tensors must be on the same device*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrbssveoQz0g"
      },
      "source": [
        "### 2. Checking if the tensor is on GPU\n",
        "\n",
        "<font color='red'>`is_cuda`</font> is an attribute of a tensor. It is true if the tensor is stored on the GPU. Otherwise, it will be set to false.\n",
        "\n",
        "#### Getting the device\n",
        "device is an attribute of a tensor. It contains the information of the device being used by the tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-9BMZEyQP4U",
        "outputId": "ea96d10f-a82f-499c-e7cf-cc09255f7496"
      },
      "source": [
        "a = torch.randn((2, 3, 4), dtype=torch.float)\n",
        "print(\"The GPU is {}.\\n\".format(a.is_cuda))\n",
        "print(\"The device is {}.\".format(a.device))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPU is False.\n",
            "\n",
            "The device is cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQzeIBx_SUXt"
      },
      "source": [
        "## And that's it for today!"
      ]
    }
  ]
}